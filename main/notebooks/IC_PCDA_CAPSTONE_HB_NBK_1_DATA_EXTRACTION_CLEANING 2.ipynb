{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60388f2d-5043-44b1-b7bd-0b5526b0abc8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "     \n",
    "# IC PCDA CAPSTONE - HARRY BAKHSHI - NOTEBOOK 1 - DATA EXTRACTION AND CLEANING\n",
    "     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea1e6f9-4821-403a-b0f2-df808152d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996ac7a-8ef4-4761-b4e8-abfbe8cc5e36",
   "metadata": {},
   "source": [
    "Data from: https://datahack.analyticsvidhya.com/contest/janatahack-demand-forecasting/True/#ProblemStatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e704b2-1e80-4e9e-b2a6-360194bfeb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150150 entries, 0 to 150149\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   record_ID        150150 non-null  int64  \n",
      " 1   week             150150 non-null  object \n",
      " 2   store_id         150150 non-null  int64  \n",
      " 3   sku_id           150150 non-null  int64  \n",
      " 4   total_price      150149 non-null  float64\n",
      " 5   base_price       150150 non-null  float64\n",
      " 6   is_featured_sku  150150 non-null  int64  \n",
      " 7   is_display_sku   150150 non-null  int64  \n",
      " 8   units_sold       150150 non-null  int64  \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 10.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/harrybakhshi/Desktop/Python_notes/data/train_0irEZ2H.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986be96c-08dc-47ed-9efb-1b85440b399a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4230e9-1cd1-4a1e-80d1-fe07a0e9b6b6",
   "metadata": {},
   "source": [
    "Null values in df col 4 - drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f1d8d9-1423-4104-bd82-34cfb9822cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150149 entries, 0 to 150149\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   record_ID        150149 non-null  int64  \n",
      " 1   week             150149 non-null  object \n",
      " 2   store_id         150149 non-null  int64  \n",
      " 3   sku_id           150149 non-null  int64  \n",
      " 4   total_price      150149 non-null  float64\n",
      " 5   base_price       150149 non-null  float64\n",
      " 6   is_featured_sku  150149 non-null  int64  \n",
      " 7   is_display_sku   150149 non-null  int64  \n",
      " 8   units_sold       150149 non-null  int64  \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 15.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "col_indices = [4]\n",
    "for col in range(len(col_indices)):\n",
    "    for i in df.index:\n",
    "        val = df.loc[i, df.columns.values[col_indices[col]]]\n",
    "        if pd.isnull(val):\n",
    "            df.drop(i, inplace = True)\n",
    "print(df.info()) #see results on dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a4218-acda-4f27-8909-1d37ed9c6518",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc959cd8-9e9f-41c1-82de-a8588d9b93a7",
   "metadata": {},
   "source": [
    "Convert week column to datetime64[ns] format in both dfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d756cd1-dab4-44e1-9e23-b1cd3a162f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values[1])\n",
    "# ensure timestamps in datetime64[ns] format\n",
    "df[df.columns.values[1]] = pd.to_datetime(df[df.columns.values[1]], format='mixed')\n",
    "#^https://saturncloud.io/blog/convert-pandas-column-to-datetime-a-guide/#:~:text=To%20convert%20a%20pandas%20column,new%20column%20with%20datetime%20values.\n",
    "#Accessed 06/06/2024\n",
    "import pandas.api.types as ptypes\n",
    "print(ptypes.is_datetime64_dtype(df['week']))\n",
    "#^https://stackoverflow.com/questions/25043620/correct-way-to-check-if-pandas-dataframe-index-is-a-certain-type-datetimeindex\n",
    "#Accessed 06/06/2024\n",
    "df = df.rename(columns={\"week\":\"timestamp\"})\n",
    "#^https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html\n",
    "#Accessed 06/06/2024\n",
    "df = df.sort_values(by='timestamp')\n",
    "#^https://blog.hubspot.com/website/pandas-sortby#:~:text=Pandas%20Sort%20by%20Column&text=Sorting%20data%20within%20a%20dataframe,the%20values%20in%20descending%20order.\n",
    "#Accessed 05/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1184ff1-7ecf-4bbd-a0dd-34082a2964a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150149"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77483f1b-8555-45ed-9876-409370771b57",
   "metadata": {},
   "source": [
    "Explore data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2be7cff-043d-45f4-839a-29568b5f5fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_ID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>store_id</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>total_price</th>\n",
       "      <th>base_price</th>\n",
       "      <th>is_featured_sku</th>\n",
       "      <th>is_display_sku</th>\n",
       "      <th>units_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33494</th>\n",
       "      <td>47417</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9984</td>\n",
       "      <td>679023</td>\n",
       "      <td>180.2625</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32721</th>\n",
       "      <td>46310</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9112</td>\n",
       "      <td>216419</td>\n",
       "      <td>88.3500</td>\n",
       "      <td>119.7000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32722</th>\n",
       "      <td>46311</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9112</td>\n",
       "      <td>300021</td>\n",
       "      <td>86.2125</td>\n",
       "      <td>116.1375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32723</th>\n",
       "      <td>46314</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9112</td>\n",
       "      <td>216425</td>\n",
       "      <td>128.9625</td>\n",
       "      <td>128.9625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32724</th>\n",
       "      <td>46315</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9112</td>\n",
       "      <td>216233</td>\n",
       "      <td>133.9500</td>\n",
       "      <td>133.9500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32725</th>\n",
       "      <td>46316</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9112</td>\n",
       "      <td>217390</td>\n",
       "      <td>141.0750</td>\n",
       "      <td>166.7250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32726</th>\n",
       "      <td>46319</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9112</td>\n",
       "      <td>219844</td>\n",
       "      <td>288.5625</td>\n",
       "      <td>288.5625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32720</th>\n",
       "      <td>46309</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9112</td>\n",
       "      <td>216418</td>\n",
       "      <td>87.6375</td>\n",
       "      <td>119.7000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32727</th>\n",
       "      <td>46320</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9112</td>\n",
       "      <td>219009</td>\n",
       "      <td>227.2875</td>\n",
       "      <td>227.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32729</th>\n",
       "      <td>46322</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9112</td>\n",
       "      <td>222087</td>\n",
       "      <td>227.2875</td>\n",
       "      <td>227.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       record_ID  timestamp  store_id  sku_id  total_price  base_price  \\\n",
       "33494      47417 2011-01-08      9984  679023     180.2625    213.0375   \n",
       "32721      46310 2011-01-08      9112  216419      88.3500    119.7000   \n",
       "32722      46311 2011-01-08      9112  300021      86.2125    116.1375   \n",
       "32723      46314 2011-01-08      9112  216425     128.9625    128.9625   \n",
       "32724      46315 2011-01-08      9112  216233     133.9500    133.9500   \n",
       "32725      46316 2011-01-08      9112  217390     141.0750    166.7250   \n",
       "32726      46319 2011-01-08      9112  219844     288.5625    288.5625   \n",
       "32720      46309 2011-01-08      9112  216418      87.6375    119.7000   \n",
       "32727      46320 2011-01-08      9112  219009     227.2875    227.2875   \n",
       "32729      46322 2011-01-08      9112  222087     227.2875    227.2875   \n",
       "\n",
       "       is_featured_sku  is_display_sku  units_sold  \n",
       "33494                0               0          21  \n",
       "32721                0               1         154  \n",
       "32722                0               1         128  \n",
       "32723                0               0          38  \n",
       "32724                0               0          89  \n",
       "32725                0               0         156  \n",
       "32726                0               0          28  \n",
       "32720                0               0         166  \n",
       "32727                0               0          75  \n",
       "32729                0               0         123  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8edfcda7-40c8-464d-8533-4f8b67a281a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_ID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>store_id</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>total_price</th>\n",
       "      <th>base_price</th>\n",
       "      <th>is_featured_sku</th>\n",
       "      <th>is_display_sku</th>\n",
       "      <th>units_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150149.000000</td>\n",
       "      <td>150149</td>\n",
       "      <td>150149.000000</td>\n",
       "      <td>150149.000000</td>\n",
       "      <td>150149.000000</td>\n",
       "      <td>150149.000000</td>\n",
       "      <td>150149.000000</td>\n",
       "      <td>150149.000000</td>\n",
       "      <td>150149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>106270.971795</td>\n",
       "      <td>2012-04-18 17:50:55.213154816</td>\n",
       "      <td>9199.420935</td>\n",
       "      <td>254761.195226</td>\n",
       "      <td>206.626751</td>\n",
       "      <td>219.424262</td>\n",
       "      <td>0.095612</td>\n",
       "      <td>0.133201</td>\n",
       "      <td>51.674543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2011-01-08 00:00:00</td>\n",
       "      <td>8023.000000</td>\n",
       "      <td>216233.000000</td>\n",
       "      <td>41.325000</td>\n",
       "      <td>61.275000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53111.000000</td>\n",
       "      <td>2011-08-22 00:00:00</td>\n",
       "      <td>8562.000000</td>\n",
       "      <td>217217.000000</td>\n",
       "      <td>130.387500</td>\n",
       "      <td>133.237500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>106226.000000</td>\n",
       "      <td>2012-04-09 00:00:00</td>\n",
       "      <td>9371.000000</td>\n",
       "      <td>222087.000000</td>\n",
       "      <td>198.075000</td>\n",
       "      <td>205.912500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>159452.000000</td>\n",
       "      <td>2012-11-20 00:00:00</td>\n",
       "      <td>9731.000000</td>\n",
       "      <td>245338.000000</td>\n",
       "      <td>233.700000</td>\n",
       "      <td>234.412500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>212644.000000</td>\n",
       "      <td>2013-12-03 00:00:00</td>\n",
       "      <td>9984.000000</td>\n",
       "      <td>679023.000000</td>\n",
       "      <td>562.162500</td>\n",
       "      <td>562.162500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2876.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61385.825580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>615.593192</td>\n",
       "      <td>85547.587866</td>\n",
       "      <td>103.308516</td>\n",
       "      <td>110.960204</td>\n",
       "      <td>0.294059</td>\n",
       "      <td>0.339793</td>\n",
       "      <td>60.207962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           record_ID                      timestamp       store_id  \\\n",
       "count  150149.000000                         150149  150149.000000   \n",
       "mean   106270.971795  2012-04-18 17:50:55.213154816    9199.420935   \n",
       "min         1.000000            2011-01-08 00:00:00    8023.000000   \n",
       "25%     53111.000000            2011-08-22 00:00:00    8562.000000   \n",
       "50%    106226.000000            2012-04-09 00:00:00    9371.000000   \n",
       "75%    159452.000000            2012-11-20 00:00:00    9731.000000   \n",
       "max    212644.000000            2013-12-03 00:00:00    9984.000000   \n",
       "std     61385.825580                            NaN     615.593192   \n",
       "\n",
       "              sku_id    total_price     base_price  is_featured_sku  \\\n",
       "count  150149.000000  150149.000000  150149.000000    150149.000000   \n",
       "mean   254761.195226     206.626751     219.424262         0.095612   \n",
       "min    216233.000000      41.325000      61.275000         0.000000   \n",
       "25%    217217.000000     130.387500     133.237500         0.000000   \n",
       "50%    222087.000000     198.075000     205.912500         0.000000   \n",
       "75%    245338.000000     233.700000     234.412500         0.000000   \n",
       "max    679023.000000     562.162500     562.162500         1.000000   \n",
       "std     85547.587866     103.308516     110.960204         0.294059   \n",
       "\n",
       "       is_display_sku     units_sold  \n",
       "count   150149.000000  150149.000000  \n",
       "mean         0.133201      51.674543  \n",
       "min          0.000000       1.000000  \n",
       "25%          0.000000      20.000000  \n",
       "50%          0.000000      35.000000  \n",
       "75%          0.000000      62.000000  \n",
       "max          1.000000    2876.000000  \n",
       "std          0.339793      60.207962  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaee190-17e5-4c80-8a27-e280bb031eca",
   "metadata": {},
   "source": [
    "Observation: data over 1061 days (2 years, 10 months, 26 days, or 34 months 26 days, or 151 weeks 4 days (including end date) from 8th Jan 2011 to 3rd Dec 2013     \n",
    "^https://www.timeanddate.com/date/durationresult.html?d1=08&m1=01&y1=2011&d2=03&m2=12&y2=2013&ti=on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd16f343-2308-4700-839e-f3ef5220af94",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604bac63-5f99-4630-b9d7-296cdffab4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150149 entries, 33494 to 129937\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   record_ID        150149 non-null  int64         \n",
      " 1   timestamp        150149 non-null  datetime64[ns]\n",
      " 2   store_id         150149 non-null  int64         \n",
      " 3   sku_id           150149 non-null  int64         \n",
      " 4   total_price      150149 non-null  float64       \n",
      " 5   base_price       150149 non-null  float64       \n",
      " 6   is_featured_sku  150149 non-null  int64         \n",
      " 7   is_display_sku   150149 non-null  int64         \n",
      " 8   units_sold       150149 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(6)\n",
      "memory usage: 11.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9232243-a5d7-4e68-aa7f-3edcb94b1c6c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "453f6175-35f5-44e1-acb4-4fed694e69c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(ptypes.is_datetime64_dtype(df['timestamp']))\n",
    "#^https://stackoverflow.com/questions/25043620/correct-way-to-check-if-pandas-dataframe-index-is-a-certain-type-datetimeindex\n",
    "#Accessed 06/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b45b299b-2f1a-4cd8-8326-df8603ce0e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_ID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>store_id</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>total_price</th>\n",
       "      <th>base_price</th>\n",
       "      <th>is_featured_sku</th>\n",
       "      <th>is_display_sku</th>\n",
       "      <th>units_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33494</th>\n",
       "      <td>47417</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9984</td>\n",
       "      <td>679023</td>\n",
       "      <td>180.2625</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33459</th>\n",
       "      <td>47366</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9954</td>\n",
       "      <td>245338</td>\n",
       "      <td>469.5375</td>\n",
       "      <td>469.5375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33486</th>\n",
       "      <td>47407</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9984</td>\n",
       "      <td>222087</td>\n",
       "      <td>227.2875</td>\n",
       "      <td>227.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33492</th>\n",
       "      <td>47415</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9984</td>\n",
       "      <td>245338</td>\n",
       "      <td>469.5375</td>\n",
       "      <td>469.5375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33491</th>\n",
       "      <td>47412</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9984</td>\n",
       "      <td>223153</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32345</th>\n",
       "      <td>45793</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>8091</td>\n",
       "      <td>219009</td>\n",
       "      <td>227.2875</td>\n",
       "      <td>227.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32344</th>\n",
       "      <td>45789</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>8091</td>\n",
       "      <td>217390</td>\n",
       "      <td>142.5000</td>\n",
       "      <td>168.8625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32350</th>\n",
       "      <td>45802</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>8095</td>\n",
       "      <td>216419</td>\n",
       "      <td>89.0625</td>\n",
       "      <td>89.0625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>8091</td>\n",
       "      <td>216233</td>\n",
       "      <td>133.9500</td>\n",
       "      <td>133.9500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>50</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>8094</td>\n",
       "      <td>217217</td>\n",
       "      <td>235.8375</td>\n",
       "      <td>235.8375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1157 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       record_ID  timestamp  store_id  sku_id  total_price  base_price  \\\n",
       "33494      47417 2011-01-08      9984  679023     180.2625    213.0375   \n",
       "33459      47366 2011-01-08      9954  245338     469.5375    469.5375   \n",
       "33486      47407 2011-01-08      9984  222087     227.2875    227.2875   \n",
       "33492      47415 2011-01-08      9984  245338     469.5375    469.5375   \n",
       "33491      47412 2011-01-08      9984  223153     213.0375    213.0375   \n",
       "...          ...        ...       ...     ...          ...         ...   \n",
       "32345      45793 2011-01-08      8091  219009     227.2875    227.2875   \n",
       "32344      45789 2011-01-08      8091  217390     142.5000    168.8625   \n",
       "32350      45802 2011-01-08      8095  216419      89.0625     89.0625   \n",
       "3              4 2011-01-17      8091  216233     133.9500    133.9500   \n",
       "34            50 2011-01-17      8094  217217     235.8375    235.8375   \n",
       "\n",
       "       is_featured_sku  is_display_sku  units_sold  \n",
       "33494                0               0          21  \n",
       "33459                0               0           9  \n",
       "33486                0               0          38  \n",
       "33492                0               0          10  \n",
       "33491                0               0          14  \n",
       "...                ...             ...         ...  \n",
       "32345                0               0           7  \n",
       "32344                0               0          24  \n",
       "32350                0               0          92  \n",
       "3                    0               0          44  \n",
       "34                   0               0          32  \n",
       "\n",
       "[1157 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by='timestamp')\n",
    "#^https://blog.hubspot.com/website/pandas-sortby#:~:text=Pandas%20Sort%20by%20Column&text=Sorting%20data%20within%20a%20dataframe,the%20values%20in%20descending%20order.\n",
    "#Accessed 05/06/2024\n",
    "df.head(1157)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d52767-edaf-48ea-a275-5104a0a09c57",
   "metadata": {},
   "source": [
    "Data attributes:\n",
    "    \n",
    "* record_ID = Unique ID for each timestamp + product + and store combination recorded in the data (categorical, nominal)  \n",
    "    \n",
    "    An sku (stock keeping unit) is \"a unique identifier for a product, typically assigned by a retailer or manufacturer\", \"used to track inventory\" and \"typically associated with a product's barcode\", \"the unique identifier for a specific product\"\n",
    "\n",
    "^https://www.shopify.com/uk/blog/what-is-a-stock-keeping-unit (Accessed 08/06/2024)\n",
    "    \n",
    "* timestamp = date of record (day in a given week when record made) (numeric, time series)       \n",
    "* store_id = Unique ID for each store (no numerical order to be assumed) (categorical, nominal)            \n",
    "* sku_id = Unique ID for each product (no numerical order to be assumed) (categorical, nominal)\n",
    "* total_price = Sales Price of the product (numeric, float)                \n",
    "* base_price = Base price of the product (numeric, float)\n",
    "\n",
    "    The base price of a product is \"the initial cost of a product or service before any additional fees or taxes are added\" such as delivery, registrations required, taxes applying to the product/service. It may change to 'maintain profitability' if the production costs, supply and demand, competition, and market trends change. (1)\n",
    "  \n",
    "  Profitability is the property of something that it produces or is likely to produce profit. (2)    \n",
    "  \"profitability - the fact that something produces or is likely to produce a profit\" (2)    \n",
    "^(1) https://fastercapital.com/topics/what-is-base-price.html (Accessed 08/06/2024)  \n",
    "^(2) https://dictionary.cambridge.org/dictionary/english/profitability (Accessed 08/06/2024)\n",
    "    \n",
    "* is_featured_sku = unique item was part of the featured item of the week (categorical, binary)\n",
    "* is_display_sku = unique item was on display at a prominent place at the store (categorical, binary)\n",
    "* units_sold = Total Units sold for the sku, in the given week of the timestamp and/or between the last time stamp and the current timestamp, and the recorded store of sale (numeric, int)\n",
    "\n",
    "^https://datahack.analyticsvidhya.com/contest/janatahack-demand-forecasting/True/#ProblemStatement\n",
    "(Accessed 07/06/2024)\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af48c0bf-c8d4-4fa9-a9d4-6ccc3321f2ee",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e73ee61-a19f-44b2-a33b-470762a71807",
   "metadata": {},
   "source": [
    "Plan:   \n",
    "Do multivariate time series with variables:\n",
    "    \n",
    "    timestamp:\n",
    "    timestamp = date of record (day in a given week when record made) (numeric, time series) \n",
    "    \n",
    "    Variables:\n",
    "    total_price = Sales Price of the product (numeric, float)                \n",
    "    base_price = Base price of the product (numeric, float)\n",
    "    units_sold = Total Units sold for the sku, in the given week of the timestamp and/or between the last time stamp and the current timestamp, and the recorded store of sale (numeric, int)\n",
    "    is_featured_sku = unique item was part of the featured item of the week (categorical, binary)\n",
    "    is_display_sku = unique item was on display at a prominent place at the store (categorical, binary)\n",
    "                \n",
    "    sku_id = Unique ID for each product (no numerical order to be assumed) (categorical, nominal)\n",
    "    \n",
    "    Create new variables (percent_featured, percent_display); these and total_price, base_price, units_sold for each sku_id (= product) to take a value at each timestamp\n",
    "\n",
    "      \n",
    "Forecast the product sales price, base price, units sold, for a given timestamp where the time is a date in the sales period (from week to week between timestamps) by which the recorded sales were made \n",
    "    \n",
    "Able to work out at a specific time of interest, what product is selling in what volume\n",
    "    \n",
    "Useful for predicting how products will sell and for what sales and base prices (what sales + base prices sell more/less of a product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327f723-29a9-478c-b6a9-86a4f46a8a53",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b5524-0d58-4821-952f-44a1fa31f22f",
   "metadata": {},
   "source": [
    "Drop cols not needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee43f47b-5efb-4a43-9b82-b69b8c78d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150149 entries, 33494 to 129937\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   timestamp        150149 non-null  datetime64[ns]\n",
      " 1   store_id         150149 non-null  int64         \n",
      " 2   sku_id           150149 non-null  int64         \n",
      " 3   total_price      150149 non-null  float64       \n",
      " 4   base_price       150149 non-null  float64       \n",
      " 5   is_featured_sku  150149 non-null  int64         \n",
      " 6   is_display_sku   150149 non-null  int64         \n",
      " 7   units_sold       150149 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(5)\n",
      "memory usage: 10.3 MB\n"
     ]
    }
   ],
   "source": [
    "#Drop cols not needed:\n",
    "col_indices = [0]\n",
    "for col in range(len(col_indices)):\n",
    "    df = df.drop(df.columns.values[col_indices[col]], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76b13a7c-0f6c-42f1-8af6-daaf11aa96ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150149 entries, 0 to 150148\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   timestamp        150149 non-null  datetime64[ns]\n",
      " 1   store_id         150149 non-null  int64         \n",
      " 2   sku_id           150149 non-null  int64         \n",
      " 3   total_price      150149 non-null  float64       \n",
      " 4   base_price       150149 non-null  float64       \n",
      " 5   is_featured_sku  150149 non-null  int64         \n",
      " 6   is_display_sku   150149 non-null  int64         \n",
      " 7   units_sold       150149 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(5)\n",
      "memory usage: 10.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.index = np.arange(0, len(df))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c1ca050-c729-4e6e-9a94-0210b342c7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>store_id</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>total_price</th>\n",
       "      <th>base_price</th>\n",
       "      <th>is_featured_sku</th>\n",
       "      <th>is_display_sku</th>\n",
       "      <th>units_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9984</td>\n",
       "      <td>679023</td>\n",
       "      <td>180.2625</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9954</td>\n",
       "      <td>245338</td>\n",
       "      <td>469.5375</td>\n",
       "      <td>469.5375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9984</td>\n",
       "      <td>222087</td>\n",
       "      <td>227.2875</td>\n",
       "      <td>227.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9984</td>\n",
       "      <td>245338</td>\n",
       "      <td>469.5375</td>\n",
       "      <td>469.5375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9984</td>\n",
       "      <td>223153</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  store_id  sku_id  total_price  base_price  is_featured_sku  \\\n",
       "0 2011-01-08      9984  679023     180.2625    213.0375                0   \n",
       "1 2011-01-08      9954  245338     469.5375    469.5375                0   \n",
       "2 2011-01-08      9984  222087     227.2875    227.2875                0   \n",
       "3 2011-01-08      9984  245338     469.5375    469.5375                0   \n",
       "4 2011-01-08      9984  223153     213.0375    213.0375                0   \n",
       "\n",
       "   is_display_sku  units_sold  \n",
       "0               0          21  \n",
       "1               0           9  \n",
       "2               0          38  \n",
       "3               0          10  \n",
       "4               0          14  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d600b82b-28d0-4d1f-aa1f-7dffa465fe33",
   "metadata": {},
   "source": [
    "How many stores and products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88b101a8-194a-4505-b38d-264baa257a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9984, 9954, 9961, 9890, 9909, 9879, 9881, 9880, 9731, 9876, 9872, 9809, 9845, 9823, 9837, 9745, 9789, 9813, 9770, 9456, 9713, 9680, 9611, 9700, 9613, 9632, 9532, 9672, 9578, 9498, 9479, 9490, 9481, 9436, 9432, 9430, 9439, 9425, 9371, 9442, 8091, 9281, 9328, 9273, 9279, 9190, 9250, 9221, 8869, 9164, 9178, 9147, 9132, 9112, 9092, 9043, 8991, 9001, 8911, 8562, 8400, 8438, 8555, 8422, 8317, 8398, 8319, 8392, 8218, 8121, 8222, 8023, 8058, 8095, 8063, 8094]\n",
      "Stores:  76\n",
      "[679023, 245338, 222087, 223153, 223245, 222765, 547934, 378934, 219029, 216418, 219009, 217390, 216233, 216425, 320485, 300021, 245387, 216419, 398721, 217217, 217777, 219844, 600934, 673209, 327492, 300291, 546789, 545621]\n",
      "Products:  28\n"
     ]
    }
   ],
   "source": [
    "col_indices = [1, 2]\n",
    "lists_unique_entries = []\n",
    "for col in range(len(col_indices)):\n",
    "    entry_list = df[df.columns.values[col_indices[col]]]\n",
    "    # #How many elements?\n",
    "    # print('Elem after:' + ' ' + str(len(entry_list)))\n",
    "    # print('')\n",
    "    #Find unique members of the list:\n",
    "    found_list = []\n",
    "    unique_list = []\n",
    "    entry = []\n",
    "    entry_list_length = len(entry_list)\n",
    "    for i in range(entry_list_length):\n",
    "        entry = entry_list[i]\n",
    "        if entry not in found_list:\n",
    "            unique_list.append(entry)\n",
    "            found_list.append(entry)\n",
    "    lists_unique_entries.append(unique_list)\n",
    "print(lists_unique_entries[0])\n",
    "print('Stores: ', len(lists_unique_entries[0]))\n",
    "print(lists_unique_entries[1])\n",
    "print('Products: ', len(lists_unique_entries[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43afbe-f0a7-4a08-85fa-16421c2952df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c6f6376-a3d6-489d-88ba-ad32b8530732",
   "metadata": {},
   "source": [
    "Multiple product sales, sales prices, base prices recorded in time series for each timestamp - panel data:     \n",
    "Bin the time series for all units, ignoring any temporal ordering within the bin input values, with equal bin size in timestamps/time for all units (1); use median over mean (median more robust to outliers if bin data distribution not symmetric (2); if bin data distribution symmetric, mean = median, so would be using median (3) if use mean in this case - instead use median for all)    \n",
    "^(1) - https://stats.stackexchange.com/questions/129900/machine-learning-algorithms-for-panel-data        \n",
    "Accessed 09/06/2024    \n",
    "^(2) - Statistics: Unlocking the Power of Data (Robin H. Lock, Patti Frazer Lock, Kari Lock Morgan, Eric F. Lock, Dennis F. Lock, 2021)   \n",
    "Accessed 08/12/2023    \n",
    "^(3) - https://online.stat.psu.edu/stat200/lesson/2/2.2/2.2.4/2.2.4.1    \n",
    "Accessed 13/06/2024   \n",
    "\n",
    "For EDA consider median total_price, base_price, units_sold, and measures percent_featured and percent_display, for all products in all stores for each timestamp:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c849744b-7b51-4eab-b696-3d5eb4d13b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Start!\n",
      "secs:  134.64049577713013\n",
      "min:  2.244008262952169\n",
      "   timestamp  median_total_price  median_base_price  median_units_sold  \\\n",
      "0 2011-01-08            205.9125           205.9125               28.0   \n",
      "1 2011-01-17            190.2375           205.9125               38.0   \n",
      "2 2011-01-24            190.2375           205.9125               37.0   \n",
      "3 2011-01-31            210.1875           210.9000               33.0   \n",
      "4 2011-02-05            210.9000           211.6125               31.0   \n",
      "\n",
      "   percent_featured  percent_display  \n",
      "0          0.066667         0.077922  \n",
      "1          0.189610         0.163636  \n",
      "2          0.274459         0.195671  \n",
      "3          0.010390         0.096104  \n",
      "4          0.000000         0.089177  \n"
     ]
    }
   ],
   "source": [
    "from warnings import simplefilter\n",
    "import statistics\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "#^https://stackoverflow.com/questions/68292862/performancewarning-dataframe-is-highly-fragmented-this-is-usually-the-result-o\n",
    "#Accessed 08/06/2024)\n",
    "\n",
    "#Get unique timestamps:\n",
    "df_col = df[df.columns.values[0]]\n",
    "type_list = []\n",
    "for i in df_col.index:\n",
    "    entry = df_col[i]\n",
    "    try:\n",
    "        found_type = str(entry)\n",
    "        type_list.append(entry)\n",
    "    except:\n",
    "        pass\n",
    "# #How many elements?\n",
    "# print('Elem after:' + ' ' + str(len(type_list)))\n",
    "# print('')\n",
    "#Find unique members of the list:\n",
    "found_list = []\n",
    "unique_in_type_list = []\n",
    "entry = []\n",
    "type_list_length = len(type_list)\n",
    "for i in range(type_list_length):\n",
    "    entry = type_list[i]\n",
    "    if entry not in found_list:\n",
    "        unique_in_type_list.append(entry)\n",
    "        found_list.append(entry)\n",
    "        \n",
    "#Make EDA df:\n",
    "d = {}\n",
    "col_list = ['timestamp','total_price', 'base_price', 'units_sold']\n",
    "col = 0\n",
    "while col == 0:\n",
    "    d[(col_list[col])] = ([float(0)] * len(unique_in_type_list))\n",
    "    col += 1\n",
    "col = 1\n",
    "while col < 4:\n",
    "    d[('median_'+ col_list[col])] = ([float(0)] * len(unique_in_type_list))\n",
    "    col += 1\n",
    "col = 4\n",
    "while col < 5:\n",
    "    d['percent_featured'] = ([float(0)] * len(unique_in_type_list))\n",
    "    col += 1\n",
    "col = 5\n",
    "while col < 6:\n",
    "    d['percent_display'] = ([float(0)] * len(unique_in_type_list))\n",
    "    col += 1\n",
    "eda_ts_df = pd.DataFrame(data=d)\n",
    "eda_ts_df['timestamp'] = pd.to_datetime(eda_ts_df['timestamp'], format='mixed')\n",
    "#^https://saturncloud.io/blog/convert-pandas-column-to-datetime-a-guide/#:~:text=To%20convert%20a%20pandas%20column,new%20column%20with%20datetime%20values.\n",
    "#Accessed 06/06/2024\n",
    "for timestamp in range(len(unique_in_type_list)):\n",
    "    entry = unique_in_type_list[timestamp]\n",
    "    eda_ts_df[eda_ts_df.columns.values[0]][timestamp] = entry\n",
    "eda_ts_df['timestamp'] = pd.to_datetime(eda_ts_df['timestamp'], format='mixed')\n",
    "#^https://saturncloud.io/blog/convert-pandas-column-to-datetime-a-guide/#:~:text=To%20convert%20a%20pandas%20column,new%20column%20with%20datetime%20values.\n",
    "#Accessed 06/06/2024\n",
    "eda_ts_df = eda_ts_df.sort_values(by='timestamp')\n",
    "#^https://blog.hubspot.com/website/pandas-sortby#:~:text=Pandas%20Sort%20by%20Column&text=Sorting%20data%20within%20a%20dataframe,the%20values%20in%20descending%20order.\n",
    "#Accessed 05/06/2024\n",
    "print(ptypes.is_datetime64_dtype(eda_ts_df['timestamp']))\n",
    "#^https://stackoverflow.com/questions/25043620/correct-way-to-check-if-pandas-dataframe-index-is-a-certain-type-datetimeindex\n",
    "#Accessed 06/06/2024\n",
    "start = time.time()\n",
    "print('Start!')\n",
    "for timestamp in range(len(unique_in_type_list)):\n",
    "    sales_price_list_per_ts = []\n",
    "    base_price_list_per_ts = []\n",
    "    units_sold_list_per_ts = []\n",
    "    is_featured_list_per_ts = []\n",
    "    is_display_list_per_ts = []\n",
    "    for row in df.index:\n",
    "        if df['timestamp'][row] == eda_ts_df['timestamp'][timestamp]:\n",
    "            sales_price_list_per_ts.append(df['total_price'][row])\n",
    "            base_price_list_per_ts.append(df['base_price'][row])\n",
    "            units_sold_list_per_ts.append(df['units_sold'][row])\n",
    "            is_featured_list_per_ts.append(df['is_featured_sku'][row])\n",
    "            is_display_list_per_ts.append(df['is_display_sku'][row])\n",
    "    median_sales_price_per_ts = statistics.median(sales_price_list_per_ts)\n",
    "    median_base_price_per_ts = statistics.median(base_price_list_per_ts)\n",
    "    median_units_sold_per_ts = statistics.median(units_sold_list_per_ts)\n",
    "    \n",
    "    #can't use mode or median as instances of is_featured_sku or is_display_sku can be too \n",
    "    #infrequent to detect the existing featuring or displaying in this way in binning multiple retailings of an \n",
    "    #individual product in all\n",
    "    #the different stores per timestamp - use mean; as is_featured count / all product observations per timestamp,\n",
    "    #is_display count / all product observations per timestamp\n",
    "    #Measure of how much featuring a product/displaying it was emphasised at that timestamp - for EDA\n",
    "    #considering all products in all stores per timestamp so measure of how much featuring \n",
    "    #products/displaying them was emphasised at that timestamp for all the products considered in all\n",
    "    #the stores considered\n",
    "\n",
    "    #Use this rather than sum because describes no of values in bin as well as no featured, whereas sum does not; \n",
    "    #as mean ok because keep outliers in potentially skewed bin input value distributions (which as discrete \n",
    "    #distributions can of course be skewed and have a mean) by Grubbs 1969 definition of an outlier (1), \n",
    "    #because after considering the cause of the outliers and obviously eliminating errors, if trying to model a \n",
    "    #population that includes these outliers, it is important to include them, as they are part of the population (2)\n",
    "    #(1) - Module 12, IC PCDA: ‘Required discussion 12.3: Anomaly detection resources’ - Harry Bakhshi. Accessed \n",
    "    #18/05/2024.\n",
    "    #(2) - Module 12, IC PCDA: 'Mini-lesson 12.2: Consequences of removing outliers'. Accessed 09/06/2024\n",
    "    \n",
    "    percent_featured_per_ts = sum(is_featured_list_per_ts) / len(is_featured_list_per_ts)\n",
    "    percent_display_per_ts = sum(is_display_list_per_ts) / len(is_display_list_per_ts) \n",
    "    eda_ts_df['median_total_price'][timestamp] = median_sales_price_per_ts\n",
    "    eda_ts_df['median_base_price'][timestamp] = median_base_price_per_ts\n",
    "    eda_ts_df['median_units_sold'][timestamp] = median_units_sold_per_ts\n",
    "    eda_ts_df['percent_featured'][timestamp] = percent_featured_per_ts\n",
    "    eda_ts_df['percent_display'][timestamp] = percent_display_per_ts\n",
    "end = time.time()\n",
    "print('secs: ', end - start) # time in seconds\n",
    "print('min: ', (end - start)/60) # time in min\n",
    "print(eda_ts_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "638fe729-ade2-425a-8a6f-eaaf14a3a615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>median_total_price</th>\n",
       "      <th>median_base_price</th>\n",
       "      <th>median_units_sold</th>\n",
       "      <th>percent_featured</th>\n",
       "      <th>percent_display</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.077922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>190.2375</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.189610</td>\n",
       "      <td>0.163636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>190.2375</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.274459</td>\n",
       "      <td>0.195671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>210.1875</td>\n",
       "      <td>210.9000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>0.096104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>210.9000</td>\n",
       "      <td>211.6125</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  median_total_price  median_base_price  median_units_sold  \\\n",
       "0 2011-01-08            205.9125           205.9125               28.0   \n",
       "1 2011-01-17            190.2375           205.9125               38.0   \n",
       "2 2011-01-24            190.2375           205.9125               37.0   \n",
       "3 2011-01-31            210.1875           210.9000               33.0   \n",
       "4 2011-02-05            210.9000           211.6125               31.0   \n",
       "\n",
       "   percent_featured  percent_display  \n",
       "0          0.066667         0.077922  \n",
       "1          0.189610         0.163636  \n",
       "2          0.274459         0.195671  \n",
       "3          0.010390         0.096104  \n",
       "4          0.000000         0.089177  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_ts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0248e4a-af78-4440-81e3-180e1a38ecfe",
   "metadata": {},
   "source": [
    "Bin data for time series - 1 value for each product variable per timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "85d4a933-97a1-436b-be41-19a6cbdb0e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n",
      "secs:  17648.841105222702\n",
      "min:  294.1473517537117\n"
     ]
    }
   ],
   "source": [
    "ts_df = eda_ts_df.copy()\n",
    "col_list = ['timestamp','total_price', 'base_price', 'units_sold', 'percent_featured', 'percent_display']\n",
    "col_list_indices = [1, 2, 3, 4, 5]\n",
    "col = 0\n",
    "while col < 3:\n",
    "    for product in range(len(lists_unique_entries[1])):\n",
    "        entry = str(lists_unique_entries[1][product]) + ('median_' + col_list[col_list_indices[col]])\n",
    "        ts_df.loc[:, entry] = pd.Series(np.zeros(len(unique_in_type_list)), index=ts_df.index)\n",
    "    col += 1\n",
    "col = 3\n",
    "while col < 4:\n",
    "    for product in range(len(lists_unique_entries[1])):\n",
    "        entry = str(lists_unique_entries[1][product]) + ('percent_featured')\n",
    "        ts_df.loc[:, entry] = pd.Series(np.zeros(len(unique_in_type_list)), index=ts_df.index)\n",
    "    col += 1\n",
    "while col < 5:\n",
    "    for product in range(len(lists_unique_entries[1])):\n",
    "        entry = str(lists_unique_entries[1][product]) + ('percent_display')\n",
    "        ts_df.loc[:, entry] = pd.Series(np.zeros(len(unique_in_type_list)), index=ts_df.index)\n",
    "    col += 1\n",
    "drop_list = ['median_total_price', 'median_base_price', 'median_units_sold', 'percent_featured', 'percent_display']\n",
    "ts_df = ts_df.drop(drop_list, axis=1)\n",
    "# ts_df.head()\n",
    "col_list = ['total_price', 'base_price', 'units_sold', 'is_featured_sku', 'is_display_sku']\n",
    "col_list_2 = ['total_price', 'base_price', 'units_sold', 'percent_featured', 'percent_display']\n",
    "start = time.time()\n",
    "print('Start!')\n",
    "for product in range(len(lists_unique_entries[1])):\n",
    "    # for timestamp in range(1):\n",
    "    for timestamp in range(len(unique_in_type_list)):\n",
    "        for col in range(len(col_list)):\n",
    "            #Create lists for central tendency measures - see lower code\n",
    "            sales_price_list_per_ts_per_product = []\n",
    "            base_price_list_per_ts_per_product = []\n",
    "            units_sold_list_per_ts_per_product = []\n",
    "            is_featured_list_per_ts_per_product = []\n",
    "            is_display_list_per_ts_per_product = []\n",
    "            for row in df.index:\n",
    "                if df['timestamp'][row] == ts_df['timestamp'][timestamp]:\n",
    "                    if df['sku_id'][row] == int(str(lists_unique_entries[1][product])):\n",
    "                        #Append to lists for for central tendency measures - see lower code\n",
    "                        if col_list[col] == 'total_price':\n",
    "                            sales_price_list_per_ts_per_product.append(df[col_list[col]][row])\n",
    "                        if col_list[col] == 'base_price':\n",
    "                            base_price_list_per_ts_per_product.append(df[col_list[col]][row])\n",
    "                        if col_list[col] == 'units_sold':\n",
    "                            units_sold_list_per_ts_per_product.append(df[col_list[col]][row])\n",
    "                        if col_list[col] == 'is_featured_sku':\n",
    "                            is_featured_list_per_ts_per_product.append(df[col_list[col]][row])\n",
    "                        if col_list[col] == 'is_display_sku':\n",
    "                            is_display_list_per_ts_per_product.append(df[col_list[col]][row])\n",
    "            #In case sales of the same product in different stores at the timestamp take the median for the product at that timestamp:\n",
    "            if col_list[col] == 'total_price':\n",
    "                ts_df[(str(lists_unique_entries[1][product]) + ('median_' + col_list[col]))][timestamp] = statistics.median(sales_price_list_per_ts_per_product)  \n",
    "            if col_list[col] == 'base_price':\n",
    "                ts_df[(str(lists_unique_entries[1][product]) + ('median_' + col_list[col]))][timestamp] = statistics.median(base_price_list_per_ts_per_product)  \n",
    "            if col_list[col] == 'units_sold':\n",
    "                ts_df[(str(lists_unique_entries[1][product]) + ('median_' + col_list[col]))][timestamp] = statistics.median(units_sold_list_per_ts_per_product)  \n",
    "            \n",
    "            #can't use mode or median as instances of is_featured_sku or is_display_sku can be too \n",
    "            #infrequent to detect the existing featuring or displaying in this way in binning multiple retailings of an individual \n",
    "            #product in all\n",
    "            #the different stores per timestamp - use mean; as is_featured count / all product observations per timestamp,\n",
    "            #is_display count / all product observations per timestamp\n",
    "            #Measure of how much featuring a product/displaying it was emphasised at that timestamp\n",
    "\n",
    "            #Use this rather than sum because describes no of values in bin as well as no featured, whereas sum does not; \n",
    "            #as mean ok because keep outliers in potentially skewed bin input value distributions (which as discrete \n",
    "            #distributions can of course be skewed and have a mean) by Grubbs 1969 definition of an outlier (1), \n",
    "            #because after considering the cause of the outliers and obviously eliminating errors, if trying to model a \n",
    "            #population that includes these outliers, it is important to include them, as they are part of the population (2)\n",
    "            #(1) - Module 12, IC PCDA: ‘Required discussion 12.3: Anomaly detection resources’ - Harry Bakhshi. Accessed \n",
    "            #18/05/2024.\n",
    "            #(2) - Module 12, IC PCDA: 'Mini-lesson 12.2: Consequences of removing outliers'. Accessed 09/06/2024\n",
    "            \n",
    "            if col_list_2[col] == 'percent_featured':\n",
    "                ts_df[(str(lists_unique_entries[1][product]) + ('percent_featured'))][timestamp] = sum(is_featured_list_per_ts_per_product) / len(is_featured_list_per_ts_per_product)  \n",
    "            if col_list_2[col] == 'percent_display':\n",
    "                ts_df[(str(lists_unique_entries[1][product]) + ('percent_display'))][timestamp] = sum(is_display_list_per_ts_per_product) / len(is_display_list_per_ts_per_product)\n",
    "end = time.time()\n",
    "print('secs: ', end - start) # time in seconds\n",
    "print('min: ', (end - start)/60) # time in min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "11816c8a-99f1-41bb-989b-e706121c09b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Started at --:--, takes approx. 5hrs 10 min (2.38 min per timestamp, 130 ts's), Expect done at\n",
    "#--:-- - took 295 mins last time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc13fc-71ae-46c6-8e13-d95a40b05965",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e8701-e653-423b-814f-170f55d4e01a",
   "metadata": {},
   "source": [
    "#### This is how you would do it for making a time series variable per store per product (10640 variables with 130 timestamp values, using parallel computing, with ability to run on either Jupyter or e.g. Spyder (offline) and ability to pause/resume/quit execution). Did it to show possible\n",
    "\n",
    "- would find seasonality, find and treat outliers, then check forecastability and drop variables not forecastable (using same code as for notebooks 4, 5, 6, 7)\n",
    "- For this data:   \n",
    "    Started at 17:05 21st Jun, expect take approx. 72.6 hrs (3.03 days) (33.52 min per timestamp)  \n",
    "    Expected done at 17:43 on Monday 24nd Jun   \n",
    "    Finished at 11:16 Mon 1 Jul   \n",
    "    secs:  843078.8388700485   \n",
    "    min:  14051.313981167476   \n",
    "    time for 130 timestamps in hrs:  234.18856635279127   \n",
    "    time for 130 timestamps in days:  9.757856931366302   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1615b-f03d-43ca-a4cf-16191fadd916",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea873ceb-aff7-4683-8d92-f857e0d2d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from janatahack_panel_data_defs import panel_to_ts_janatahack\n",
    "# #^https://stackoverflow.com/questions/41385708/multiprocessing-example-giving-attributeerror\n",
    "# #Accessed 15/06/2024\n",
    "# from warnings import simplefilter\n",
    "# simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "# #^https://stackoverflow.com/questions/68292862/performancewarning-dataframe-is-highly-fragmented-this-is-usually-the-result-o\n",
    "# #Accessed 08/06/2024)\n",
    "\n",
    "# file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_eda_ts.pik'\n",
    "# # with open(file, 'wb') as f:\n",
    "# #     pickle.dump(eda_ts_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      eda_ts_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "# file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_lists_unique_entries.pik'\n",
    "# # with open(file, 'wb') as f:\n",
    "# #     pickle.dump(lists_unique_entries, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      lists_unique_entries = pickle.load(f) #load pickle file 'file' into variable\n",
    "    \n",
    "# ts_df = eda_ts_df.copy()\n",
    "# col_list = ['timestamp','total_price', 'base_price', 'units_sold', 'percent_featured', 'percent_display']\n",
    "# col_list_indices = [1, 2, 3, 4, 5]\n",
    "# col = 0\n",
    "# store_product_list = []\n",
    "# while col < 3:\n",
    "#     for store in range(len(lists_unique_entries[0])):    \n",
    "#         for product in range(len(lists_unique_entries[1])):\n",
    "#             entry = str(lists_unique_entries[0][store]) + '_' + str(lists_unique_entries[1][product]) + ('median_' + col_list[col_list_indices[col]])\n",
    "#             store_product_list.append(entry)\n",
    "#             ts_df.loc[:, entry] = pd.Series(np.zeros(len(ts_df)), index=ts_df.index)\n",
    "#     col += 1\n",
    "# col = 3\n",
    "# while col < 4:\n",
    "#     for store in range(len(lists_unique_entries[0])):  \n",
    "#         for product in range(len(lists_unique_entries[1])):\n",
    "#             entry = str(lists_unique_entries[0][store]) + '_' + str(lists_unique_entries[1][product]) + ('percent_featured')\n",
    "#             store_product_list.append(entry)\n",
    "#             ts_df.loc[:, entry] = pd.Series(np.zeros(len(ts_df)), index=ts_df.index)\n",
    "#     col += 1\n",
    "# while col < 5:\n",
    "#     for store in range(len(lists_unique_entries[0])):  \n",
    "#         for product in range(len(lists_unique_entries[1])):\n",
    "#             entry = str(lists_unique_entries[0][store]) + '_' + str(lists_unique_entries[1][product]) + ('percent_display')\n",
    "#             store_product_list.append(entry)\n",
    "#             ts_df.loc[:, entry] = pd.Series(np.zeros(len(ts_df)), index=ts_df.index)\n",
    "#     col += 1\n",
    "# drop_list = ['median_total_price', 'median_base_price', 'median_units_sold', 'percent_featured', 'percent_display']\n",
    "# ts_df = ts_df.drop(drop_list, axis=1)\n",
    "# col_list = ['total_price', 'base_price', 'units_sold', 'is_featured_sku', 'is_display_sku']\n",
    "# col_list_2 = ['total_price', 'base_price', 'units_sold', 'percent_featured', 'percent_display']\n",
    "\n",
    "# file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_store_product_list.pik'\n",
    "# with open(file, 'wb') as f:\n",
    "#     pickle.dump(store_product_list, f) #write df to .pik file on disk\n",
    "# # with open(file, 'rb') as f:\n",
    "# #      store_product_list = pickle.load(f) #load pickle file 'file' into variable\n",
    "# _ts_df = ts_df\n",
    "# file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data__ts_df.pik'\n",
    "# with open(file, 'wb') as f:\n",
    "#     pickle.dump(_ts_df, f) #write df to .pik file on disk\n",
    "# # with open(file, 'rb') as f:\n",
    "# #      _ts_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "# file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_df.pik'\n",
    "# # with open(file, 'wb') as f:\n",
    "# #     pickle.dump(df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#       df = pickle.load(f) #load pickle file 'file' into variable\n",
    "\n",
    "# import multiprocessing \n",
    "# # from multiprocessing import set_start_method\n",
    "# # set_start_method(\"spawn\")\n",
    "# from multiprocessing import Pool\n",
    "# #^https://python.omics.wiki/multiprocessing_map/multiprocessing_partial_function_multiple_arguments\n",
    "# #^https://www.sitepoint.com/python-multiprocessing-parallel-programming/\n",
    "# #Both accessed 15/06/2024\n",
    "\n",
    "# # sec_list = []\n",
    "\n",
    "# file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data__ts_df.pik'\n",
    "# # with open(file, 'wb') as f:\n",
    "# #     pickle.dump(ts_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#       ts_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "      \n",
    "# print('Expected time in hrs: ', ((1.5121979713439941/8)*10640*130)/(60*60))\n",
    "# print('Expected time in days: ', ((1.5121979713439941/8)*10640*130)/(60*60*24))\n",
    "# size = int(len(store_product_list))\n",
    "# # size = int(16)\n",
    "# chunksize = int(8)\n",
    "# task_denom = 8 #no of simultaneous processes to do safely possible, can't be greater than size\n",
    "# result = math.floor(size / task_denom)\n",
    "# #^https://www.w3schools.com/python/ref_math_floor.asp#:~:text=The%20math.,necessary%2C%20and%20returns%20the%20result.\n",
    "# #Accessed 06/07/2024\n",
    "# remainder = size % task_denom\n",
    "# #^https://runestone.academy/ns/books/published/thinkcspy/SimplePythonData/OperatorsandOperands.html#\n",
    "# #Accessed 06/07/2024\n",
    "# tasks = result + math.ceil(remainder/task_denom)\n",
    "# print(tasks)\n",
    "# # chunksize = int(size/8)\n",
    "# print('Start!')\n",
    "# if __name__ == \"__main__\":\n",
    "#     with Pool(processes=8) as pool: #8 cores on my laptop\n",
    "#         start1 = time.time()\n",
    "#         step = 0\n",
    "#         step_count = 0\n",
    "#         ts_df_temp = ts_df.drop(ts_df.columns.values[1:], axis=1)\n",
    "#         while step_count < tasks:\n",
    "#             if step_count == tasks:\n",
    "#                 break\n",
    "#             #^https://www.geeksforgeeks.org/how-to-use-while-true-in-python/\n",
    "#             #Accessed 20/06/2024\n",
    "#             for ele in range(int(len(list(range(len(store_product_list)))[:size])/task_denom)):\n",
    "#                 try:\n",
    "#                     map_list = list(pool.map(panel_to_ts_janatahack, list(range(len(store_product_list)))[(ele + step):(ele + step + task_denom)], chunksize=chunksize))        \n",
    "#                     #^https://python.omics.wiki/multiprocessing_map/multiprocessing_partial_function_multiple_arguments\n",
    "#                     #^https://www.sitepoint.com/python-multiprocessing-parallel-programming/\n",
    "#                     #Both accessed 15/06/2024\n",
    "#                     #^https://stackoverflow.com/questions/1303347/getting-a-map-to-return-a-list-in-python-3-x\n",
    "#                     #^https://stackoverflow.com/questions/58841709/how-to-store-multiple-pandas-dataframes-together\n",
    "#                     #^https://python.omics.wiki/multiprocessing_map/multiprocessing_partial_function_multiple_arguments\n",
    "#                     #^https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool\n",
    "#                     #All accessed 15/06/2024\n",
    "#                     # start2 = time.time()\n",
    "#                     for item in range(len(map_list)):\n",
    "#                         ts_df_temp_2 = map_list[item]\n",
    "#                         ts_df_temp = pd.merge(\n",
    "#                             ts_df_temp, \n",
    "#                             ts_df_temp_2, \n",
    "#                             left_index=True, \n",
    "#                             right_index=True\n",
    "#                         )\n",
    "#                     step = step + (task_denom - 1)\n",
    "#                     step_count += 1\n",
    "#                     # end2 = time.time()\n",
    "#                 except KeyboardInterrupt:\n",
    "#                     try:\n",
    "#                         print('\\nPausing...  (Hit ENTER to continue, type quit to exit.)')\n",
    "#                         response = input()\n",
    "#                         if response == 'quit':\n",
    "#                             import sys\n",
    "#                             sys.exit()\n",
    "#                         else:\n",
    "#                             print('Resuming...')\n",
    "#                     except KeyboardInterrupt:\n",
    "#                         print('Resuming...')\n",
    "#                         continue\n",
    "#                 #^https://stackoverflow.com/questions/62779180/pandas-merge-unexpectedly-produces-suffixes\n",
    "#                 #Accessed 15/06/2024\n",
    "#                 #^https://stackoverflow.com/questions/7180914/pause-resume-a-python-script-in-middle\n",
    "#                 #^https://stackoverflow.com/questions/73663/how-do-i-terminate-a-script\n",
    "#                 #Accessed 20/06/2024\n",
    "#         end1 = time.time()\n",
    "#         # sec_list.append((end1 - start1))\n",
    "#         print('secs: ', (end1 - start1)) # time in seconds\n",
    "#         print('min: ', (end1 - start1)/60) # time in min\n",
    "#         print('time for 130 timestamps in hrs: ', (end1 - start1)/(60*60)) # time in hrs\n",
    "#         print('time for 130 timestamps in days: ', (end1 - start1)/(60*60*24)) # time in days       \n",
    "#     # exiting the 'with'-block has stopped the pool\n",
    "#     print(\"Now the pool is closed and no longer available\")\n",
    "#     pool.terminate()\n",
    "# ts_df = ts_df_temp\n",
    "# print(ts_df['9984_679023median_total_price'][100:])\n",
    "# print(ts_df['9984_245338median_total_price'][0:10])\n",
    "# #Pickle multivariate timeseries:\n",
    "# file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_ts_df_parallel.pik'\n",
    "# # with open(file, 'wb') as f:\n",
    "# #     pickle.dump(ts_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#       ts_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "# file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_ts_df_parallel_2.pik'\n",
    "# # with open(file, 'wb') as f:\n",
    "# #     pickle.dump(ts_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#       ts_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "# print(ts_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f518331-178d-4ed4-9c12-a417da4261f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle multivariate timeseries:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_ts_df_parallel.pik'\n",
    "# with open(file, 'wb') as f:\n",
    "#     pickle.dump(ts_df_2, f) #write df to .pik file on disk\n",
    "with open(file, 'rb') as f:\n",
    "     ts_df_2 = pickle.load(f) #load pickle file 'file' into variable\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_ts_df_parallel_2.pik'\n",
    "# with open(file, 'wb') as f:\n",
    "#     pickle.dump(ts_df_2, f) #write df to .pik file on disk\n",
    "with open(file, 'rb') as f:\n",
    "      ts_df_2 = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315ae25-4b7b-49cd-a1c3-821b666ef445",
   "metadata": {},
   "source": [
    "Test conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213df8ef-93bc-40dc-b4f2-4ae8b33e68c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18955/2221620203.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_2 = df.copy()[df.copy()['sku_id'] == 679023][df.copy()['store_id'] == 9984]\n"
     ]
    }
   ],
   "source": [
    "df_2 = df.copy()[df.copy()['sku_id'] == 679023][df.copy()['store_id'] == 9984]\n",
    "df_2.index = np.arange(0, len(df_2))\n",
    "df_2.head(50)\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20777f54-4a79-4868-9c04-8a49fa02350e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.2625"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_test_list = [] \n",
    "for row in range(1):\n",
    "    median_test_list.append(df_2['total_price'][row])\n",
    "_9984_679023median_total_price_ts_1 = statistics.median(median_test_list)  \n",
    "_9984_679023median_total_price_ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64000a9a-3977-4ce4-a188-01e14eadc8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213.0375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_test_list = [] \n",
    "for row in range(1):\n",
    "    median_test_list.append(df_2['base_price'][row])\n",
    "_9984_679023median_base_price_ts_1 = statistics.median(median_test_list) \n",
    "_9984_679023median_base_price_ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf02651-a906-4ad5-9856-13f3904ef072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_test_list = [] \n",
    "for row in range(1):\n",
    "    median_test_list.append(df_2['units_sold'][row])\n",
    "_9984_679023median_units_sold_ts_1 = statistics.median(median_test_list)\n",
    "_9984_679023median_units_sold_ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27c894f6-c177-4d3f-9aae-90ee77d9990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_list = [] \n",
    "for row in range(1):\n",
    "    mean_test_list.append(df_2['is_featured_sku'][row])\n",
    "_9984_679023percent_featured_ts_1 = sum(mean_test_list) / len(mean_test_list)\n",
    "_9984_679023percent_featured_ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "639f356d-635e-4958-8f69-1371cc53b9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_list = [] \n",
    "for row in range(1):\n",
    "    mean_test_list.append(df_2['is_display_sku'][row])\n",
    "_9984_679023percent_display_ts_1 = sum(mean_test_list) / len(mean_test_list)\n",
    "_9984_679023percent_display_ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73b0534d-9a58-4c2f-8d00-b9e492dd1957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213.0375"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df_2['9984_679023median_base_price'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db6b735f-f65b-4bdb-baa1-a168aaac7116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df_2['9984_679023median_units_sold'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "685b5d25-b7f2-4752-b275-40cba953fb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df_2['9984_679023percent_featured'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d2cadbf-e5cd-4dd6-876a-bb5503f65625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df_2['9984_679023percent_display'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4468841-f1a3-46f1-bd10-d04414494393",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "48ada008-ce93-44db-89ee-3f953a498da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130 entries, 0 to 129\n",
      "Columns: 141 entries, timestamp to 545621percent_display\n",
      "dtypes: datetime64[ns](1), float64(140)\n",
      "memory usage: 143.3 KB\n"
     ]
    }
   ],
   "source": [
    "ts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c8795be8-3228-436a-84f6-f33f753ffa43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>679023median_total_price</th>\n",
       "      <th>245338median_total_price</th>\n",
       "      <th>222087median_total_price</th>\n",
       "      <th>223153median_total_price</th>\n",
       "      <th>223245median_total_price</th>\n",
       "      <th>222765median_total_price</th>\n",
       "      <th>547934median_total_price</th>\n",
       "      <th>378934median_total_price</th>\n",
       "      <th>219029median_total_price</th>\n",
       "      <th>...</th>\n",
       "      <th>398721percent_display</th>\n",
       "      <th>217217percent_display</th>\n",
       "      <th>217777percent_display</th>\n",
       "      <th>219844percent_display</th>\n",
       "      <th>600934percent_display</th>\n",
       "      <th>673209percent_display</th>\n",
       "      <th>327492percent_display</th>\n",
       "      <th>300291percent_display</th>\n",
       "      <th>546789percent_display</th>\n",
       "      <th>545621percent_display</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>180.2625</td>\n",
       "      <td>469.5375</td>\n",
       "      <td>226.93125</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>195.225</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>312.7875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.7875</td>\n",
       "      <td>196.65000</td>\n",
       "      <td>190.2375</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>240.825</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>312.0750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  679023median_total_price  245338median_total_price  \\\n",
       "0 2011-01-08                  180.2625                  469.5375   \n",
       "1 2011-01-17                  178.1250                  426.7875   \n",
       "\n",
       "   222087median_total_price  223153median_total_price  \\\n",
       "0                 226.93125                  213.0375   \n",
       "1                 196.65000                  190.2375   \n",
       "\n",
       "   223245median_total_price  222765median_total_price  \\\n",
       "0                  205.2000                   195.225   \n",
       "1                  205.9125                   240.825   \n",
       "\n",
       "   547934median_total_price  378934median_total_price  \\\n",
       "0                  177.4125                  205.9125   \n",
       "1                  177.4125                  177.4125   \n",
       "\n",
       "   219029median_total_price  ...  398721percent_display  \\\n",
       "0                  312.7875  ...               0.055556   \n",
       "1                  312.0750  ...               0.444444   \n",
       "\n",
       "   217217percent_display  217777percent_display  219844percent_display  \\\n",
       "0               0.076923                   0.10               0.107143   \n",
       "1               0.230769                   0.15               0.321429   \n",
       "\n",
       "   600934percent_display  673209percent_display  327492percent_display  \\\n",
       "0               0.285714                    0.5                    0.0   \n",
       "1               0.000000                    0.0                    0.0   \n",
       "\n",
       "   300291percent_display  546789percent_display  545621percent_display  \n",
       "0               0.222222               0.571429                    0.0  \n",
       "1               0.000000               0.000000                    0.0  \n",
       "\n",
       "[2 rows x 141 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "817924b1-b1dd-4996-a0fd-b3666a315678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>store_id</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>total_price</th>\n",
       "      <th>base_price</th>\n",
       "      <th>is_featured_sku</th>\n",
       "      <th>is_display_sku</th>\n",
       "      <th>units_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9984</td>\n",
       "      <td>679023</td>\n",
       "      <td>180.2625</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9425</td>\n",
       "      <td>679023</td>\n",
       "      <td>180.9750</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9430</td>\n",
       "      <td>679023</td>\n",
       "      <td>193.0875</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9281</td>\n",
       "      <td>679023</td>\n",
       "      <td>186.6750</td>\n",
       "      <td>198.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>9092</td>\n",
       "      <td>679023</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>8869</td>\n",
       "      <td>679023</td>\n",
       "      <td>191.6625</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>8317</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.8375</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>8063</td>\n",
       "      <td>679023</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>8094</td>\n",
       "      <td>679023</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>8063</td>\n",
       "      <td>679023</td>\n",
       "      <td>183.1125</td>\n",
       "      <td>183.1125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>8094</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>8317</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>8869</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>9092</td>\n",
       "      <td>679023</td>\n",
       "      <td>182.4000</td>\n",
       "      <td>182.4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>9281</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>9430</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>9425</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>9984</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>9425</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>9430</td>\n",
       "      <td>679023</td>\n",
       "      <td>179.5500</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>9281</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>9984</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>9092</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>8869</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>8317</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>8063</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>8094</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>8063</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>8094</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>8317</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>9984</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>8869</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>9092</td>\n",
       "      <td>679023</td>\n",
       "      <td>182.4000</td>\n",
       "      <td>182.4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>9281</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>9430</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.8375</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>9425</td>\n",
       "      <td>679023</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>178.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>9425</td>\n",
       "      <td>679023</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>9430</td>\n",
       "      <td>679023</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>9281</td>\n",
       "      <td>679023</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>9984</td>\n",
       "      <td>679023</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>9092</td>\n",
       "      <td>679023</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>8869</td>\n",
       "      <td>679023</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>8317</td>\n",
       "      <td>679023</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>8063</td>\n",
       "      <td>679023</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>8094</td>\n",
       "      <td>679023</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>9984</td>\n",
       "      <td>679023</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>8063</td>\n",
       "      <td>679023</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>8094</td>\n",
       "      <td>679023</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>8317</td>\n",
       "      <td>679023</td>\n",
       "      <td>203.0625</td>\n",
       "      <td>203.0625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>8869</td>\n",
       "      <td>679023</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  store_id  sku_id  total_price  base_price  is_featured_sku  \\\n",
       "0  2011-01-08      9984  679023     180.2625    213.0375                0   \n",
       "1  2011-01-08      9425  679023     180.9750    213.0375                1   \n",
       "2  2011-01-08      9430  679023     193.0875    213.0375                0   \n",
       "3  2011-01-08      9281  679023     186.6750    198.0750                0   \n",
       "4  2011-01-08      9092  679023     177.4125    213.0375                1   \n",
       "5  2011-01-08      8869  679023     191.6625    213.0375                0   \n",
       "6  2011-01-08      8317  679023     178.8375    213.0375                1   \n",
       "7  2011-01-08      8063  679023     177.4125    213.0375                1   \n",
       "8  2011-01-08      8094  679023     177.4125    213.0375                0   \n",
       "9  2011-01-17      8063  679023     183.1125    183.1125                0   \n",
       "10 2011-01-17      8094  679023     178.1250    205.9125                0   \n",
       "11 2011-01-17      8317  679023     178.1250    178.1250                0   \n",
       "12 2011-01-17      8869  679023     178.1250    205.9125                0   \n",
       "13 2011-01-17      9092  679023     182.4000    182.4000                0   \n",
       "14 2011-01-17      9281  679023     178.1250    178.1250                0   \n",
       "15 2011-01-17      9430  679023     178.1250    205.9125                0   \n",
       "16 2011-01-17      9425  679023     178.1250    178.1250                0   \n",
       "17 2011-01-17      9984  679023     178.1250    178.1250                0   \n",
       "18 2011-01-24      9425  679023     178.1250    178.1250                0   \n",
       "19 2011-01-24      9430  679023     179.5500    205.9125                0   \n",
       "20 2011-01-24      9281  679023     178.1250    178.1250                0   \n",
       "21 2011-01-24      9984  679023     178.1250    178.1250                0   \n",
       "22 2011-01-24      9092  679023     178.1250    178.1250                0   \n",
       "23 2011-01-24      8869  679023     178.1250    205.9125                0   \n",
       "24 2011-01-24      8317  679023     178.1250    178.1250                0   \n",
       "25 2011-01-24      8063  679023     178.1250    178.1250                0   \n",
       "26 2011-01-24      8094  679023     178.1250    205.9125                0   \n",
       "27 2011-01-31      8063  679023     178.1250    178.1250                0   \n",
       "28 2011-01-31      8094  679023     178.1250    205.9125                0   \n",
       "29 2011-01-31      8317  679023     178.1250    178.1250                0   \n",
       "30 2011-01-31      9984  679023     178.1250    178.1250                0   \n",
       "31 2011-01-31      8869  679023     178.1250    205.9125                0   \n",
       "32 2011-01-31      9092  679023     182.4000    182.4000                0   \n",
       "33 2011-01-31      9281  679023     178.1250    178.1250                0   \n",
       "34 2011-01-31      9430  679023     178.8375    205.9125                0   \n",
       "35 2011-01-31      9425  679023     178.1250    178.1250                0   \n",
       "36 2011-02-05      9425  679023     205.9125    205.9125                0   \n",
       "37 2011-02-05      9430  679023     213.0375    213.0375                0   \n",
       "38 2011-02-05      9281  679023     205.9125    205.9125                0   \n",
       "39 2011-02-05      9984  679023     205.9125    205.9125                0   \n",
       "40 2011-02-05      9092  679023     205.9125    205.9125                0   \n",
       "41 2011-02-05      8869  679023     213.0375    213.0375                0   \n",
       "42 2011-02-05      8317  679023     205.9125    205.9125                0   \n",
       "43 2011-02-05      8063  679023     205.9125    205.9125                0   \n",
       "44 2011-02-05      8094  679023     205.9125    205.9125                0   \n",
       "45 2011-02-14      9984  679023     205.9125    205.9125                0   \n",
       "46 2011-02-14      8063  679023     205.9125    205.9125                0   \n",
       "47 2011-02-14      8094  679023     205.9125    205.9125                0   \n",
       "48 2011-02-14      8317  679023     203.0625    203.0625                0   \n",
       "49 2011-02-14      8869  679023     213.0375    213.0375                0   \n",
       "\n",
       "    is_display_sku  units_sold  \n",
       "0                0          21  \n",
       "1                1          17  \n",
       "2                1          28  \n",
       "3                1           5  \n",
       "4                1          26  \n",
       "5                1          38  \n",
       "6                0          31  \n",
       "7                0           5  \n",
       "8                1          25  \n",
       "9                0           8  \n",
       "10               0          10  \n",
       "11               0          15  \n",
       "12               1          28  \n",
       "13               0          10  \n",
       "14               0           8  \n",
       "15               1          25  \n",
       "16               0          13  \n",
       "17               0           4  \n",
       "18               0          10  \n",
       "19               1          38  \n",
       "20               1           3  \n",
       "21               0           8  \n",
       "22               0           8  \n",
       "23               1          34  \n",
       "24               0          23  \n",
       "25               0          11  \n",
       "26               0           8  \n",
       "27               0           9  \n",
       "28               0           4  \n",
       "29               0          23  \n",
       "30               0          10  \n",
       "31               1          23  \n",
       "32               0          10  \n",
       "33               0          10  \n",
       "34               1          43  \n",
       "35               0          17  \n",
       "36               0          20  \n",
       "37               0          17  \n",
       "38               1           7  \n",
       "39               1           3  \n",
       "40               0          11  \n",
       "41               1          18  \n",
       "42               0          23  \n",
       "43               1           6  \n",
       "44               0           4  \n",
       "45               0          12  \n",
       "46               0           4  \n",
       "47               0          12  \n",
       "48               0          31  \n",
       "49               0          12  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = df.copy()[df.copy()['sku_id'] == 679023]\n",
    "df_2.index = np.arange(0, len(df_2))\n",
    "df_2.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "45328392-4f7f-4551-9468-c667a58ac609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.2625"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_test_list = [] \n",
    "for row in range(9):\n",
    "    median_test_list.append(df_2['total_price'][row])\n",
    "_679023median_total_price_ts_1 = statistics.median(median_test_list)  \n",
    "_679023median_total_price_ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dea45885-e09a-4370-b90d-42ef8640b47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213.0375"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_test_list = [] \n",
    "for row in range(9):\n",
    "    median_test_list.append(df_2['base_price'][row])\n",
    "_679023median_base_price_ts_1 = statistics.median(median_test_list) \n",
    "_679023median_base_price_ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bdd24a61-2951-44c3-9a6a-06168cbf6646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_test_list = [] \n",
    "for row in range(9):\n",
    "    median_test_list.append(df_2['units_sold'][row])\n",
    "_679023median_units_sold_ts_1 = statistics.median(median_test_list)\n",
    "_679023median_units_sold_ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3b1638e1-66b5-4a82-b8af-6625dbe421bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_list = [] \n",
    "for row in range(9):\n",
    "    mean_test_list.append(df_2['is_featured_sku'][row])\n",
    "_679023percent_featured_ts_1 = sum(mean_test_list) / len(mean_test_list)\n",
    "_679023percent_featured_ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e55990ba-cf6a-4430-a96c-9d25bdd104de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_list = [] \n",
    "for row in range(9):\n",
    "    mean_test_list.append(df_2['is_display_sku'][row])\n",
    "_679023percent_display_ts_1 = sum(mean_test_list) / len(mean_test_list)\n",
    "_679023percent_display_ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9013a0a7-4c24-4cb7-ab1b-9d2889be49ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213.0375"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df['679023median_base_price'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2f90e5cb-5206-408c-af4e-dcd76921e031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df['679023median_units_sold'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "21d764a5-6d9c-483a-9d1d-904d1309fe07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df['679023percent_featured'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bcc5e32a-3b55-48ae-b428-49b95a0d9a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df['679023percent_display'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "90a92e1f-26a9-494a-ac0b-a8d2e5bb1fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130 entries, 0 to 129\n",
      "Columns: 141 entries, timestamp to 545621percent_display\n",
      "dtypes: datetime64[ns](1), float64(140)\n",
      "memory usage: 143.3 KB\n"
     ]
    }
   ],
   "source": [
    "ts_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab5e8f1-1289-46b4-8149-059e37f25cda",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe9afd-4304-4e9b-885d-bec01059abbc",
   "metadata": {},
   "source": [
    "Pickle multivariate timeseries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6a3459b7-853a-4b0f-97d9-015b16ebc54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle multivariate timeseries:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_ts_df.pik'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(ts_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      ts_df = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b9878c02-05a0-435a-8dcf-4d943100fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle multivariate timeseries:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_ts_df_2.pik'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(ts_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      ts_df = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ff77c1c8-af72-4426-bb6a-26cdf69f78a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>median_total_price</th>\n",
       "      <th>median_base_price</th>\n",
       "      <th>median_units_sold</th>\n",
       "      <th>percent_featured</th>\n",
       "      <th>percent_display</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.077922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>190.2375</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.189610</td>\n",
       "      <td>0.163636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>190.2375</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.274459</td>\n",
       "      <td>0.195671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>210.1875</td>\n",
       "      <td>210.9000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>0.096104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>210.9000</td>\n",
       "      <td>211.6125</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  median_total_price  median_base_price  median_units_sold  \\\n",
       "0 2011-01-08            205.9125           205.9125               28.0   \n",
       "1 2011-01-17            190.2375           205.9125               38.0   \n",
       "2 2011-01-24            190.2375           205.9125               37.0   \n",
       "3 2011-01-31            210.1875           210.9000               33.0   \n",
       "4 2011-02-05            210.9000           211.6125               31.0   \n",
       "\n",
       "   percent_featured  percent_display  \n",
       "0          0.066667         0.077922  \n",
       "1          0.189610         0.163636  \n",
       "2          0.274459         0.195671  \n",
       "3          0.010390         0.096104  \n",
       "4          0.000000         0.089177  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_ts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "697a61dd-d656-425a-ba36-ed22f2936ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_eda_ts.pik'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(eda_ts_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      eda_ts_df = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d6c0268-f21d-4112-bee2-227ac5bd2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_df.pik'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      df = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057edc31-eb9d-4b02-9f38-ff133b957242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
