{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d2d086-0466-4b18-8521-7bc70164e473",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "     \n",
    "# IC PCDA CAPSTONE - HARRY BAKHSHI - NOTEBOOK 9 - MAKE SEASONAL DATA STATIONARY\n",
    "     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa58216c-f24f-4621-8949-c1b5d4761b11",
   "metadata": {},
   "source": [
    "MIT License for code used from https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python in notebook:   \n",
    "https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python?tab=MIT-1-ov-file     \n",
    "\n",
    "(Accessed 06/06/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d8df92b0-61db-4e17-a5be-e992bf9ae9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "pio.templates.default = \"plotly_white\"\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import statistics\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3149be-6c1d-4d53-b214-6d291f6ae6c3",
   "metadata": {},
   "source": [
    "Load timeseries and seasonal period list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "06bd8196-b97a-442a-a835-46d8cc1b6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import timeseries data and seasonal period list:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/outlier_treated_ts_df_feature_engineered_2.pik'\n",
    "# with open(file, 'wb') as f:\n",
    "#        pickle.dump(ts_df, f) #write df to .pik file on disk\n",
    "with open(file, 'rb') as f:\n",
    "     ts_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_variable_seasonal_period_list_2_2.pik'\n",
    "# with open(file, 'wb') as f:\n",
    "#     pickle.dump(seasonal_period_list, f) #write df to .pik file on disk\n",
    "with open(file, 'rb') as f:\n",
    "     seasonal_period_list = pickle.load(f) #load pickle file 'file' into variable   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f72673a7-67e5-4c94-8dd9-fc231f65d650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>month_name</th>\n",
       "      <th>year</th>\n",
       "      <th>week_of_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-10</th>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2011-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-24</th>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-07</th>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-02-07</td>\n",
       "      <td>2</td>\n",
       "      <td>February</td>\n",
       "      <td>2011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           weekday_name  weekday  week  day        date  month month_name  \\\n",
       "timestamp                                                                   \n",
       "2011-01-10       Monday        0     2   10  2011-01-10      1    January   \n",
       "2011-01-17       Monday        0     3   17  2011-01-17      1    January   \n",
       "2011-01-24       Monday        0     4   24  2011-01-24      1    January   \n",
       "2011-01-31       Monday        0     5   31  2011-01-31      1    January   \n",
       "2011-02-07       Monday        0     6    7  2011-02-07      2   February   \n",
       "\n",
       "            year  week_of_month  \n",
       "timestamp                        \n",
       "2011-01-10  2011            2.0  \n",
       "2011-01-17  2011            4.0  \n",
       "2011-01-24  2011            5.0  \n",
       "2011-01-31  2011            6.0  \n",
       "2011-02-07  2011            1.0  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df[ts_df.columns.values[137:146]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1b262feb-4d03-46c2-963c-d4f8cc5531ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df.drop(list(ts_df.columns.values[137:146]), axis=1, inplace=True)\n",
    "ts_df.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2e71429f-269a-4102-af25-f372253c0c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['679023median_total_price', '245338median_total_price', '222087median_total_price', '223153median_total_price', '223245median_total_price', '222765median_total_price', '547934median_total_price', '378934median_total_price', '219029median_total_price', '216418median_total_price', '219009median_total_price', '217390median_total_price', '216233median_total_price', '216425median_total_price', '320485median_total_price', '300021median_total_price', '245387median_total_price', '216419median_total_price', '398721median_total_price', '217217median_total_price', '217777median_total_price', '219844median_total_price', '600934median_total_price', '673209median_total_price', '327492median_total_price', '300291median_total_price', '546789median_total_price', '545621median_total_price', '679023median_base_price', '245338median_base_price', '222087median_base_price', '223153median_base_price', '223245median_base_price', '222765median_base_price', '547934median_base_price', '378934median_base_price', '219029median_base_price', '216418median_base_price', '219009median_base_price', '217390median_base_price', '216233median_base_price', '216425median_base_price', '320485median_base_price', '300021median_base_price', '245387median_base_price', '216419median_base_price', '398721median_base_price', '217777median_base_price', '219844median_base_price', '600934median_base_price', '673209median_base_price', '327492median_base_price', '300291median_base_price', '546789median_base_price', '545621median_base_price', '679023median_units_sold', '245338median_units_sold', '222087median_units_sold', '223153median_units_sold', '223245median_units_sold', '222765median_units_sold', '547934median_units_sold', '378934median_units_sold', '219029median_units_sold', '216418median_units_sold', '219009median_units_sold', '217390median_units_sold', '216233median_units_sold', '216425median_units_sold', '320485median_units_sold', '300021median_units_sold', '245387median_units_sold', '216419median_units_sold', '398721median_units_sold', '217217median_units_sold', '217777median_units_sold', '219844median_units_sold', '600934median_units_sold', '673209median_units_sold', '327492median_units_sold', '300291median_units_sold', '546789median_units_sold', '545621median_units_sold', '679023percent_featured', '222087percent_featured', '223153percent_featured', '223245percent_featured', '222765percent_featured', '547934percent_featured', '378934percent_featured', '219029percent_featured', '216418percent_featured', '219009percent_featured', '217390percent_featured', '216233percent_featured', '216425percent_featured', '320485percent_featured', '300021percent_featured', '216419percent_featured', '217217percent_featured', '217777percent_featured', '219844percent_featured', '600934percent_featured', '673209percent_featured', '327492percent_featured', '300291percent_featured', '546789percent_featured', '545621percent_featured', '679023percent_display', '245338percent_display', '222087percent_display', '223153percent_display', '223245percent_display', '222765percent_display', '547934percent_display', '378934percent_display', '219029percent_display', '216418percent_display', '219009percent_display', '217390percent_display', '216233percent_display', '216425percent_display', '320485percent_display', '300021percent_display', '245387percent_display', '216419percent_display', '398721percent_display', '217217percent_display', '217777percent_display', '219844percent_display', '600934percent_display', '673209percent_display', '327492percent_display', '300291percent_display', '546789percent_display', '545621percent_display']\n"
     ]
    }
   ],
   "source": [
    "#list of variables in the seasonal period list:\n",
    "name_list = list(ts_df.columns.values[:136])\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/name_list_2.pik'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(name_list, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      name_list = pickle.load(f) #load pickle file 'file' into variable\n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348b77e-56ee-4597-a2e3-890b4bba9e64",
   "metadata": {},
   "source": [
    "Re-split feature engineered data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e0a841b1-d440-4a13-8f7f-3bb8bc99fc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Training samples: 114 | # of Validation samples: 19 | # of Test samples: 19 | # of Train+val samples: 133\n",
      "Max Date in Train: 2013-03-11 | Min Date in Validation: 2013-03-18 | Min Date in Test: 2013-07-29 | Max Date in Train+val: 2013-07-22| Min Date in Train+val: 2011-01-10\n"
     ]
    }
   ],
   "source": [
    "#Do train-test-validation split: \n",
    "test = ts_df.iloc[133:, :]\n",
    "val = ts_df.iloc[114:133, :]\n",
    "train = ts_df.iloc[:114, :]\n",
    "train_and_val = ts_df.iloc[:133, :]\n",
    "print(f\"# of Training samples: {len(train)} | # of Validation samples: {len(val)} | # of Test samples: {len(test)} | # of Train+val samples: {len(train_and_val)}\")\n",
    "print(f\"Max Date in Train: {train.index.date.max()} | Min Date in Validation: {val.index.date.min()} | Min Date in Test: {test.index.date.min()} | Max Date in Train+val: {train_and_val.index.date.max()}| Min Date in Train+val: {train_and_val.index.date.min()}\")\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/01-Setting%20up%20Experiment%20Harness.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fff1121b-1a10-4c67-8a0f-623b8f1a6b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52,\n",
       " 52,\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 4,\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 8,\n",
       " 52,\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 52,\n",
       " 8,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 4,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 9,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 8,\n",
       " 4,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 8,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 4,\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 52,\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 4,\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 5,\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 4,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 4,\n",
       " 52,\n",
       " 'not seasonal',\n",
       " 'not seasonal',\n",
       " 52,\n",
       " 'not seasonal']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = list(ts_df.columns.values[:])\n",
    "seasonal_period_list\n",
    "# col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e340a0d8-4c82-4774-83a7-248ff33071fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>679023median_total_price</th>\n",
       "      <th>245338median_total_price</th>\n",
       "      <th>222087median_total_price</th>\n",
       "      <th>223153median_total_price</th>\n",
       "      <th>223245median_total_price</th>\n",
       "      <th>222765median_total_price</th>\n",
       "      <th>547934median_total_price</th>\n",
       "      <th>378934median_total_price</th>\n",
       "      <th>219029median_total_price</th>\n",
       "      <th>216418median_total_price</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp_Week_cos_1</th>\n",
       "      <th>timestamp_Week_cos_2</th>\n",
       "      <th>timestamp_Week_cos_3</th>\n",
       "      <th>timestamp_Week_cos_4</th>\n",
       "      <th>timestamp_Week_cos_5</th>\n",
       "      <th>timestamp_Week_cos_6</th>\n",
       "      <th>timestamp_Week_cos_7</th>\n",
       "      <th>timestamp_Week_cos_8</th>\n",
       "      <th>timestamp_Week_cos_9</th>\n",
       "      <th>timestamp_Week_cos_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-10</th>\n",
       "      <td>180.2625</td>\n",
       "      <td>469.537500</td>\n",
       "      <td>226.931250</td>\n",
       "      <td>213.037500</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>195.225000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>205.912500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>87.637500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.748511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>196.650000</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.075000</td>\n",
       "      <td>93.337500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935016</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.464723</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.239316</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>-0.885456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-24</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>0.120537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>448.162500</td>\n",
       "      <td>226.931250</td>\n",
       "      <td>212.325000</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>84.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>-0.239316</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>-0.464723</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>0.970942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-07</th>\n",
       "      <td>180.2625</td>\n",
       "      <td>448.795621</td>\n",
       "      <td>175.185694</td>\n",
       "      <td>212.135054</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>240.792458</td>\n",
       "      <td>177.600521</td>\n",
       "      <td>177.604805</td>\n",
       "      <td>245.708337</td>\n",
       "      <td>90.036567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.568065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            679023median_total_price  245338median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                  180.2625                469.537500   \n",
       "2011-01-17                  178.1250                426.787500   \n",
       "2011-01-24                  178.1250                426.787500   \n",
       "2011-01-31                  178.1250                448.162500   \n",
       "2011-02-07                  180.2625                448.795621   \n",
       "\n",
       "            222087median_total_price  223153median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                226.931250                213.037500   \n",
       "2011-01-17                196.650000                190.237500   \n",
       "2011-01-24                190.237500                190.237500   \n",
       "2011-01-31                226.931250                212.325000   \n",
       "2011-02-07                175.185694                212.135054   \n",
       "\n",
       "            223245median_total_price  222765median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                  205.2000                195.225000   \n",
       "2011-01-17                  205.9125                240.825000   \n",
       "2011-01-24                  213.0375                240.825000   \n",
       "2011-01-31                  213.0375                240.825000   \n",
       "2011-02-07                  205.2000                240.792458   \n",
       "\n",
       "            547934median_total_price  378934median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                177.412500                205.912500   \n",
       "2011-01-17                177.412500                177.412500   \n",
       "2011-01-24                177.412500                177.412500   \n",
       "2011-01-31                177.412500                177.412500   \n",
       "2011-02-07                177.600521                177.604805   \n",
       "\n",
       "            219029median_total_price  216418median_total_price  ...  \\\n",
       "timestamp                                                       ...   \n",
       "2011-01-10                312.787500                 87.637500  ...   \n",
       "2011-01-17                312.075000                 93.337500  ...   \n",
       "2011-01-24                312.787500                 85.500000  ...   \n",
       "2011-01-31                312.787500                 84.075000  ...   \n",
       "2011-02-07                245.708337                 90.036567  ...   \n",
       "\n",
       "            timestamp_Week_cos_1  timestamp_Week_cos_2  timestamp_Week_cos_3  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10              0.970942              0.885456              0.748511   \n",
       "2011-01-17              0.935016              0.748511              0.464723   \n",
       "2011-01-24              0.885456              0.568065              0.120537   \n",
       "2011-01-31              0.822984              0.354605             -0.239316   \n",
       "2011-02-07              0.748511              0.120537             -0.568065   \n",
       "\n",
       "            timestamp_Week_cos_4  timestamp_Week_cos_5  timestamp_Week_cos_6  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10              0.568065              0.354605              0.120537   \n",
       "2011-01-17              0.120537             -0.239316             -0.568065   \n",
       "2011-01-24             -0.354605             -0.748511             -0.970942   \n",
       "2011-01-31             -0.748511             -0.992709             -0.885456   \n",
       "2011-02-07             -0.970942             -0.885456             -0.354605   \n",
       "\n",
       "            timestamp_Week_cos_7  timestamp_Week_cos_8  timestamp_Week_cos_9  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10             -0.120537             -0.354605             -0.568065   \n",
       "2011-01-17             -0.822984             -0.970942             -0.992709   \n",
       "2011-01-24             -0.970942             -0.748511             -0.354605   \n",
       "2011-01-31             -0.464723              0.120537              0.663123   \n",
       "2011-02-07              0.354605              0.885456              0.970942   \n",
       "\n",
       "            timestamp_Week_cos_10  \n",
       "timestamp                          \n",
       "2011-01-10              -0.748511  \n",
       "2011-01-17              -0.885456  \n",
       "2011-01-24               0.120537  \n",
       "2011-01-31               0.970942  \n",
       "2011-02-07               0.568065  \n",
       "\n",
       "[5 rows x 874 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d224188-0344-473a-ae93-cf05f0a0c45b",
   "metadata": {},
   "source": [
    "# MAKE TRAINING DATA STATIONARY\n",
    "- for predicting validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fda0c32f-f457-44ac-ab12-ad6d9111a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(len(col_list)):\n",
    "    train[col_list[col]] = pd.to_numeric(train[col_list[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "857e5223-c144-42d9-b7f5-943284fae707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for col in range(len(col_list)):\n",
    "#     for row in range(len(train)):\n",
    "#         if pd.isnull(train[col_list[col]][row]):\n",
    "#             count += 1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "363216f4-14ce-4aa3-87fb-5bf9ba8c7bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96852/2171507813.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.07573007419705391' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  ser_act.iloc[row] = statistics.median(ser)\n"
     ]
    }
   ],
   "source": [
    "for col in range(len(col_list)):\n",
    "    ser = train[col_list[col]].copy()\n",
    "    drop_list = []\n",
    "    for row in range(len(train)):\n",
    "        if pd.isnull(ser.iloc[row]):\n",
    "            drop_list.append(list(ser.index)[row])\n",
    "    ser.drop(drop_list, inplace=True)\n",
    "    ser = list(ser)\n",
    "    ser_act = train[col_list[col]]\n",
    "    for row in range(len(train)):\n",
    "        if pd.isnull(ser_act.iloc[row]):\n",
    "            if not ser:\n",
    "                ser_act.iloc[row] = 0\n",
    "            else:\n",
    "                ser_act.iloc[row] = statistics.median(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "13fe5c8e-5504-4c62-b1c1-4a7d23e22690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for col in range(len(col_list)):\n",
    "#     for row in range(len(train)):\n",
    "#         if pd.isnull(train[col_list[col]][row]):\n",
    "#             count += 1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9fc20c8c-bcbf-456e-ad8f-cc3a4b3cf538",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(len(col_list)):\n",
    "    val[col_list[col]] = pd.to_numeric(val[col_list[col]])\n",
    "for col in range(len(col_list)):\n",
    "    ser = val[col_list[col]].copy()\n",
    "    drop_list = []\n",
    "    for row in range(len(val)):\n",
    "        if pd.isnull(ser.iloc[row]):\n",
    "            drop_list.append(list(ser.index)[row])\n",
    "    ser.drop(drop_list, inplace=True)\n",
    "    ser = list(ser)\n",
    "    ser_act = val[col_list[col]]\n",
    "    for row in range(len(val)):\n",
    "        if pd.isnull(ser_act.iloc[row]):\n",
    "            if not ser:\n",
    "                ser_act.iloc[row] = 0\n",
    "            else:\n",
    "                ser_act.iloc[row] = statistics.median(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6fae56d2-3528-4321-b2dc-1ccbadbd894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/train_feature_engineered_2.pik'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(train, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      train = pickle.load(f) #load pickle file 'file' into variable\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/val_feature_engineered_2.pik'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(val, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      val = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cc05ea47-b11e-49f0-872f-5f7466dd1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/train_feature_engineered_2.pik'\n",
    "# # with open(file, 'wb') as f:\n",
    "# #     pickle.dump(train, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      train = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "888f8207-a449-4bf2-b32b-ad42a00c645b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>679023median_total_price</th>\n",
       "      <th>245338median_total_price</th>\n",
       "      <th>222087median_total_price</th>\n",
       "      <th>223153median_total_price</th>\n",
       "      <th>223245median_total_price</th>\n",
       "      <th>222765median_total_price</th>\n",
       "      <th>547934median_total_price</th>\n",
       "      <th>378934median_total_price</th>\n",
       "      <th>219029median_total_price</th>\n",
       "      <th>216418median_total_price</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp_Week_cos_1</th>\n",
       "      <th>timestamp_Week_cos_2</th>\n",
       "      <th>timestamp_Week_cos_3</th>\n",
       "      <th>timestamp_Week_cos_4</th>\n",
       "      <th>timestamp_Week_cos_5</th>\n",
       "      <th>timestamp_Week_cos_6</th>\n",
       "      <th>timestamp_Week_cos_7</th>\n",
       "      <th>timestamp_Week_cos_8</th>\n",
       "      <th>timestamp_Week_cos_9</th>\n",
       "      <th>timestamp_Week_cos_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-10</th>\n",
       "      <td>180.2625</td>\n",
       "      <td>469.537500</td>\n",
       "      <td>226.931250</td>\n",
       "      <td>213.037500</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>195.225000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>205.912500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>87.637500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.748511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>196.650000</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.075000</td>\n",
       "      <td>93.337500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935016</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.464723</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.239316</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>-0.885456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-24</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>0.120537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>448.162500</td>\n",
       "      <td>226.931250</td>\n",
       "      <td>212.325000</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>84.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>-0.239316</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>-0.464723</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>0.970942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-07</th>\n",
       "      <td>180.2625</td>\n",
       "      <td>448.795621</td>\n",
       "      <td>175.185694</td>\n",
       "      <td>212.135054</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>240.792458</td>\n",
       "      <td>177.600521</td>\n",
       "      <td>177.604805</td>\n",
       "      <td>245.708337</td>\n",
       "      <td>90.036567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.568065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            679023median_total_price  245338median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                  180.2625                469.537500   \n",
       "2011-01-17                  178.1250                426.787500   \n",
       "2011-01-24                  178.1250                426.787500   \n",
       "2011-01-31                  178.1250                448.162500   \n",
       "2011-02-07                  180.2625                448.795621   \n",
       "\n",
       "            222087median_total_price  223153median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                226.931250                213.037500   \n",
       "2011-01-17                196.650000                190.237500   \n",
       "2011-01-24                190.237500                190.237500   \n",
       "2011-01-31                226.931250                212.325000   \n",
       "2011-02-07                175.185694                212.135054   \n",
       "\n",
       "            223245median_total_price  222765median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                  205.2000                195.225000   \n",
       "2011-01-17                  205.9125                240.825000   \n",
       "2011-01-24                  213.0375                240.825000   \n",
       "2011-01-31                  213.0375                240.825000   \n",
       "2011-02-07                  205.2000                240.792458   \n",
       "\n",
       "            547934median_total_price  378934median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                177.412500                205.912500   \n",
       "2011-01-17                177.412500                177.412500   \n",
       "2011-01-24                177.412500                177.412500   \n",
       "2011-01-31                177.412500                177.412500   \n",
       "2011-02-07                177.600521                177.604805   \n",
       "\n",
       "            219029median_total_price  216418median_total_price  ...  \\\n",
       "timestamp                                                       ...   \n",
       "2011-01-10                312.787500                 87.637500  ...   \n",
       "2011-01-17                312.075000                 93.337500  ...   \n",
       "2011-01-24                312.787500                 85.500000  ...   \n",
       "2011-01-31                312.787500                 84.075000  ...   \n",
       "2011-02-07                245.708337                 90.036567  ...   \n",
       "\n",
       "            timestamp_Week_cos_1  timestamp_Week_cos_2  timestamp_Week_cos_3  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10              0.970942              0.885456              0.748511   \n",
       "2011-01-17              0.935016              0.748511              0.464723   \n",
       "2011-01-24              0.885456              0.568065              0.120537   \n",
       "2011-01-31              0.822984              0.354605             -0.239316   \n",
       "2011-02-07              0.748511              0.120537             -0.568065   \n",
       "\n",
       "            timestamp_Week_cos_4  timestamp_Week_cos_5  timestamp_Week_cos_6  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10              0.568065              0.354605              0.120537   \n",
       "2011-01-17              0.120537             -0.239316             -0.568065   \n",
       "2011-01-24             -0.354605             -0.748511             -0.970942   \n",
       "2011-01-31             -0.748511             -0.992709             -0.885456   \n",
       "2011-02-07             -0.970942             -0.885456             -0.354605   \n",
       "\n",
       "            timestamp_Week_cos_7  timestamp_Week_cos_8  timestamp_Week_cos_9  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10             -0.120537             -0.354605             -0.568065   \n",
       "2011-01-17             -0.822984             -0.970942             -0.992709   \n",
       "2011-01-24             -0.970942             -0.748511             -0.354605   \n",
       "2011-01-31             -0.464723              0.120537              0.663123   \n",
       "2011-02-07              0.354605              0.885456              0.970942   \n",
       "\n",
       "            timestamp_Week_cos_10  \n",
       "timestamp                          \n",
       "2011-01-10              -0.748511  \n",
       "2011-01-17              -0.885456  \n",
       "2011-01-24               0.120537  \n",
       "2011-01-31               0.970942  \n",
       "2011-02-07               0.568065  \n",
       "\n",
       "[5 rows x 874 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "726011da-43b1-4bc3-9814-d5c584646e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymannkendall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8629b5d2-4337-4143-ae09-1914d84d2daf",
   "metadata": {},
   "source": [
    "Weak stationarity caused by constant mean, constant variance, autocorrelation constant (1)  (autocorrelation changes occur with periodic, seasonal behaviour (2))   \n",
    "Deterministic trend, heteroscedasticity, stochastic trend, seasonality make a series non-stationary (2)   \n",
    "\n",
    "To make variable stationary:\n",
    "- does max = min? This is a case where all values are the same and so mean = constant, variance = constant, series is weakly stationary\n",
    "- is trend deterministic (mean changes) (2) or stochastic (constant mean, variance changes; = unit root (2))?\n",
    "- stochastic → stabilise mean by differencing (2)(3)(4), remove seasonality if present, remove heteroscedasticity (changes in variance)\n",
    "- deterministic → stabilise mean by detrending (2)(5), remove seasonality if present, remove heteroscedasticity\n",
    "\n",
    "(1) - https://www.itl.nist.gov/div898/handbook/pmc/section4/pmc442.htm  \n",
    "^Accessed 21/07/2024   \n",
    "(2) Modern Time Series Forecasting with Python (Manu Joseph, 2022)   \n",
    "(3) - https://blog.stata.com/2016/06/21/unit-root-tests-in-stata/     \n",
    "^Accessed 21/07/2024   \n",
    "(4) - https://otexts.com/fpp2/stationarity.html   \n",
    "^Accessed 21/07/2024   \n",
    "(5) - https://www.sciencedirect.com/science/article/abs/pii/016920709090003T  \n",
    "^Accessed 21/07/2024   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d25a5eab-aa49-4274-a0a2-41902c06ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transforms.target_transformations import DeseasonalizingTransformer\n",
    "def AutoStationaryTransformModified(df, col_list, var, index=None):\n",
    "    #Creating the timeseries with datetime index\n",
    "    y = df[col_list[var]]\n",
    "    if y.max() != y.min():\n",
    "        #Check for stochastic trend:\n",
    "        if check_unit_root(y, confidence=0.05).stationary == False:\n",
    "            diff_transformer = AdditiveDifferencingTransformer()\n",
    "            # [1:] because differencing reduces the length of the time series by one\n",
    "            y_diff = diff_transformer.fit_transform(y, freq=\"W-MON\")[1:]\n",
    "            # Setting the transformed series back to the dataframe\n",
    "            df[col_list[var]][1:] = y_diff.values\n",
    "            df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
    "            #Creating the timeseries with datetime index\n",
    "            y = df[col_list[var]]\n",
    "            if index != None:\n",
    "                deseasonalizing_transformer = DeseasonalizingTransformer(seasonality_extraction=\"period_averages\",seasonal_period=seasonal_period_list[index])\n",
    "            else:\n",
    "                deseasonalizing_transformer = DeseasonalizingTransformer(seasonality_extraction=\"period_averages\",seasonal_period=seasonal_period_list[var])\n",
    "            y_deseasonalized = deseasonalizing_transformer.fit_transform(y, freq=\"W-MON\")\n",
    "            #Setting the transformed series back to the dataframe           \n",
    "            df[col_list[var]] = y_deseasonalized.values\n",
    "            #Creating the timeseries with datetime index\n",
    "            y = df[col_list[var]]\n",
    "            if check_heteroscedastisticity(y, confidence=0.005)[0] == True:\n",
    "                #shifting the series into positive domain\n",
    "                _y_hetero = y-y.min()\n",
    "                #Arbritarily divided the data into sub-series of length 25\n",
    "                boxcox_transformer = BoxCoxTransformer(seasonal_period=25, add_one=True, optimization=\"guerrero\")\n",
    "                y_diff = boxcox_transformer.fit_transform(_y_hetero)\n",
    "                # Setting the transformed series back to the dataframe\n",
    "                df[col_list[var]] = y_diff.values\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            #Check deterministic trend\n",
    "            if check_deterministic_trend(y, confidence=0.05).deterministic_trend == True:\n",
    "            # if check_trend(y, confidence=0.05, seasonal_period=None, mann_kendall=True, prewhiten=None).trend == True:\n",
    "                detrending_transformer = DetrendingTransformer()\n",
    "                y_diff = detrending_transformer.fit_transform(y, freq=\"W-MON\")\n",
    "                # Setting the transformed series back to the dataframe\n",
    "                df[col_list[var]] = y_diff.values\n",
    "                #Creating the timeseries with datetime index\n",
    "                y = df[col_list[var]]\n",
    "                if index != None:\n",
    "                    deseasonalizing_transformer = DeseasonalizingTransformer(seasonality_extraction=\"period_averages\",seasonal_period=seasonal_period_list[index])\n",
    "                else:\n",
    "                    deseasonalizing_transformer = DeseasonalizingTransformer(seasonality_extraction=\"period_averages\",seasonal_period=seasonal_period_list[var])\n",
    "                y_deseasonalized = deseasonalizing_transformer.fit_transform(y, freq=\"W-MON\")\n",
    "                #Setting the transformed series back to the dataframe           \n",
    "                df[col_list[var]] = y_deseasonalized.values\n",
    "                #Creating the timeseries with datetime index\n",
    "                y = df[col_list[var]]\n",
    "                #Check heteroscedastisticity\n",
    "                if check_heteroscedastisticity(y, confidence=0.005)[0] == True:\n",
    "                    #shifting the series into positive domain\n",
    "                    _y_hetero = y-y.min()\n",
    "                    #Arbritarily divided the data into sub-series of length 25\n",
    "                    boxcox_transformer = BoxCoxTransformer(seasonal_period=25, add_one=True, optimization=\"guerrero\")\n",
    "                    y_diff = boxcox_transformer.fit_transform(_y_hetero)\n",
    "                    # Setting the transformed series back to the dataframe\n",
    "                    df[col_list[var]] = y_diff.values\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        pass\n",
    "    return df[col_list[var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7cb4b91c-a6de-45c9-9abf-e56ad2415f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/537860190.py:39: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n"
     ]
    }
   ],
   "source": [
    "#Make training data stationary:\n",
    "# from src.transforms.target_transformations import AutoStationaryTransformer\n",
    "from src.transforms.target_transformations import DetrendingTransformer\n",
    "from src.transforms.stationary_utils import check_unit_root\n",
    "from src.transforms.target_transformations import AdditiveDifferencingTransformer\n",
    "from src.transforms.stationary_utils import check_trend\n",
    "from src.transforms.stationary_utils import check_deterministic_trend\n",
    "from src.transforms.stationary_utils import check_heteroscedastisticity\n",
    "from src.transforms.target_transformations import BoxCoxTransformer\n",
    "transformer_pipelines = {}\n",
    "# for var in range(4):\n",
    "for var in range(len(col_list)):\n",
    "    if var < 136:\n",
    "    # if var < 140:\n",
    "        if seasonal_period_list[var] != 'not seasonal':\n",
    "            train[col_list[var]] = AutoStationaryTransformModified(train, col_list, var)\n",
    "            # #Initialize the AutoStationaryTransformer with seasonality period\n",
    "            # auto_stationary = AutoStationaryTransformer(seasonal_period=seasonal_period_list[var])\n",
    "            # #Creating the timeseries with datetime index\n",
    "            # y = train[col_list[var]]\n",
    "            # #Fitting and trainsforming the train\n",
    "            # y_stat = auto_stationary.fit_transform(y, freq=\"W-MON\")\n",
    "            # # Setting the transformerd series back to the dataframe           \n",
    "            # train[col_list[var]] = y_stat.values\n",
    "            # #Saving the pipeline\n",
    "            # transformer_pipelines[col_list[var]] = auto_stationary\n",
    "        if seasonal_period_list[var] == 'not seasonal':\n",
    "            #Creating the timeseries with datetime index\n",
    "            y = train[col_list[var]]\n",
    "            #Check stationary\n",
    "            if y.max() != y.min():\n",
    "                #Check for stochastic trend:\n",
    "                if check_unit_root(y, confidence=0.05).stationary == False:\n",
    "                    diff_transformer = AdditiveDifferencingTransformer()\n",
    "                    # [1:] because differencing reduces the length of the time series by one\n",
    "                    y_diff = diff_transformer.fit_transform(y, freq=\"W-MON\")[1:]\n",
    "                    # Setting the transformed series back to the dataframe\n",
    "                    train[col_list[var]][1:] = y_diff.values\n",
    "                    train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
    "                    #Creating the timeseries with datetime index\n",
    "                    y = train[col_list[var]]\n",
    "                    if check_heteroscedastisticity(y, confidence=0.005)[0] == True:\n",
    "                        #shifting the series into positive domain\n",
    "                        _y_hetero = y-y.min()\n",
    "                        #Arbritarily divided the data into sub-series of length 25\n",
    "                        boxcox_transformer = BoxCoxTransformer(seasonal_period=25, add_one=True, optimization=\"guerrero\")\n",
    "                        y_diff = boxcox_transformer.fit_transform(_y_hetero)\n",
    "                        # Setting the transformed series back to the dataframe\n",
    "                        train[col_list[var]] = y_diff.values\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    #Check deterministic trend\n",
    "                    if check_deterministic_trend(y, confidence=0.05).deterministic_trend == True:\n",
    "                    # if check_trend(y, confidence=0.05, seasonal_period=None, mann_kendall=True, prewhiten=None).trend == True:\n",
    "                        detrending_transformer = DetrendingTransformer()\n",
    "                        y_diff = detrending_transformer.fit_transform(y, freq=\"W-MON\")\n",
    "                        # Setting the transformed series back to the dataframe\n",
    "                        train[col_list[var]] = y_diff.values\n",
    "                        #Creating the timeseries with datetime index\n",
    "                        y = train[col_list[var]]\n",
    "                        #Check heteroscedastisticity\n",
    "                        if check_heteroscedastisticity(y, confidence=0.005)[0] == True:\n",
    "                            #shifting the series into positive domain\n",
    "                            _y_hetero = y-y.min()\n",
    "                            #Arbritarily divided the data into sub-series of length 25\n",
    "                            boxcox_transformer = BoxCoxTransformer(seasonal_period=25, add_one=True, optimization=\"guerrero\")\n",
    "                            y_diff = boxcox_transformer.fit_transform(_y_hetero)\n",
    "                            # Setting the transformed series back to the dataframe\n",
    "                            train[col_list[var]] = y_diff.values\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    else:       \n",
    "        found_output = col_list[var].find('seasonal')\n",
    "        if found_output != -1:\n",
    "            found_output = col_list[var].find('median_total_price')\n",
    "            if found_output != -1:\n",
    "                index = name_list.index(col_list[var][0:24])\n",
    "                if seasonal_period_list[index] != 'not seasonal':\n",
    "                    train[col_list[var]] = AutoStationaryTransformModified(train, col_list, var, index)\n",
    "                    # #Initialize the AutoStationaryTransformer with seasonality period\n",
    "                    # auto_stationary = AutoStationaryTransformer(seasonal_period=seasonal_period_list[index])\n",
    "                    # #Creating the timeseries with datetime index\n",
    "                    # y = train[col_list[var]]\n",
    "                    # #Fitting and trainsforming the train\n",
    "                    # y_stat = auto_stationary.fit_transform(y, freq=\"W-MON\")\n",
    "                    # # Setting the transformerd series back to the dataframe\n",
    "                    # train[col_list[var]] = y_stat.values\n",
    "                    # #Saving the pipeline\n",
    "                    # transformer_pipelines[col_list[var]] = auto_stationary\n",
    "            found_output = col_list[var].find('median_base_price')\n",
    "            if found_output != -1:\n",
    "                index = name_list.index(col_list[var][0:23])\n",
    "                if seasonal_period_list[index] != 'not seasonal':\n",
    "                    train[col_list[var]] = AutoStationaryTransformModified(train, col_list, var, index)\n",
    "            found_output = col_list[var].find('median_units_sold')\n",
    "            if found_output != -1:\n",
    "                index = name_list.index(col_list[var][0:23])\n",
    "                if seasonal_period_list[index] != 'not seasonal':\n",
    "                    train[col_list[var]] = AutoStationaryTransformModified(train, col_list, var, index)\n",
    "            found_output = col_list[var].find('percent_featured')\n",
    "            if found_output != -1:\n",
    "                index = name_list.index(col_list[var][0:22])\n",
    "                if seasonal_period_list[index] != 'not seasonal':\n",
    "                    train[col_list[var]] = AutoStationaryTransformModified(train, col_list, var, index)\n",
    "            found_output = col_list[var].find('percent_display')\n",
    "            if found_output != -1:\n",
    "                index = name_list.index(col_list[var][0:21])\n",
    "                if seasonal_period_list[index] != 'not seasonal':\n",
    "                    train[col_list[var]] = AutoStationaryTransformModified(train, col_list, var, index)\n",
    "            else:\n",
    "                found_output = col_list[var].find('ewma')\n",
    "                if found_output != -1:\n",
    "                    found_output = col_list[var].find('median_total_price')\n",
    "                    if found_output != -1:\n",
    "                        index = name_list.index(col_list[var][0:24])\n",
    "                        if seasonal_period_list[index] != 'not seasonal':\n",
    "                            train[col_list[var]] = AutoStationaryTransformModified(train, col_list, var, index)\n",
    "                    found_output = col_list[var].find('median_base_price')\n",
    "                    if found_output != -1:\n",
    "                        index = name_list.index(col_list[var][0:23])\n",
    "                        if seasonal_period_list[index] != 'not seasonal':\n",
    "                            train[col_list[var]] = AutoStationaryTransformModified(train, col_list, var, index)\n",
    "                    found_output = col_list[var].find('median_units_sold')\n",
    "                    if found_output != -1:\n",
    "                        index = name_list.index(col_list[var][0:23])\n",
    "                        if seasonal_period_list[index] != 'not seasonal':\n",
    "                            train[col_list[var]] = AutoStationaryTransformModified(train, col_list, var, index)\n",
    "                    found_output = col_list[var].find('percent_featured')\n",
    "                    if found_output != -1:\n",
    "                        index = name_list.index(col_list[var][0:22])\n",
    "                        if seasonal_period_list[index] != 'not seasonal':\n",
    "                            train[col_list[var]] = AutoStationaryTransformModified(train, col_list, var, index)\n",
    "                    found_output = col_list[var].find('percent_display')\n",
    "                    if found_output != -1:\n",
    "                        index = name_list.index(col_list[var][0:21])\n",
    "                        if seasonal_period_list[index] != 'not seasonal':\n",
    "                            train[col_list[var]] = AutoStationaryTransformModified(train, col_list, var, index)\n",
    "                else:\n",
    "                    #Creating the timeseries with datetime index\n",
    "                    y = train[col_list[var]]\n",
    "                    #Check stationary\n",
    "                    if y.max() != y.min():\n",
    "                        #Check for stochastic trend:\n",
    "                        if check_unit_root(y, confidence=0.05).stationary == False:\n",
    "                            diff_transformer = AdditiveDifferencingTransformer()\n",
    "                            # [1:] because differencing reduces the length of the time series by one\n",
    "                            y_diff = diff_transformer.fit_transform(y, freq=\"W-MON\")[1:]\n",
    "                            # Setting the transformed series back to the dataframe\n",
    "                            train[col_list[var]][1:] = y_diff.values\n",
    "                            train[col_list[var]][0] = statistics.median(train[col_list[var]][1:])\n",
    "                            if check_heteroscedastisticity(y, confidence=0.005)[0] == True:\n",
    "                                #shifting the series into positive domain\n",
    "                                _y_hetero = y-y.min()\n",
    "                                #Arbritarily divided the data into sub-series of length 25\n",
    "                                boxcox_transformer = BoxCoxTransformer(seasonal_period=25, add_one=True, optimization=\"guerrero\")\n",
    "                                y_diff = boxcox_transformer.fit_transform(_y_hetero)\n",
    "                                # Setting the transformed series back to the dataframe\n",
    "                                train[col_list[var]] = y_diff.values\n",
    "                            else:\n",
    "                                pass\n",
    "                        else:\n",
    "                            #Check deterministic trend\n",
    "                            if check_deterministic_trend(y, confidence=0.05).deterministic_trend == True:\n",
    "                            # if check_trend(y, confidence=0.05, seasonal_period=None, mann_kendall=True, prewhiten=None).trend == True:\n",
    "                                detrending_transformer = DetrendingTransformer()\n",
    "                                y_diff = detrending_transformer.fit_transform(y, freq=\"W-MON\")\n",
    "                                # Setting the transformed series back to the dataframe\n",
    "                                train[col_list[var]] = y_diff.values\n",
    "                                #Creating the timeseries with datetime index\n",
    "                                y = train[col_list[var]]\n",
    "                                #Check heteroscedastisticity\n",
    "                                if check_heteroscedastisticity(y, confidence=0.005)[0] == True:\n",
    "                                    #shifting the series into positive domain\n",
    "                                    _y_hetero = y-y.min()\n",
    "                                    #Arbritarily divided the data into sub-series of length 25\n",
    "                                    boxcox_transformer = BoxCoxTransformer(seasonal_period=25, add_one=True, optimization=\"guerrero\")\n",
    "                                    y_diff = boxcox_transformer.fit_transform(_y_hetero)\n",
    "                                    # Setting the transformed series back to the dataframe\n",
    "                                    train[col_list[var]] = y_diff.values\n",
    "                            else:\n",
    "                                pass\n",
    "                    else:\n",
    "                        pass\n",
    "  \n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/train_stationary_2.pik'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(train, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      train = pickle.load(f) #load pickle file 'file' into variable\n",
    "    \n",
    "# file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/auto_stationary_transformer_pipeline_train.pik'\n",
    "# with open(file, 'wb') as f:\n",
    "#     pickle.dump(transformer_pipelines, f) #write df to .pik file on disk\n",
    "# # with open(file, 'rb') as f:\n",
    "# #      transformer_pipelines = pickle.load(f) #load pickle file 'file' into variable\n",
    "\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter07/02-Dealing%20with%20Non-Stationarity.ipynb\n",
    "#Accessed 04/07/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4e982a97-9fae-414e-9a4a-c1de2baf8bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>679023median_total_price</th>\n",
       "      <th>245338median_total_price</th>\n",
       "      <th>222087median_total_price</th>\n",
       "      <th>223153median_total_price</th>\n",
       "      <th>223245median_total_price</th>\n",
       "      <th>222765median_total_price</th>\n",
       "      <th>547934median_total_price</th>\n",
       "      <th>378934median_total_price</th>\n",
       "      <th>219029median_total_price</th>\n",
       "      <th>216418median_total_price</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp_Week_cos_1</th>\n",
       "      <th>timestamp_Week_cos_2</th>\n",
       "      <th>timestamp_Week_cos_3</th>\n",
       "      <th>timestamp_Week_cos_4</th>\n",
       "      <th>timestamp_Week_cos_5</th>\n",
       "      <th>timestamp_Week_cos_6</th>\n",
       "      <th>timestamp_Week_cos_7</th>\n",
       "      <th>timestamp_Week_cos_8</th>\n",
       "      <th>timestamp_Week_cos_9</th>\n",
       "      <th>timestamp_Week_cos_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-10</th>\n",
       "      <td>180.2625</td>\n",
       "      <td>469.537500</td>\n",
       "      <td>5718.078564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>195.225000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>205.912500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>87.637500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.748511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-22.800000</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.075000</td>\n",
       "      <td>93.337500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935016</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.464723</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.239316</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>-0.885456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-24</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>1956.735899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>0.120537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>448.162500</td>\n",
       "      <td>4841.076303</td>\n",
       "      <td>22.087500</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>84.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>-0.239316</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>-0.464723</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>0.970942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-07</th>\n",
       "      <td>180.2625</td>\n",
       "      <td>448.795621</td>\n",
       "      <td>728.932091</td>\n",
       "      <td>-0.189946</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>240.792458</td>\n",
       "      <td>177.600521</td>\n",
       "      <td>177.604805</td>\n",
       "      <td>245.708337</td>\n",
       "      <td>90.036567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.568065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            679023median_total_price  245338median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                  180.2625                469.537500   \n",
       "2011-01-17                  178.1250                426.787500   \n",
       "2011-01-24                  178.1250                426.787500   \n",
       "2011-01-31                  178.1250                448.162500   \n",
       "2011-02-07                  180.2625                448.795621   \n",
       "\n",
       "            222087median_total_price  223153median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10               5718.078564                  0.000000   \n",
       "2011-01-17                  0.000000                -22.800000   \n",
       "2011-01-24               1956.735899                  0.000000   \n",
       "2011-01-31               4841.076303                 22.087500   \n",
       "2011-02-07                728.932091                 -0.189946   \n",
       "\n",
       "            223245median_total_price  222765median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                  205.2000                195.225000   \n",
       "2011-01-17                  205.9125                240.825000   \n",
       "2011-01-24                  213.0375                240.825000   \n",
       "2011-01-31                  213.0375                240.825000   \n",
       "2011-02-07                  205.2000                240.792458   \n",
       "\n",
       "            547934median_total_price  378934median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                177.412500                205.912500   \n",
       "2011-01-17                177.412500                177.412500   \n",
       "2011-01-24                177.412500                177.412500   \n",
       "2011-01-31                177.412500                177.412500   \n",
       "2011-02-07                177.600521                177.604805   \n",
       "\n",
       "            219029median_total_price  216418median_total_price  ...  \\\n",
       "timestamp                                                       ...   \n",
       "2011-01-10                312.787500                 87.637500  ...   \n",
       "2011-01-17                312.075000                 93.337500  ...   \n",
       "2011-01-24                312.787500                 85.500000  ...   \n",
       "2011-01-31                312.787500                 84.075000  ...   \n",
       "2011-02-07                245.708337                 90.036567  ...   \n",
       "\n",
       "            timestamp_Week_cos_1  timestamp_Week_cos_2  timestamp_Week_cos_3  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10              0.970942              0.885456              0.748511   \n",
       "2011-01-17              0.935016              0.748511              0.464723   \n",
       "2011-01-24              0.885456              0.568065              0.120537   \n",
       "2011-01-31              0.822984              0.354605             -0.239316   \n",
       "2011-02-07              0.748511              0.120537             -0.568065   \n",
       "\n",
       "            timestamp_Week_cos_4  timestamp_Week_cos_5  timestamp_Week_cos_6  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10              0.568065              0.354605              0.120537   \n",
       "2011-01-17              0.120537             -0.239316             -0.568065   \n",
       "2011-01-24             -0.354605             -0.748511             -0.970942   \n",
       "2011-01-31             -0.748511             -0.992709             -0.885456   \n",
       "2011-02-07             -0.970942             -0.885456             -0.354605   \n",
       "\n",
       "            timestamp_Week_cos_7  timestamp_Week_cos_8  timestamp_Week_cos_9  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10             -0.120537             -0.354605             -0.568065   \n",
       "2011-01-17             -0.822984             -0.970942             -0.992709   \n",
       "2011-01-24             -0.970942             -0.748511             -0.354605   \n",
       "2011-01-31             -0.464723              0.120537              0.663123   \n",
       "2011-02-07              0.354605              0.885456              0.970942   \n",
       "\n",
       "            timestamp_Week_cos_10  \n",
       "timestamp                          \n",
       "2011-01-10              -0.748511  \n",
       "2011-01-17              -0.885456  \n",
       "2011-01-24               0.120537  \n",
       "2011-01-31               0.970942  \n",
       "2011-02-07               0.568065  \n",
       "\n",
       "[5 rows x 874 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb3c9f0-98eb-482d-b9c8-53757c1b09e1",
   "metadata": {},
   "source": [
    "# MAKE TRAIN+VAL DATA STATIONARY\n",
    "- for predicting test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1037da4b-0bb2-405e-9dae-d665d3c250b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(len(col_list)):\n",
    "    train_and_val[col_list[col]] = pd.to_numeric(train_and_val[col_list[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f1ef3fb4-c74f-450f-97d5-ffa609fc2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(len(col_list)):\n",
    "    ser = train_and_val[col_list[col]].copy()\n",
    "    drop_list = []\n",
    "    for row in range(len(train_and_val)):\n",
    "        if pd.isnull(ser.iloc[row]):\n",
    "            drop_list.append(list(ser.index)[row])\n",
    "    ser.drop(drop_list, inplace=True)\n",
    "    ser = list(ser)\n",
    "    ser_act = train_and_val[col_list[col]]\n",
    "    for row in range(len(train_and_val)):\n",
    "        if pd.isnull(ser_act.iloc[row]):\n",
    "            if not ser:\n",
    "                ser_act.iloc[row] = 0\n",
    "            else:\n",
    "                ser_act.iloc[row] = statistics.median(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "be3be17a-e5e6-4edb-b093-6a2fc92cc44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/train_and_val_feature_engineered.pik'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(train_and_val, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      train_and_val = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "75c8e39a-1afd-479b-ba52-f21965b521de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>679023median_total_price</th>\n",
       "      <th>245338median_total_price</th>\n",
       "      <th>222087median_total_price</th>\n",
       "      <th>223153median_total_price</th>\n",
       "      <th>223245median_total_price</th>\n",
       "      <th>222765median_total_price</th>\n",
       "      <th>547934median_total_price</th>\n",
       "      <th>378934median_total_price</th>\n",
       "      <th>219029median_total_price</th>\n",
       "      <th>216418median_total_price</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp_Week_cos_1</th>\n",
       "      <th>timestamp_Week_cos_2</th>\n",
       "      <th>timestamp_Week_cos_3</th>\n",
       "      <th>timestamp_Week_cos_4</th>\n",
       "      <th>timestamp_Week_cos_5</th>\n",
       "      <th>timestamp_Week_cos_6</th>\n",
       "      <th>timestamp_Week_cos_7</th>\n",
       "      <th>timestamp_Week_cos_8</th>\n",
       "      <th>timestamp_Week_cos_9</th>\n",
       "      <th>timestamp_Week_cos_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-10</th>\n",
       "      <td>180.2625</td>\n",
       "      <td>469.537500</td>\n",
       "      <td>226.931250</td>\n",
       "      <td>213.037500</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>195.225000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>205.912500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>87.637500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.748511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>196.650000</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.075000</td>\n",
       "      <td>93.337500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935016</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.464723</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.239316</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>-0.885456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-24</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>0.120537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>448.162500</td>\n",
       "      <td>226.931250</td>\n",
       "      <td>212.325000</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>84.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>-0.239316</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>-0.464723</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>0.970942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-07</th>\n",
       "      <td>180.2625</td>\n",
       "      <td>448.795621</td>\n",
       "      <td>175.185694</td>\n",
       "      <td>212.135054</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>240.792458</td>\n",
       "      <td>177.600521</td>\n",
       "      <td>177.604805</td>\n",
       "      <td>245.708337</td>\n",
       "      <td>90.036567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.568065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            679023median_total_price  245338median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                  180.2625                469.537500   \n",
       "2011-01-17                  178.1250                426.787500   \n",
       "2011-01-24                  178.1250                426.787500   \n",
       "2011-01-31                  178.1250                448.162500   \n",
       "2011-02-07                  180.2625                448.795621   \n",
       "\n",
       "            222087median_total_price  223153median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                226.931250                213.037500   \n",
       "2011-01-17                196.650000                190.237500   \n",
       "2011-01-24                190.237500                190.237500   \n",
       "2011-01-31                226.931250                212.325000   \n",
       "2011-02-07                175.185694                212.135054   \n",
       "\n",
       "            223245median_total_price  222765median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                  205.2000                195.225000   \n",
       "2011-01-17                  205.9125                240.825000   \n",
       "2011-01-24                  213.0375                240.825000   \n",
       "2011-01-31                  213.0375                240.825000   \n",
       "2011-02-07                  205.2000                240.792458   \n",
       "\n",
       "            547934median_total_price  378934median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                177.412500                205.912500   \n",
       "2011-01-17                177.412500                177.412500   \n",
       "2011-01-24                177.412500                177.412500   \n",
       "2011-01-31                177.412500                177.412500   \n",
       "2011-02-07                177.600521                177.604805   \n",
       "\n",
       "            219029median_total_price  216418median_total_price  ...  \\\n",
       "timestamp                                                       ...   \n",
       "2011-01-10                312.787500                 87.637500  ...   \n",
       "2011-01-17                312.075000                 93.337500  ...   \n",
       "2011-01-24                312.787500                 85.500000  ...   \n",
       "2011-01-31                312.787500                 84.075000  ...   \n",
       "2011-02-07                245.708337                 90.036567  ...   \n",
       "\n",
       "            timestamp_Week_cos_1  timestamp_Week_cos_2  timestamp_Week_cos_3  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10              0.970942              0.885456              0.748511   \n",
       "2011-01-17              0.935016              0.748511              0.464723   \n",
       "2011-01-24              0.885456              0.568065              0.120537   \n",
       "2011-01-31              0.822984              0.354605             -0.239316   \n",
       "2011-02-07              0.748511              0.120537             -0.568065   \n",
       "\n",
       "            timestamp_Week_cos_4  timestamp_Week_cos_5  timestamp_Week_cos_6  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10              0.568065              0.354605              0.120537   \n",
       "2011-01-17              0.120537             -0.239316             -0.568065   \n",
       "2011-01-24             -0.354605             -0.748511             -0.970942   \n",
       "2011-01-31             -0.748511             -0.992709             -0.885456   \n",
       "2011-02-07             -0.970942             -0.885456             -0.354605   \n",
       "\n",
       "            timestamp_Week_cos_7  timestamp_Week_cos_8  timestamp_Week_cos_9  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10             -0.120537             -0.354605             -0.568065   \n",
       "2011-01-17             -0.822984             -0.970942             -0.992709   \n",
       "2011-01-24             -0.970942             -0.748511             -0.354605   \n",
       "2011-01-31             -0.464723              0.120537              0.663123   \n",
       "2011-02-07              0.354605              0.885456              0.970942   \n",
       "\n",
       "            timestamp_Week_cos_10  \n",
       "timestamp                          \n",
       "2011-01-10              -0.748511  \n",
       "2011-01-17              -0.885456  \n",
       "2011-01-24               0.120537  \n",
       "2011-01-31               0.970942  \n",
       "2011-02-07               0.568065  \n",
       "\n",
       "[5 rows x 874 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b164a592-bc0b-4523-abb1-e3d86e1a5476",
   "metadata": {},
   "source": [
    "Weak stationarity caused by constant mean, constant variance, autocorrelation constant (1)  (autocorrelation changes occur with periodic, seasonal behaviour (2))   \n",
    "Deterministic trend, heteroscedasticity, stochastic trend, seasonality make a series non-stationary (2)   \n",
    "\n",
    "To make variable stationary:\n",
    "- does max = min? This is a case where all values are the same and so mean = constant, variance = constant, series is weakly stationary\n",
    "- is trend deterministic (mean changes) (2) or stochastic (constant mean, variance changes; = unit root (2))?\n",
    "- stochastic → stabilise mean by differencing (2)(3)(4), remove seasonality if present, remove heteroscedasticity (changes in variance)\n",
    "- deterministic → stabilise mean by detrending (2)(5), remove seasonality if present, remove heteroscedasticity\n",
    "\n",
    "(1) - https://www.itl.nist.gov/div898/handbook/pmc/section4/pmc442.htm  \n",
    "^Accessed 21/07/2024   \n",
    "(2) Modern Time Series Forecasting with Python (Manu Joseph, 2022)   \n",
    "(3) - https://blog.stata.com/2016/06/21/unit-root-tests-in-stata/     \n",
    "^Accessed 21/07/2024   \n",
    "(4) - https://otexts.com/fpp2/stationarity.html   \n",
    "^Accessed 21/07/2024   \n",
    "(5) - https://www.sciencedirect.com/science/article/abs/pii/016920709090003T  \n",
    "^Accessed 21/07/2024   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "73c583d0-5990-4328-9ee8-e5a3f339bdcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/1691313460.py:38: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
      "/tmp/ipykernel_96852/48967971.py:13: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df[col_list[var]][0] = statistics.median(df[col_list[var]][1:])\n"
     ]
    }
   ],
   "source": [
    "#Make train+val data stationary:\n",
    "# from src.transforms.target_transformations import AutoStationaryTransformer\n",
    "from src.transforms.target_transformations import DetrendingTransformer\n",
    "from src.transforms.stationary_utils import check_unit_root\n",
    "from src.transforms.target_transformations import AdditiveDifferencingTransformer\n",
    "from src.transforms.stationary_utils import check_trend\n",
    "from src.transforms.stationary_utils import check_deterministic_trend\n",
    "from src.transforms.stationary_utils import check_heteroscedastisticity\n",
    "from src.transforms.target_transformations import BoxCoxTransformer\n",
    "transformer_pipelines = {}\n",
    "for var in range(len(col_list)):\n",
    "    if var < 136:\n",
    "    # if var < 140:\n",
    "        if seasonal_period_list[var] != 'not seasonal':\n",
    "            train_and_val[col_list[var]] = AutoStationaryTransformModified(train_and_val, col_list, var)\n",
    "            # #Initialize the AutoStationaryTransformer with seasonality period\n",
    "            # auto_stationary = AutoStationaryTransformer(seasonal_period=seasonal_period_list[var])\n",
    "            # #Creating the timeseries with datetime index\n",
    "            # y = train_and_val[col_list[var]]\n",
    "            # #Fitting and trainsforming the train\n",
    "            # y_stat = auto_stationary.fit_transform(y, freq=\"W-MON\")\n",
    "            # # Setting the transformerd series back to the dataframe           \n",
    "            # train_and_val[col_list[var]] = y_stat.values\n",
    "            # #Saving the pipeline\n",
    "            # transformer_pipelines[col_list[var]] = auto_stationary\n",
    "        if seasonal_period_list[var] == 'not seasonal':\n",
    "            #Creating the timeseries with datetime index\n",
    "            y = train_and_val[col_list[var]]\n",
    "            #Check stationary\n",
    "            if y.max() != y.min():\n",
    "                #Check for stochastic trend:\n",
    "                if check_unit_root(y, confidence=0.05).stationary == False:\n",
    "                    diff_transformer = AdditiveDifferencingTransformer()\n",
    "                    # [1:] because differencing reduces the length of the time series by one\n",
    "                    y_diff = diff_transformer.fit_transform(y, freq=\"W-MON\")[1:]\n",
    "                    # Setting the transformed series back to the dataframe\n",
    "                    train_and_val[col_list[var]][1:] = y_diff.values\n",
    "                    train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
    "                    #Creating the timeseries with datetime index\n",
    "                    y = train_and_val[col_list[var]]\n",
    "                    if check_heteroscedastisticity(y, confidence=0.005)[0] == True:\n",
    "                        #shifting the series into positive domain\n",
    "                        _y_hetero = y-y.min()\n",
    "                        #Arbritarily divided the data into sub-series of length 25\n",
    "                        boxcox_transformer = BoxCoxTransformer(seasonal_period=25, add_one=True, optimization=\"guerrero\")\n",
    "                        y_diff = boxcox_transformer.fit_transform(_y_hetero)\n",
    "                        # Setting the transformed series back to the dataframe\n",
    "                        train_and_val[col_list[var]] = y_diff.values\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    #Check deterministic trend\n",
    "                    if check_deterministic_trend(y, confidence=0.05).deterministic_trend == True:\n",
    "                    # if check_trend(y, confidence=0.05, seasonal_period=None, mann_kendall=True, prewhiten=None).trend == True:\n",
    "                        detrending_transformer = DetrendingTransformer()\n",
    "                        y_diff = detrending_transformer.fit_transform(y, freq=\"W-MON\")\n",
    "                        # Setting the transformed series back to the dataframe\n",
    "                        train_and_val[col_list[var]] = y_diff.values\n",
    "                        #Creating the timeseries with datetime index\n",
    "                        y = train_and_val[col_list[var]]\n",
    "                        #Check heteroscedastisticity\n",
    "                        if check_heteroscedastisticity(y, confidence=0.005)[0] == True:\n",
    "                            #shifting the series into positive domain\n",
    "                            _y_hetero = y-y.min()\n",
    "                            #Arbritarily divided the data into sub-series of length 25\n",
    "                            boxcox_transformer = BoxCoxTransformer(seasonal_period=25, add_one=True, optimization=\"guerrero\")\n",
    "                            y_diff = boxcox_transformer.fit_transform(_y_hetero)\n",
    "                            # Setting the transformed series back to the dataframe\n",
    "                            train_and_val[col_list[var]] = y_diff.values\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    else:       \n",
    "        found_output = col_list[var].find('seasonal')\n",
    "        if found_output != -1:\n",
    "            found_output = col_list[var].find('median_total_price')\n",
    "            if found_output != -1:\n",
    "                index = name_list.index(col_list[var][0:24])\n",
    "                if seasonal_period_list[index] != 'not seasonal':\n",
    "                    train_and_val[col_list[var]] = AutoStationaryTransformModified(train_and_val, col_list, var, index)\n",
    "                    # #Initialize the AutoStationaryTransformer with seasonality period\n",
    "                    # auto_stationary = AutoStationaryTransformer(seasonal_period=seasonal_period_list[index])\n",
    "                    # #Creating the timeseries with datetime index\n",
    "                    # y = train_and_val[col_list[var]]\n",
    "                    # #Fitting and trainsforming the train\n",
    "                    # y_stat = auto_stationary.fit_transform(y, freq=\"W-MON\")\n",
    "                    # # Setting the transformerd series back to the dataframe\n",
    "                    # train_and_val[col_list[var]] = y_stat.values\n",
    "                    # #Saving the pipeline\n",
    "                    # transformer_pipelines[col_list[var]] = auto_stationary\n",
    "            found_output = col_list[var].find('median_base_price')\n",
    "            if found_output != -1:\n",
    "                index = name_list.index(col_list[var][0:23])\n",
    "                if seasonal_period_list[index] != 'not seasonal':\n",
    "                    train_and_val[col_list[var]] = AutoStationaryTransformModified(train_and_val, col_list, var, index)\n",
    "            found_output = col_list[var].find('median_units_sold')\n",
    "            if found_output != -1:\n",
    "                index = name_list.index(col_list[var][0:23])\n",
    "                if seasonal_period_list[index] != 'not seasonal':\n",
    "                    train_and_val[col_list[var]] = AutoStationaryTransformModified(train_and_val, col_list, var, index)\n",
    "            found_output = col_list[var].find('percent_featured')\n",
    "            if found_output != -1:\n",
    "                index = name_list.index(col_list[var][0:22])\n",
    "                if seasonal_period_list[index] != 'not seasonal':\n",
    "                    train_and_val[col_list[var]] = AutoStationaryTransformModified(train_and_val, col_list, var, index)\n",
    "            found_output = col_list[var].find('percent_display')\n",
    "            if found_output != -1:\n",
    "                index = name_list.index(col_list[var][0:21])\n",
    "                if seasonal_period_list[index] != 'not seasonal':\n",
    "                    train_and_val[col_list[var]] = AutoStationaryTransformModified(train_and_val, col_list, var, index)\n",
    "            else:\n",
    "                found_output = col_list[var].find('ewma')\n",
    "                if found_output != -1:\n",
    "                    found_output = col_list[var].find('median_total_price')\n",
    "                    if found_output != -1:\n",
    "                        index = name_list.index(col_list[var][0:24])\n",
    "                        if seasonal_period_list[index] != 'not seasonal':\n",
    "                            train_and_val[col_list[var]] = AutoStationaryTransformModified(train_and_val, col_list, var, index)\n",
    "                    found_output = col_list[var].find('median_base_price')\n",
    "                    if found_output != -1:\n",
    "                        index = name_list.index(col_list[var][0:23])\n",
    "                        if seasonal_period_list[index] != 'not seasonal':\n",
    "                            train_and_val[col_list[var]] = AutoStationaryTransformModified(train_and_val, col_list, var, index)\n",
    "                    found_output = col_list[var].find('median_units_sold')\n",
    "                    if found_output != -1:\n",
    "                        index = name_list.index(col_list[var][0:23])\n",
    "                        if seasonal_period_list[index] != 'not seasonal':\n",
    "                            train_and_val[col_list[var]] = AutoStationaryTransformModified(train_and_val, col_list, var, index)\n",
    "                    found_output = col_list[var].find('percent_featured')\n",
    "                    if found_output != -1:\n",
    "                        index = name_list.index(col_list[var][0:22])\n",
    "                        if seasonal_period_list[index] != 'not seasonal':\n",
    "                            train_and_val[col_list[var]] = AutoStationaryTransformModified(train_and_val, col_list, var, index)\n",
    "                    found_output = col_list[var].find('percent_display')\n",
    "                    if found_output != -1:\n",
    "                        index = name_list.index(col_list[var][0:21])\n",
    "                        if seasonal_period_list[index] != 'not seasonal':\n",
    "                            train_and_val[col_list[var]] = AutoStationaryTransformModified(train_and_val, col_list, var, index)\n",
    "                else:\n",
    "                    #Creating the timeseries with datetime index\n",
    "                    y = train_and_val[col_list[var]]\n",
    "                    #Check stationary\n",
    "                    if y.max() != y.min():\n",
    "                        #Check for stochastic trend:\n",
    "                        if check_unit_root(y, confidence=0.05).stationary == False:\n",
    "                            diff_transformer = AdditiveDifferencingTransformer()\n",
    "                            # [1:] because differencing reduces the length of the time series by one\n",
    "                            y_diff = diff_transformer.fit_transform(y, freq=\"W-MON\")[1:]\n",
    "                            # Setting the transformed series back to the dataframe\n",
    "                            train_and_val[col_list[var]][1:] = y_diff.values\n",
    "                            train_and_val[col_list[var]][0] = statistics.median(train_and_val[col_list[var]][1:])\n",
    "                            #Creating the timeseries with datetime index\n",
    "                            y = train_and_val[col_list[var]]\n",
    "                            if check_heteroscedastisticity(y, confidence=0.005)[0] == True:\n",
    "                                #shifting the series into positive domain\n",
    "                                _y_hetero = y-y.min()\n",
    "                                #Arbritarily divided the data into sub-series of length 25\n",
    "                                boxcox_transformer = BoxCoxTransformer(seasonal_period=25, add_one=True, optimization=\"guerrero\")\n",
    "                                y_diff = boxcox_transformer.fit_transform(_y_hetero)\n",
    "                                # Setting the transformed series back to the dataframe\n",
    "                                train_and_val[col_list[var]] = y_diff.values\n",
    "                            else:\n",
    "                                pass\n",
    "                        else:\n",
    "                            #Check deterministic trend\n",
    "                            if check_deterministic_trend(y, confidence=0.05).deterministic_trend == True:\n",
    "                            # if check_trend(y, confidence=0.05, seasonal_period=None, mann_kendall=True, prewhiten=None).trend == True:\n",
    "                                detrending_transformer = DetrendingTransformer()\n",
    "                                y_diff = detrending_transformer.fit_transform(y, freq=\"W-MON\")\n",
    "                                # Setting the transformed series back to the dataframe\n",
    "                                train_and_val[col_list[var]] = y_diff.values\n",
    "                                #Creating the timeseries with datetime index\n",
    "                                y = train_and_val[col_list[var]]\n",
    "                                #Check heteroscedastisticity\n",
    "                                if check_heteroscedastisticity(y, confidence=0.005)[0] == True:\n",
    "                                    #shifting the series into positive domain\n",
    "                                    _y_hetero = y-y.min()\n",
    "                                    #Arbritarily divided the data into sub-series of length 25\n",
    "                                    boxcox_transformer = BoxCoxTransformer(seasonal_period=25, add_one=True, optimization=\"guerrero\")\n",
    "                                    y_diff = boxcox_transformer.fit_transform(_y_hetero)\n",
    "                                    # Setting the transformed series back to the dataframe\n",
    "                                    train_and_val[col_list[var]] = y_diff.values\n",
    "                            else:\n",
    "                                pass\n",
    "                    else:\n",
    "                        pass\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/train_and_val_stationary_2.pik'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(train_and_val, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      train_and_val = pickle.load(f) #load pickle file 'file' into variable\n",
    "\n",
    "# file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/auto_stationary_transformer_pipeline_train_and_val_2.pik'\n",
    "# with open(file, 'wb') as f:\n",
    "#     pickle.dump(transformer_pipelines, f) #write df to .pik file on disk\n",
    "# # with open(file, 'rb') as f:\n",
    "# #      transformer_pipelines = pickle.load(f) #load pickle file 'file' into variable\n",
    "\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter07/02-Dealing%20with%20Non-Stationarity.ipynb\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter07/02a-Dealing%20with%20Non-Stationarity-Train%2BVal.ipynb\n",
    "#Accessed 04/07/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "eac0ff1c-b700-473f-84b3-d6845ef223b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>679023median_total_price</th>\n",
       "      <th>245338median_total_price</th>\n",
       "      <th>222087median_total_price</th>\n",
       "      <th>223153median_total_price</th>\n",
       "      <th>223245median_total_price</th>\n",
       "      <th>222765median_total_price</th>\n",
       "      <th>547934median_total_price</th>\n",
       "      <th>378934median_total_price</th>\n",
       "      <th>219029median_total_price</th>\n",
       "      <th>216418median_total_price</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp_Week_cos_1</th>\n",
       "      <th>timestamp_Week_cos_2</th>\n",
       "      <th>timestamp_Week_cos_3</th>\n",
       "      <th>timestamp_Week_cos_4</th>\n",
       "      <th>timestamp_Week_cos_5</th>\n",
       "      <th>timestamp_Week_cos_6</th>\n",
       "      <th>timestamp_Week_cos_7</th>\n",
       "      <th>timestamp_Week_cos_8</th>\n",
       "      <th>timestamp_Week_cos_9</th>\n",
       "      <th>timestamp_Week_cos_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-10</th>\n",
       "      <td>180.2625</td>\n",
       "      <td>469.537500</td>\n",
       "      <td>0.990670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>195.225000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>205.912500</td>\n",
       "      <td>1.522737</td>\n",
       "      <td>87.637500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.748511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-22.800000</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.337500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935016</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.464723</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.239316</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>-0.885456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-24</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>0.984020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>1.484744</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>0.120537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>448.162500</td>\n",
       "      <td>0.989841</td>\n",
       "      <td>22.087500</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>1.484353</td>\n",
       "      <td>84.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>-0.239316</td>\n",
       "      <td>-0.748511</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>-0.464723</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>0.970942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-07</th>\n",
       "      <td>180.2625</td>\n",
       "      <td>448.795621</td>\n",
       "      <td>0.973822</td>\n",
       "      <td>-0.189946</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>240.792458</td>\n",
       "      <td>177.600521</td>\n",
       "      <td>177.604805</td>\n",
       "      <td>1.418130</td>\n",
       "      <td>90.036567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.568065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 874 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            679023median_total_price  245338median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                  180.2625                469.537500   \n",
       "2011-01-17                  178.1250                426.787500   \n",
       "2011-01-24                  178.1250                426.787500   \n",
       "2011-01-31                  178.1250                448.162500   \n",
       "2011-02-07                  180.2625                448.795621   \n",
       "\n",
       "            222087median_total_price  223153median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                  0.990670                  0.000000   \n",
       "2011-01-17                  0.000000                -22.800000   \n",
       "2011-01-24                  0.984020                  0.000000   \n",
       "2011-01-31                  0.989841                 22.087500   \n",
       "2011-02-07                  0.973822                 -0.189946   \n",
       "\n",
       "            223245median_total_price  222765median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                  205.2000                195.225000   \n",
       "2011-01-17                  205.9125                240.825000   \n",
       "2011-01-24                  213.0375                240.825000   \n",
       "2011-01-31                  213.0375                240.825000   \n",
       "2011-02-07                  205.2000                240.792458   \n",
       "\n",
       "            547934median_total_price  378934median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-10                177.412500                205.912500   \n",
       "2011-01-17                177.412500                177.412500   \n",
       "2011-01-24                177.412500                177.412500   \n",
       "2011-01-31                177.412500                177.412500   \n",
       "2011-02-07                177.600521                177.604805   \n",
       "\n",
       "            219029median_total_price  216418median_total_price  ...  \\\n",
       "timestamp                                                       ...   \n",
       "2011-01-10                  1.522737                 87.637500  ...   \n",
       "2011-01-17                  0.000000                 93.337500  ...   \n",
       "2011-01-24                  1.484744                 85.500000  ...   \n",
       "2011-01-31                  1.484353                 84.075000  ...   \n",
       "2011-02-07                  1.418130                 90.036567  ...   \n",
       "\n",
       "            timestamp_Week_cos_1  timestamp_Week_cos_2  timestamp_Week_cos_3  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10              0.970942              0.885456              0.748511   \n",
       "2011-01-17              0.935016              0.748511              0.464723   \n",
       "2011-01-24              0.885456              0.568065              0.120537   \n",
       "2011-01-31              0.822984              0.354605             -0.239316   \n",
       "2011-02-07              0.748511              0.120537             -0.568065   \n",
       "\n",
       "            timestamp_Week_cos_4  timestamp_Week_cos_5  timestamp_Week_cos_6  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10              0.568065              0.354605              0.120537   \n",
       "2011-01-17              0.120537             -0.239316             -0.568065   \n",
       "2011-01-24             -0.354605             -0.748511             -0.970942   \n",
       "2011-01-31             -0.748511             -0.992709             -0.885456   \n",
       "2011-02-07             -0.970942             -0.885456             -0.354605   \n",
       "\n",
       "            timestamp_Week_cos_7  timestamp_Week_cos_8  timestamp_Week_cos_9  \\\n",
       "timestamp                                                                      \n",
       "2011-01-10             -0.120537             -0.354605             -0.568065   \n",
       "2011-01-17             -0.822984             -0.970942             -0.992709   \n",
       "2011-01-24             -0.970942             -0.748511             -0.354605   \n",
       "2011-01-31             -0.464723              0.120537              0.663123   \n",
       "2011-02-07              0.354605              0.885456              0.970942   \n",
       "\n",
       "            timestamp_Week_cos_10  \n",
       "timestamp                          \n",
       "2011-01-10              -0.748511  \n",
       "2011-01-17              -0.885456  \n",
       "2011-01-24               0.120537  \n",
       "2011-01-31               0.970942  \n",
       "2011-02-07               0.568065  \n",
       "\n",
       "[5 rows x 874 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf759d-9c70-4d03-8ea8-5164354c4b2a",
   "metadata": {},
   "source": [
    "Pickle test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cb1a516e-3c3a-42de-bf62-598f5cd98a1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in range(len(col_list)):\n",
    "    test[col_list[col]] = pd.to_numeric(test[col_list[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c973c24f-6517-4421-806a-b30f9b1d2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(len(col_list)):\n",
    "    ser = test[col_list[col]].copy()\n",
    "    drop_list = []\n",
    "    for row in range(len(test)):\n",
    "        if pd.isnull(ser.iloc[row]):\n",
    "            drop_list.append(list(ser.index)[row])\n",
    "    ser.drop(drop_list, inplace=True)\n",
    "    ser = list(ser)\n",
    "    ser_act = test[col_list[col]]\n",
    "    for row in range(len(test)):\n",
    "        if pd.isnull(ser_act.iloc[row]):\n",
    "            if not ser:\n",
    "                ser_act.iloc[row] = 0\n",
    "            else:\n",
    "                ser_act.iloc[row] = statistics.median(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5aeaf434-29d1-48e7-8e77-3d4e700c38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/test_feature_engineered_2.pik'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(test, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      test = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756d274-c767-446b-b61c-857be0142be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
