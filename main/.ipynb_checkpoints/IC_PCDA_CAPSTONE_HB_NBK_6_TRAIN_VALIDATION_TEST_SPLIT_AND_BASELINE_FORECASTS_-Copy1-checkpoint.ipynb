{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb338ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "     \n",
    "# IC PCDA CAPSTONE - HARRY BAKHSHI - NOTEBOOK 6 - TRAIN/VALIDATION/TEST SPLIT AND BASELINE FORECASTS\n",
    "     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a335ed",
   "metadata": {},
   "source": [
    "MIT License for code used from https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python in notebook:   \n",
    "https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python?tab=MIT-1-ov-file     \n",
    "\n",
    "(Accessed 06/06/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb750ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from darts import TimeSeries\n",
    "from darts.models import (\n",
    "    NaiveSeasonal,\n",
    "    NaiveMean,\n",
    "    NaiveDrift,\n",
    "    ExponentialSmoothing,\n",
    "    AutoARIMA,\n",
    "    ARIMA,\n",
    "    Theta,\n",
    "    FFT\n",
    ")\n",
    "\n",
    "from darts.metrics import mase, mse, mae, ope\n",
    "from darts.utils.utils import SeasonalityMode\n",
    "\n",
    "from src.utils.ts_utils import forecast_bias #calculates forecast bias\n",
    "#^see: https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/src/utils/ts_utils.py\n",
    "#Accessed 17/06/2024\n",
    "from src.utils.general import LogTime #prints Time Elapsed\n",
    "#^see: https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/src/utils/general.py\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a31f65-bf67-4ff5-827b-74094364f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaleido \n",
    "#!pip install darts\n",
    "#!pip install humanize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603943ef-457e-4c1e-b1b4-fa0461244806",
   "metadata": {},
   "source": [
    "Import timeseries data and seasonal period list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1848ab9-bd23-4fcb-b9d6-7064b7031441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import timeseries data and seasonal period list:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/outlier_treated_ts_df_2.pik'\n",
    "# with open(file, 'wb') as f:\n",
    "#        pickle.dump(ts_df, f) #write df to .pik file on disk\n",
    "with open(file, 'rb') as f:\n",
    "     ts_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/janatahack_demand_forecasting_data_variable_seasonal_period_list_2.pik'\n",
    "# with open(file, 'wb') as f:\n",
    "#     pickle.dump(seasonal_period_list, f) #write df to .pik file on disk\n",
    "with open(file, 'rb') as f:\n",
    "     seasonal_period_list = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5522f7a-1846-4b5d-a081-8441f8f50c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>679023median_total_price</th>\n",
       "      <th>245338median_total_price</th>\n",
       "      <th>222087median_total_price</th>\n",
       "      <th>223153median_total_price</th>\n",
       "      <th>223245median_total_price</th>\n",
       "      <th>222765median_total_price</th>\n",
       "      <th>547934median_total_price</th>\n",
       "      <th>378934median_total_price</th>\n",
       "      <th>219029median_total_price</th>\n",
       "      <th>216418median_total_price</th>\n",
       "      <th>...</th>\n",
       "      <th>545621percent_display</th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>month_name</th>\n",
       "      <th>year</th>\n",
       "      <th>week_of_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-08</th>\n",
       "      <td>180.2625</td>\n",
       "      <td>469.5375</td>\n",
       "      <td>226.93125</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>205.2000</td>\n",
       "      <td>195.2250</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>312.7875</td>\n",
       "      <td>87.6375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.7875</td>\n",
       "      <td>196.65000</td>\n",
       "      <td>190.2375</td>\n",
       "      <td>205.9125</td>\n",
       "      <td>240.8250</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>312.0750</td>\n",
       "      <td>93.3375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-24</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>426.7875</td>\n",
       "      <td>190.23750</td>\n",
       "      <td>190.2375</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.8250</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>312.7875</td>\n",
       "      <td>85.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31</th>\n",
       "      <td>178.1250</td>\n",
       "      <td>448.1625</td>\n",
       "      <td>226.93125</td>\n",
       "      <td>212.3250</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>240.8250</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>312.7875</td>\n",
       "      <td>84.0750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-05</th>\n",
       "      <td>205.9125</td>\n",
       "      <td>469.5375</td>\n",
       "      <td>227.28750</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>213.0375</td>\n",
       "      <td>234.4125</td>\n",
       "      <td>142.5000</td>\n",
       "      <td>177.4125</td>\n",
       "      <td>312.7875</td>\n",
       "      <td>87.6375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>2</td>\n",
       "      <td>February</td>\n",
       "      <td>2011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            679023median_total_price  245338median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-08                  180.2625                  469.5375   \n",
       "2011-01-17                  178.1250                  426.7875   \n",
       "2011-01-24                  178.1250                  426.7875   \n",
       "2011-01-31                  178.1250                  448.1625   \n",
       "2011-02-05                  205.9125                  469.5375   \n",
       "\n",
       "            222087median_total_price  223153median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-08                 226.93125                  213.0375   \n",
       "2011-01-17                 196.65000                  190.2375   \n",
       "2011-01-24                 190.23750                  190.2375   \n",
       "2011-01-31                 226.93125                  212.3250   \n",
       "2011-02-05                 227.28750                  213.0375   \n",
       "\n",
       "            223245median_total_price  222765median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-08                  205.2000                  195.2250   \n",
       "2011-01-17                  205.9125                  240.8250   \n",
       "2011-01-24                  213.0375                  240.8250   \n",
       "2011-01-31                  213.0375                  240.8250   \n",
       "2011-02-05                  213.0375                  234.4125   \n",
       "\n",
       "            547934median_total_price  378934median_total_price  \\\n",
       "timestamp                                                        \n",
       "2011-01-08                  177.4125                  205.9125   \n",
       "2011-01-17                  177.4125                  177.4125   \n",
       "2011-01-24                  177.4125                  177.4125   \n",
       "2011-01-31                  177.4125                  177.4125   \n",
       "2011-02-05                  142.5000                  177.4125   \n",
       "\n",
       "            219029median_total_price  216418median_total_price  ...  \\\n",
       "timestamp                                                       ...   \n",
       "2011-01-08                  312.7875                   87.6375  ...   \n",
       "2011-01-17                  312.0750                   93.3375  ...   \n",
       "2011-01-24                  312.7875                   85.5000  ...   \n",
       "2011-01-31                  312.7875                   84.0750  ...   \n",
       "2011-02-05                  312.7875                   87.6375  ...   \n",
       "\n",
       "            545621percent_display  weekday_name  weekday  week  day  \\\n",
       "timestamp                                                             \n",
       "2011-01-08                    0.0      Saturday        5     1    8   \n",
       "2011-01-17                    0.0        Monday        0     3   17   \n",
       "2011-01-24                    0.0        Monday        0     4   24   \n",
       "2011-01-31                    0.0        Monday        0     5   31   \n",
       "2011-02-05                    0.0      Saturday        5     5    5   \n",
       "\n",
       "                  date  month  month_name  year  week_of_month  \n",
       "timestamp                                                       \n",
       "2011-01-08  2011-01-08      1     January  2011            2.0  \n",
       "2011-01-17  2011-01-17      1     January  2011            4.0  \n",
       "2011-01-24  2011-01-24      1     January  2011            5.0  \n",
       "2011-01-31  2011-01-31      1     January  2011            6.0  \n",
       "2011-02-05  2011-02-05      2    February  2011            1.0  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07329bb-246d-4fc6-9b76-40516225c726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['679023median_total_price', '245338median_total_price',\n",
       "       '222087median_total_price', '223153median_total_price',\n",
       "       '223245median_total_price', '222765median_total_price',\n",
       "       '547934median_total_price', '378934median_total_price',\n",
       "       '219029median_total_price', '216418median_total_price',\n",
       "       '219009median_total_price', '217390median_total_price',\n",
       "       '216233median_total_price', '216425median_total_price',\n",
       "       '320485median_total_price', '300021median_total_price',\n",
       "       '245387median_total_price', '216419median_total_price',\n",
       "       '398721median_total_price', '217217median_total_price',\n",
       "       '217777median_total_price', '219844median_total_price',\n",
       "       '600934median_total_price', '673209median_total_price',\n",
       "       '327492median_total_price', '300291median_total_price',\n",
       "       '546789median_total_price', '545621median_total_price',\n",
       "       '679023median_base_price', '245338median_base_price',\n",
       "       '222087median_base_price', '223153median_base_price',\n",
       "       '223245median_base_price', '222765median_base_price',\n",
       "       '547934median_base_price', '378934median_base_price',\n",
       "       '219029median_base_price', '216418median_base_price',\n",
       "       '219009median_base_price', '217390median_base_price',\n",
       "       '216233median_base_price', '216425median_base_price',\n",
       "       '320485median_base_price', '300021median_base_price',\n",
       "       '245387median_base_price', '216419median_base_price',\n",
       "       '398721median_base_price', '217217median_base_price',\n",
       "       '217777median_base_price', '219844median_base_price',\n",
       "       '600934median_base_price', '673209median_base_price',\n",
       "       '327492median_base_price', '300291median_base_price',\n",
       "       '546789median_base_price', '545621median_base_price',\n",
       "       '679023median_units_sold', '245338median_units_sold',\n",
       "       '222087median_units_sold', '223153median_units_sold',\n",
       "       '223245median_units_sold', '222765median_units_sold',\n",
       "       '547934median_units_sold', '378934median_units_sold',\n",
       "       '219029median_units_sold', '216418median_units_sold',\n",
       "       '219009median_units_sold', '217390median_units_sold',\n",
       "       '216233median_units_sold', '216425median_units_sold',\n",
       "       '320485median_units_sold', '300021median_units_sold',\n",
       "       '245387median_units_sold', '216419median_units_sold',\n",
       "       '398721median_units_sold', '217217median_units_sold',\n",
       "       '217777median_units_sold', '219844median_units_sold',\n",
       "       '600934median_units_sold', '673209median_units_sold',\n",
       "       '327492median_units_sold', '300291median_units_sold',\n",
       "       '546789median_units_sold', '545621median_units_sold',\n",
       "       '679023percent_featured', '245338percent_featured',\n",
       "       '222087percent_featured', '223153percent_featured',\n",
       "       '223245percent_featured', '222765percent_featured',\n",
       "       '547934percent_featured', '378934percent_featured',\n",
       "       '219029percent_featured', '216418percent_featured',\n",
       "       '219009percent_featured', '217390percent_featured',\n",
       "       '216233percent_featured', '216425percent_featured',\n",
       "       '320485percent_featured', '300021percent_featured',\n",
       "       '245387percent_featured', '216419percent_featured',\n",
       "       '398721percent_featured', '217217percent_featured',\n",
       "       '217777percent_featured', '219844percent_featured',\n",
       "       '600934percent_featured', '673209percent_featured',\n",
       "       '327492percent_featured', '300291percent_featured',\n",
       "       '546789percent_featured', '545621percent_featured',\n",
       "       '679023percent_display', '245338percent_display',\n",
       "       '222087percent_display', '223153percent_display',\n",
       "       '223245percent_display', '222765percent_display',\n",
       "       '547934percent_display', '378934percent_display',\n",
       "       '219029percent_display', '216418percent_display',\n",
       "       '219009percent_display', '217390percent_display',\n",
       "       '216233percent_display', '216425percent_display',\n",
       "       '320485percent_display', '300021percent_display',\n",
       "       '245387percent_display', '216419percent_display',\n",
       "       '398721percent_display', '217217percent_display',\n",
       "       '217777percent_display', '219844percent_display',\n",
       "       '600934percent_display', '673209percent_display',\n",
       "       '327492percent_display', '300291percent_display',\n",
       "       '546789percent_display', '545621percent_display'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df.columns.values[:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93af1301-df98-4d75-871d-5f72b8920982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(137 - 105)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4139061-84f3-48b8-bf35-83c88eb9bec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679023median_total_price      191.6625\n",
       "245338median_total_price      469.5375\n",
       "222087median_total_price       172.425\n",
       "223153median_total_price      235.8375\n",
       "223245median_total_price      235.8375\n",
       "                               ...    \n",
       "date                        2013-01-22\n",
       "month                                1\n",
       "month_name                     January\n",
       "year                              2013\n",
       "week_of_month                      4.0\n",
       "Name: 2013-01-22 00:00:00, Length: 149, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df.iloc[104] #Jan 22 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee5077de-5078-4081-8462-05fa446de89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679023median_total_price      177.4125\n",
       "245338median_total_price      339.8625\n",
       "222087median_total_price      210.1875\n",
       "223153median_total_price      235.8375\n",
       "223245median_total_price      227.2875\n",
       "                               ...    \n",
       "date                        2013-12-03\n",
       "month                               12\n",
       "month_name                    December\n",
       "year                              2013\n",
       "week_of_month                      1.0\n",
       "Name: 2013-12-03 00:00:00, Length: 149, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df.iloc[136] #Dec 03 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e3a4be0-c389-4d79-a4ea-fb5960b5180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11678832116788321\n",
      "18.24\n"
     ]
    }
   ],
   "source": [
    "print(16/137)\n",
    "print(152*0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27cf1026-d9b6-4a7a-9b92-960584053728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(105 + 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e06858-a2c6-4169-9469-fa9bf13b9510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679023median_total_price      234.4125\n",
       "245338median_total_price      375.4875\n",
       "222087median_total_price     173.49375\n",
       "223153median_total_price       141.075\n",
       "223245median_total_price        219.45\n",
       "                               ...    \n",
       "date                        2013-05-28\n",
       "month                                5\n",
       "month_name                         May\n",
       "year                              2013\n",
       "week_of_month                      5.0\n",
       "Name: 2013-05-28 00:00:00, Length: 149, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df.iloc[120] #May 28 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23aabcc-2aa3-4005-9966-e8db96e0b458",
   "metadata": {},
   "source": [
    "Convert time index to integer timestep (using darts can't infer or set (as values missing) freq of the time index as the date indices are inconsistent (there are 3 frequencies: '8D' (every 8 calendar days), 'W-MON' (weekly beginning on Monday), 'B' (every business day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95e25c4a-ad82-4bb9-afd5-332d47531044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>679023median_total_price</th>\n",
       "      <th>245338median_total_price</th>\n",
       "      <th>222087median_total_price</th>\n",
       "      <th>223153median_total_price</th>\n",
       "      <th>223245median_total_price</th>\n",
       "      <th>222765median_total_price</th>\n",
       "      <th>547934median_total_price</th>\n",
       "      <th>378934median_total_price</th>\n",
       "      <th>219029median_total_price</th>\n",
       "      <th>216418median_total_price</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>month_name</th>\n",
       "      <th>year</th>\n",
       "      <th>week_of_month</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180.262500</td>\n",
       "      <td>469.537500</td>\n",
       "      <td>226.931250</td>\n",
       "      <td>213.037500</td>\n",
       "      <td>205.200000</td>\n",
       "      <td>195.225000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>205.912500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>87.637500</td>\n",
       "      <td>...</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>178.125000</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>196.650000</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>205.912500</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.075000</td>\n",
       "      <td>93.337500</td>\n",
       "      <td>...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.125000</td>\n",
       "      <td>426.787500</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>190.237500</td>\n",
       "      <td>213.037500</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178.125000</td>\n",
       "      <td>448.162500</td>\n",
       "      <td>226.931250</td>\n",
       "      <td>212.325000</td>\n",
       "      <td>213.037500</td>\n",
       "      <td>240.825000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>84.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2011</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205.912500</td>\n",
       "      <td>469.537500</td>\n",
       "      <td>227.287500</td>\n",
       "      <td>213.037500</td>\n",
       "      <td>213.037500</td>\n",
       "      <td>234.412500</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>87.637500</td>\n",
       "      <td>...</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>2</td>\n",
       "      <td>February</td>\n",
       "      <td>2011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>234.751046</td>\n",
       "      <td>333.134460</td>\n",
       "      <td>214.936819</td>\n",
       "      <td>237.989605</td>\n",
       "      <td>227.818410</td>\n",
       "      <td>243.615693</td>\n",
       "      <td>151.623765</td>\n",
       "      <td>206.524337</td>\n",
       "      <td>353.818679</td>\n",
       "      <td>97.632103</td>\n",
       "      <td>...</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>2013-10-19</td>\n",
       "      <td>10</td>\n",
       "      <td>October</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>234.480150</td>\n",
       "      <td>373.450283</td>\n",
       "      <td>218.666937</td>\n",
       "      <td>213.070494</td>\n",
       "      <td>202.169001</td>\n",
       "      <td>212.702979</td>\n",
       "      <td>172.886582</td>\n",
       "      <td>206.137349</td>\n",
       "      <td>359.761503</td>\n",
       "      <td>95.361484</td>\n",
       "      <td>...</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>2013-10-26</td>\n",
       "      <td>10</td>\n",
       "      <td>October</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.0</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>234.412500</td>\n",
       "      <td>375.487500</td>\n",
       "      <td>203.775000</td>\n",
       "      <td>235.837500</td>\n",
       "      <td>223.725000</td>\n",
       "      <td>239.400000</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>205.912500</td>\n",
       "      <td>327.037500</td>\n",
       "      <td>97.256250</td>\n",
       "      <td>...</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-11-06</td>\n",
       "      <td>11</td>\n",
       "      <td>November</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>177.412500</td>\n",
       "      <td>355.537500</td>\n",
       "      <td>195.581250</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>213.750000</td>\n",
       "      <td>227.287500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>155.325000</td>\n",
       "      <td>312.787500</td>\n",
       "      <td>88.706250</td>\n",
       "      <td>...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-02</td>\n",
       "      <td>12</td>\n",
       "      <td>December</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>177.412500</td>\n",
       "      <td>339.862500</td>\n",
       "      <td>210.187500</td>\n",
       "      <td>235.837500</td>\n",
       "      <td>227.287500</td>\n",
       "      <td>227.287500</td>\n",
       "      <td>177.412500</td>\n",
       "      <td>205.912500</td>\n",
       "      <td>327.037500</td>\n",
       "      <td>89.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>12</td>\n",
       "      <td>December</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     679023median_total_price  245338median_total_price  \\\n",
       "0                  180.262500                469.537500   \n",
       "1                  178.125000                426.787500   \n",
       "2                  178.125000                426.787500   \n",
       "3                  178.125000                448.162500   \n",
       "4                  205.912500                469.537500   \n",
       "..                        ...                       ...   \n",
       "132                234.751046                333.134460   \n",
       "133                234.480150                373.450283   \n",
       "134                234.412500                375.487500   \n",
       "135                177.412500                355.537500   \n",
       "136                177.412500                339.862500   \n",
       "\n",
       "     222087median_total_price  223153median_total_price  \\\n",
       "0                  226.931250                213.037500   \n",
       "1                  196.650000                190.237500   \n",
       "2                  190.237500                190.237500   \n",
       "3                  226.931250                212.325000   \n",
       "4                  227.287500                213.037500   \n",
       "..                        ...                       ...   \n",
       "132                214.936819                237.989605   \n",
       "133                218.666937                213.070494   \n",
       "134                203.775000                235.837500   \n",
       "135                195.581250                177.412500   \n",
       "136                210.187500                235.837500   \n",
       "\n",
       "     223245median_total_price  222765median_total_price  \\\n",
       "0                  205.200000                195.225000   \n",
       "1                  205.912500                240.825000   \n",
       "2                  213.037500                240.825000   \n",
       "3                  213.037500                240.825000   \n",
       "4                  213.037500                234.412500   \n",
       "..                        ...                       ...   \n",
       "132                227.818410                243.615693   \n",
       "133                202.169001                212.702979   \n",
       "134                223.725000                239.400000   \n",
       "135                213.750000                227.287500   \n",
       "136                227.287500                227.287500   \n",
       "\n",
       "     547934median_total_price  378934median_total_price  \\\n",
       "0                  177.412500                205.912500   \n",
       "1                  177.412500                177.412500   \n",
       "2                  177.412500                177.412500   \n",
       "3                  177.412500                177.412500   \n",
       "4                  142.500000                177.412500   \n",
       "..                        ...                       ...   \n",
       "132                151.623765                206.524337   \n",
       "133                172.886582                206.137349   \n",
       "134                177.412500                205.912500   \n",
       "135                177.412500                155.325000   \n",
       "136                177.412500                205.912500   \n",
       "\n",
       "     219029median_total_price  216418median_total_price  ...  weekday_name  \\\n",
       "0                  312.787500                 87.637500  ...      Saturday   \n",
       "1                  312.075000                 93.337500  ...        Monday   \n",
       "2                  312.787500                 85.500000  ...        Monday   \n",
       "3                  312.787500                 84.075000  ...        Monday   \n",
       "4                  312.787500                 87.637500  ...      Saturday   \n",
       "..                        ...                       ...  ...           ...   \n",
       "132                353.818679                 97.632103  ...      Saturday   \n",
       "133                359.761503                 95.361484  ...      Saturday   \n",
       "134                327.037500                 97.256250  ...     Wednesday   \n",
       "135                312.787500                 88.706250  ...        Monday   \n",
       "136                327.037500                 89.062500  ...       Tuesday   \n",
       "\n",
       "     weekday  week  day        date  month  month_name  year  week_of_month  \\\n",
       "0          5     1    8  2011-01-08      1     January  2011            2.0   \n",
       "1          0     3   17  2011-01-17      1     January  2011            4.0   \n",
       "2          0     4   24  2011-01-24      1     January  2011            5.0   \n",
       "3          0     5   31  2011-01-31      1     January  2011            6.0   \n",
       "4          5     5    5  2011-02-05      2    February  2011            1.0   \n",
       "..       ...   ...  ...         ...    ...         ...   ...            ...   \n",
       "132        5    42   19  2013-10-19     10     October  2013            3.0   \n",
       "133        5    43   26  2013-10-26     10     October  2013            4.0   \n",
       "134        2    45    6  2013-11-06     11    November  2013            2.0   \n",
       "135        0    49    2  2013-12-02     12    December  2013            1.0   \n",
       "136        1    49    3  2013-12-03     12    December  2013            1.0   \n",
       "\n",
       "     timestamp  \n",
       "0            0  \n",
       "1            1  \n",
       "2            2  \n",
       "3            3  \n",
       "4            4  \n",
       "..         ...  \n",
       "132        132  \n",
       "133        133  \n",
       "134        134  \n",
       "135        135  \n",
       "136        136  \n",
       "\n",
       "[137 rows x 150 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df.set_index(np.arange(0, len(ts_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc5483-07dd-44ae-847b-8a24d53edc17",
   "metadata": {},
   "source": [
    "See below - can't impute missing dates (not with a diff of 7 see below) to infer freq as W-MON, as more dates to impute than dates to base seasonal period on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ac01e06-27ed-40af-ba14-2829c388d565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xn/_bz_k2_x60v2l_s_sch6rwp40000gn/T/ipykernel_18092/1694138804.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ts_df['weekday'][5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df['timestamp'] = ts_df.index\n",
    "ts_df['weekday'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3dad6adc-9e9e-4215-a983-c67065d190ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 7, 7, 5, 9, 7, 7, 10, 4, 7, 7, 7, 3, 11, 7, 14, 3, 4, 7, 7, 7, 7, 7, 7, 5, 1, 8, 7, 7, 14, 7, 7, 7, 7, 14, 7, 14, 7, 7, 7, 4, 3, 7, 7, 7, 11, 3, 7, 7, 10, 11, 7, 7, 2, 9, 3, 7, 7, 6, 3, 6, 7, 7, 13, 3, 5, 7, 12, 9, 7, 7, 4, 1, 8, 8, 7, 12, 9, 7, 7, 5, 9, 7, 7, 4, 9, 8, 7, 9, 3, 9, 7, 7, 10, 3, 1, 7, 7, 9, 12, 7, 7, 14, 7, 7, 6, 3, 12, 7, 21, 7, 11, 10, 7, 7, 2, 1, 11, 7, 7, 21, 7, 10, 27, 34, 3, 7, 7, 7, 7, 7, 7, 7, 11, 26, 1]\n",
      "7\n",
      "10\n",
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xn/_bz_k2_x60v2l_s_sch6rwp40000gn/T/ipykernel_18092/4283604613.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  d1 = ts_df['timestamp'][row]\n",
      "/var/folders/xn/_bz_k2_x60v2l_s_sch6rwp40000gn/T/ipykernel_18092/4283604613.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  d2 = ts_df['timestamp'][row + 1]\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "diff_list = []\n",
    "count = 0\n",
    "count_2 = 0\n",
    "for row in range(len(ts_df['timestamp']) - 1):\n",
    "    d1 = ts_df['timestamp'][row]\n",
    "    d2 = ts_df['timestamp'][row + 1]\n",
    "    diff_list.append(abs((d2 - d1).days))\n",
    "    if diff_list[row] == 9:\n",
    "        count += 1\n",
    "    if diff_list[row] == 7:\n",
    "        count_2 += 1\n",
    "print(diff_list)\n",
    "print(statistics.mode(diff_list))\n",
    "print(count)\n",
    "print(count_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c15fa-4adb-48a6-b1c2-e2075f951c07",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e4e1e-1325-4c04-b518-9ddf42984b1a",
   "metadata": {},
   "source": [
    "## DO TRAIN - VALIDATION - TEST SPLIT:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085e7fc-21ff-47e7-985d-880dd0e07a02",
   "metadata": {},
   "source": [
    "Do train-validation-test split:   \n",
    "\n",
    "\"As a standard practice, in machine learning, we set aside two parts of the dataset, name them validation data and test data, and don’t use them at all to train the model. The validation data is used in the modeling process to assess the quality of the model. To select between different model classes, tune the hyperparameters, perform feature selection, and so on, we need a dataset.\" (1)   \n",
    "\"Test data is like the final test of your chosen model. It tells you how well your model is doing in unseen data\" (1)   \n",
    "\"rule of thumb\" - \"to set equal-sized validation and test datasets so that the key modeling decisions we make based on the validation data are as close as possible to the test data.\" (1)  \n",
    "\"In regular regression or classification, we usually sample a few records at random and set them aside. But while dealing with time series, we need to respect the temporal aspect of the dataset. Therefore, a best practice is to set aside the latest part of the dataset as the test data.\" (1)   \n",
    "\"The validation set cannot be used simultaneously for model selection and to predict the future performance of the selected model on unseen data.  It is required to have a new and untouched data set called a ‘test set’. (2)   \n",
    "\"Training set = data set used to train different models, validation set = a data set used to select the most promising model, test set = a data set used to get an unbiased estimate of a model’s performance\" (2)   \n",
    "\"The test set should ideally be at least as large as the maximum forecast horizon required\" (3)  \n",
    "\"A forecast horizon is the number of time steps into the future we want to forecast at any point in time.\" (1)  \n",
    "\n",
    "^Understanding that test dataset should from the latest part of the data and be as large as the maximum forecast horizon required, the validation set should be of equal size, and that the training data should comprise the remainder of the data excluded from the data partioned in this way   \n",
    "\n",
    "Therefore, if maximum forecast time ahead equal to 12% of data time period (approx. 152/4 = 18 weeks ahead (151 weeks 4 days duration of time series data) (4)), test data latest 12%, validation data next 12%, and training data first 76%\n",
    "\n",
    "^(1) - Modern Time Series With Python, Manu Joseph (2022)   \n",
    "^(2) - Module 18, IC PCDA: \"Required quiz 18.1: Test sets and naive benchmarks\"   \n",
    "^(3) - Forecasting: Principles and Practice (2nd ed) (Rob J Hyndman and George Athanasopoulos, 2018)   \n",
    "^(4) - https://www.timeanddate.com/date/durationresult.html?d1=8&m1=1&y1=2011&d2=3&m2=12&y2=2013&ti=on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8749cdb7-484a-4172-9215-fb201068d9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Training samples: 105 | # of Validation samples: 16 | # of Test samples: 16\n",
      "Max Date in Train: 2013-01-22 | Min Date in Validation: 2013-01-29 | Min Date in Test: 2013-06-18\n"
     ]
    }
   ],
   "source": [
    "#Do train-test-validation split: \n",
    "test = ts_df.iloc[121:, :]\n",
    "val = ts_df.iloc[105:121, :]\n",
    "train = ts_df.iloc[:105, :]\n",
    "print(f\"# of Training samples: {len(train)} | # of Validation samples: {len(val)} | # of Test samples: {len(test)}\")\n",
    "print(f\"Max Date in Train: {train.date.max()} | Min Date in Validation: {val.date.min()} | Min Date in Test: {test.date.min()}\")\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/01-Setting%20up%20Experiment%20Harness.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d508c31-e623-481e-8d25-082684591c2b",
   "metadata": {},
   "source": [
    "Store in parquet format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "780ea420-7154-4818-99d3-d135fd11f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store in parquet format:\n",
    "train.to_parquet(\"/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/train.parquet\")\n",
    "val.to_parquet(\"/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/val.parquet\")\n",
    "test.to_parquet(\"/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/test.parquet\")\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/01-Setting%20up%20Experiment%20Harness.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb50ae-02c2-4b71-aa14-44b07b171a86",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf45217-18a9-496b-8f87-7dc251bc0a4a",
   "metadata": {},
   "source": [
    "## BASELINE FORECASTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb0bc0-fdf2-4a22-a160-ef7c0a7ed1c1",
   "metadata": {},
   "source": [
    "Create function for formatting ploty plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18d855fc-8f54-4025-9d84-b07ddcfa0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function for formatting ploty plots:\n",
    "def format_plot(fig, legends = None, xlabel=\"Time\", ylabel=\"Value\", title=\"\", font_size=15):\n",
    "    if legends:\n",
    "        names = cycle(legends)\n",
    "        fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
    "    fig.update_layout(\n",
    "            autosize=False,\n",
    "            width=900,\n",
    "            height=500,\n",
    "            title_text=title,\n",
    "            title={\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'},\n",
    "            titlefont={\n",
    "                \"size\": 20\n",
    "            },\n",
    "            legend_title = None,\n",
    "            legend=dict(\n",
    "                font=dict(size=font_size),\n",
    "                orientation=\"h\",\n",
    "                yanchor=\"bottom\",\n",
    "                y=0.98,\n",
    "                xanchor=\"right\",\n",
    "                x=1,\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title_text=ylabel,\n",
    "                titlefont=dict(size=font_size),\n",
    "                tickfont=dict(size=font_size),\n",
    "            ),\n",
    "            xaxis=dict(\n",
    "                title_text=xlabel,\n",
    "                titlefont=dict(size=font_size),\n",
    "                tickfont=dict(size=font_size),\n",
    "            )\n",
    "        )\n",
    "    return fig\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ab885-8d61-476b-87dd-9fea169461a9",
   "metadata": {},
   "source": [
    "Can load data from parquet files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd13c69f-73e4-41c4-9851-cdd7ac60fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can load data from parquet files:\n",
    "train_df = pd.read_parquet('/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/train.parquet')\n",
    "val_df = pd.read_parquet('/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/val.parquet')\n",
    "test_df = pd.read_parquet('/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/test.parquet')\n",
    "# #^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "# #Accessed 17/06/2024\n",
    "\n",
    "# train_df.set_index(pd.to_datetime(train_df.index, format='mixed'))\n",
    "# #^https://saturncloud.io/blog/convert-pandas-column-to-datetime-a-guide/#:~:text=To%20convert%20a%20pandas%20column,new%20column%20with%20datetime%20values.\n",
    "# #Accessed 06/06/2024\n",
    "# train_df.set_index(np.arange(0, len(train_df)))\n",
    "# #^https://saturncloud.io/blog/convert-pandas-column-to-datetime-a-guide/#:~:text=To%20convert%20a%20pandas%20column,new%20column%20with%20datetime%20values.\n",
    "# #Accessed 06/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6720e79-f8be-4e11-9145-851fbac31020",
   "metadata": {},
   "source": [
    "Create function for evaluating model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f660d6-3666-4ac1-9d29-428ec4463920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function for evaluating model performance:\n",
    "def eval_model(model, ts_train, ts_test, name=None):\n",
    "    if name is None:\n",
    "        name = type(model).__name__\n",
    "    model.fit(ts_train)\n",
    "    y_pred = model.predict(len(ts_test))\n",
    "    return y_pred, {\n",
    "        \"Algorithm\": name,\n",
    "        \"MAE\": mae(actual_series = ts_test, pred_series = y_pred),\n",
    "        \"MSE\": mse(actual_series = ts_test, pred_series = y_pred),\n",
    "        \"MASE\": mase(actual_series = ts_test, pred_series = y_pred, insample=ts_train),\n",
    "        \"Forecast Bias\": forecast_bias(actual_series = ts_test, pred_series = y_pred)\n",
    "    }\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2029fbf-7341-42a6-99a9-58622a29e851",
   "metadata": {},
   "source": [
    "Create function to return model predictions in pd series format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5a10817-3b0b-49e9-a2f7-274c0e5b439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to return model predictions in pd series format:\n",
    "def format_y_pred(y_pred, name):\n",
    "    y_pred = y_pred.data_array().to_series()\n",
    "    y_pred.index = y_pred.index.get_level_values(0)\n",
    "    y_pred.name = name\n",
    "    return y_pred\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772ae74-58eb-4928-b7c6-342d6cae8519",
   "metadata": {},
   "source": [
    "Create function for plotting forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4705af68-ea1d-483a-8e51-1c11d1715e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function for plotting forecasts\n",
    "from itertools import cycle\n",
    "def plot_forecast(pred_df, forecast_columns, forecast_display_names=None):\n",
    "    if forecast_display_names is None:\n",
    "        forecast_display_names = forecast_columns\n",
    "    else:\n",
    "        assert len(forecast_columns)==len(forecast_display_names)\n",
    "    mask = ~pred_df[forecast_columns[0]].isnull()\n",
    "    # colors = [\"rgba(\"+\",\".join([str(c) for c in plotting_utils.hex_to_rgb(c)])+\",<alpha>)\" for c in px.colors.qualitative.Plotly]\n",
    "    colors = [c.replace(\"rgb\", \"rgba\").replace(\")\", \", <alpha>)\") for c in px.colors.qualitative.Dark2]\n",
    "    # colors = [c.replace(\"rgb\", \"rgba\").replace(\")\", \", <alpha>)\") for c in px.colors.qualitative.Safe]\n",
    "    act_color = colors[0]\n",
    "    colors = cycle(colors[1:])\n",
    "    dash_types = cycle([\"dash\",\"dot\",\"dashdot\"])\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=pred_df[mask].index, y=pred_df[mask].energy_consumption,\n",
    "                        mode='lines', line = dict(color=act_color.replace(\"<alpha>\", \"0.3\")),\n",
    "                        name='Actual Consumption'))\n",
    "    for col, display_col in zip(forecast_columns,forecast_display_names):\n",
    "        fig.add_trace(go.Scatter(x=pred_df[mask].index, y=pred_df.loc[mask, col],\n",
    "                            mode='lines', line = dict(dash=next(dash_types), color=next(colors).replace(\"<alpha>\", \"1\")),\n",
    "                            name=display_col))\n",
    "    return fig\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e974e2-2e6c-45d6-b719-86bf5c77f2d6",
   "metadata": {},
   "source": [
    "### RUN FORECASTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4779c-8407-4a2c-a364-02e3645aecee",
   "metadata": {},
   "source": [
    "Run Theta forecast and FFT (from darts.models) forecast as comparison because:\n",
    "\n",
    "\"The Theta Forecast was the top-performing submission in the M3 forecasting competition that was held in 2002.\"   \n",
    "\n",
    "- Theta is recognised as a top time forecasting model   \n",
    "\n",
    "\"Fourier Transform decomposes a time series, which is in the time domain, to temporal frequencies, which is in the frequency domain. It breaks apart a time series and returns the information about the frequency of all the sine (or cosine) waves that constitute the time series....by knowing the frequencies of all the sine waves of a time series, we can reconstruct the time series perfectly, allowing a seamless transition from the frequency domain to the time domain.\"   \n",
    "\n",
    "\"For sequences that are evenly spaced, Discrete Fourier Transform is applicable, which does away with the integral and makes it into a summation. However, this is also very slow to compute. Fortunately, there is an algorithm called Fast Fourier Transform (FFT) that makes it computationally feasible. Coupled with this, there is an Inverse Fast Fourier Transform (IFFT) to go back to the time domain. While FFT will let us reconstruct the time series exactly, that is not something we want when we are forecasting. We only want to capture the signal in the time series and exclude the noise. Therefore, we can filter out noise by choosing a few prominent frequencies from FFT and only use this smaller set in IFFT. Since FFT needs the time series to be detrended, we must apply a detrending step before the FFT step and add the trend once we have reconstructed the time series. This is implemented in darts...\"   \n",
    "\n",
    "- Darts implementation of FFT and IFFT (FFT from darts.models) filters out noise to approach further towards perfect reconstruction of a time series as a forecasting model using the frequencies of all the sine waves of the time series\n",
    "\n",
    "^Source: Modern Time Series With Python, Manu Joseph (2022)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b53160-1953-4c55-b440-d7e44befddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(ts_df.columns.values[:140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f43cf7f-bb81-4ea4-9b3d-ead9e3470a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.metrics.metrics import _get_values_or_raise\n",
    "from typing import Optional, Tuple, Union, Sequence, Callable, cast\n",
    "def forecast_bias(actual_series: Union[TimeSeries, Sequence[TimeSeries], np.ndarray],\n",
    "        pred_series: Union[TimeSeries, Sequence[TimeSeries], np.ndarray],\n",
    "        intersect: bool = True,\n",
    "        *,\n",
    "        reduction: Callable[[np.ndarray], float] = np.mean,\n",
    "        inter_reduction: Callable[[np.ndarray], Union[float, np.ndarray]] = lambda x: x,\n",
    "        n_jobs: int = 1,\n",
    "        verbose: bool = False) -> Union[float, np.ndarray]:\n",
    "    \"\"\" Forecast Bias (FB).\n",
    "\n",
    "    Given a time series of actual values :math:`y_t` and a time series of predicted values :math:`\\\\hat{y}_t`\n",
    "    both of length :math:`T`, it is a percentage value computed as\n",
    "\n",
    "    .. math:: 100 \\\\cdot \\\\frac{\\\\sum_{t=1}^{T}{y_t}\n",
    "              - \\\\sum_{t=1}^{T}{\\\\hat{y}_t}}{\\\\sum_{t=1}^{T}{y_t}}.\n",
    "\n",
    "    If any of the series is stochastic (containing several samples), the median sample value is considered.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual_series\n",
    "        The `TimeSeries` or `Sequence[TimeSeries]` of actual values.\n",
    "    pred_series\n",
    "        The `TimeSeries` or `Sequence[TimeSeries]` of predicted values.\n",
    "    intersect\n",
    "        For time series that are overlapping in time without having the same time index, setting `intersect=True`\n",
    "        will consider the values only over their common time interval (intersection in time).\n",
    "    reduction\n",
    "        Function taking as input a `np.ndarray` and returning a scalar value. This function is used to aggregate\n",
    "        the metrics of different components in case of multivariate `TimeSeries` instances.\n",
    "    inter_reduction\n",
    "        Function taking as input a `np.ndarray` and returning either a scalar value or a `np.ndarray`.\n",
    "        This function can be used to aggregate the metrics of different series in case the metric is evaluated on a\n",
    "        `Sequence[TimeSeries]`. Defaults to the identity function, which returns the pairwise metrics for each pair\n",
    "        of `TimeSeries` received in input. Example: `inter_reduction=np.mean`, will return the average of the pairwise\n",
    "        metrics.\n",
    "    n_jobs\n",
    "        The number of jobs to run in parallel. Parallel jobs are created only when a `Sequence[TimeSeries]` is\n",
    "        passed as input, parallelising operations regarding different `TimeSeries`. Defaults to `1`\n",
    "        (sequential). Setting the parameter to `-1` means using all the available processors.\n",
    "    verbose\n",
    "        Optionally, whether to print operations progress\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If :math:`\\\\sum_{t=1}^{T}{y_t} = 0`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The Forecast Bias (OPE)\n",
    "    \"\"\"\n",
    "    assert type(actual_series) is type(pred_series), \"actual_series and pred_series should be of same type.\"\n",
    "    if isinstance(actual_series, np.ndarray):\n",
    "        y_true, y_pred = actual_series, pred_series\n",
    "    else:\n",
    "        y_true, y_pred = _get_values_or_raise(actual_series, pred_series, intersect)\n",
    "    y_true_sum, y_pred_sum = np.sum(y_true), np.sum(y_pred)\n",
    "    # raise_if_not(y_true_sum > 0, 'The series of actual value cannot sum to zero when computing OPE.', logger)\n",
    "    return ((y_true_sum - y_pred_sum) / y_true_sum) * 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da1e51-33e6-4047-88e7-68071adba4b8",
   "metadata": {},
   "source": [
    "### RUN FORECASTS FOR VALIDATION SET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a8942-b7d5-4882-b212-09cd9f73a39c",
   "metadata": {},
   "source": [
    "Do Theta forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d2b5879-cef0-488e-bc77-f04244cca825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[180.2625]\n",
      " [178.125 ]\n",
      " [178.125 ]\n",
      " [178.125 ]\n",
      " [205.9125]\n",
      " [205.9125]\n",
      " [205.9125]\n",
      " [205.9125]\n",
      " [178.125 ]\n",
      " [205.9125]\n",
      " [177.4125]\n",
      " [177.4125]\n",
      " [177.4125]\n",
      " [204.4875]\n",
      " [205.9125]\n",
      " [205.9125]\n",
      " [208.7625]\n",
      " [213.0375]\n",
      " [205.9125]\n",
      " [205.9125]\n",
      " [205.9125]\n",
      " [201.6375]\n",
      " [178.125 ]\n",
      " [178.125 ]\n",
      " [178.125 ]\n",
      " [178.125 ]\n",
      " [205.9125]\n",
      " [177.4125]\n",
      " [213.0375]\n",
      " [177.4125]\n",
      " [177.4125]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [205.9125]\n",
      " [178.125 ]\n",
      " [178.125 ]\n",
      " [205.9125]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [204.4875]\n",
      " [205.9125]\n",
      " [213.0375]\n",
      " [178.8375]\n",
      " [177.4125]\n",
      " [213.0375]\n",
      " [178.125 ]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [177.4125]\n",
      " [177.4125]\n",
      " [213.0375]\n",
      " [177.4125]\n",
      " [178.125 ]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [177.4125]\n",
      " [178.125 ]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [178.125 ]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [177.4125]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [178.125 ]\n",
      " [178.125 ]\n",
      " [177.4125]\n",
      " [213.0375]\n",
      " [177.4125]\n",
      " [177.4125]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [178.125 ]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [178.125 ]\n",
      " [213.0375]\n",
      " [177.4125]\n",
      " [207.3375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [178.125 ]\n",
      " [213.0375]\n",
      " [177.4125]\n",
      " [177.4125]\n",
      " [177.4125]\n",
      " [178.125 ]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [204.4875]\n",
      " [191.6625]\n",
      " [191.6625]]\n",
      "[[191.6625]\n",
      " [213.0375]\n",
      " [234.4125]\n",
      " [177.4125]\n",
      " [177.4125]\n",
      " [177.4125]\n",
      " [213.0375]\n",
      " [234.4125]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [213.0375]\n",
      " [191.6625]\n",
      " [177.4125]\n",
      " [165.3   ]\n",
      " [172.425 ]\n",
      " [234.4125]]\n",
      "Time Elapsed: 0 microseconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/darts/metrics/metrics.py:783: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/darts/metrics/metrics.py:242: RuntimeWarning: Mean of empty slice\n",
      "  vals = np.expand_dims(component_reduction(vals, axis=COMP_AX), axis=COMP_AX)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/darts/metrics/metrics.py:1159: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/darts/metrics/metrics.py:998: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(\n",
      "/var/folders/xn/_bz_k2_x60v2l_s_sch6rwp40000gn/T/ipykernel_15160/2604410711.py:63: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return ((y_true_sum - y_pred_sum) / y_true_sum) * 100.\n"
     ]
    }
   ],
   "source": [
    "#Do Theta forecast:\n",
    "name = \"Theta\"\n",
    "theta_preds = []\n",
    "theta_metrics = []\n",
    "with LogTime() as timer:\n",
    "    for var in range(1):\n",
    "    # for var in range(len(col_list)):\n",
    "        # tr = train_df.loc[:, [train_df.columns.values[var]]].to_numpy()\n",
    "        # vl = val_df.loc[:, [val_df.columns.values[var]]].to_numpy()\n",
    "        if seasonal_period_list[var] != 'not seasonal':\n",
    "            theta_model = Theta(theta=3, seasonality_period=seasonal_period_list[var], season_mode=SeasonalityMode.ADDITIVE)\n",
    "        if seasonal_period_list[var] == 'not seasonal':\n",
    "            theta_model = Theta(theta=3, seasonality_period=0, season_mode=SeasonalityMode.NONE)\n",
    "        tr = TimeSeries.from_dataframe(train_df, time_col='timestamp', value_cols=train_df.columns.values[var])\n",
    "        vl = TimeSeries.from_dataframe(val_df, time_col='timestamp', value_cols=val_df.columns.values[var])\n",
    "        # ts = TimeSeries.from_series(test_df[test_df.columns.values[var]])\n",
    "        y_pred, metrics = eval_model(theta_model, tr, vl, name=name)\n",
    "        y_pred = format_y_pred(y_pred, (\"predictions\" + '_' + str(col_list[var]))).to_frame()\n",
    "        y_pred['Variable'] = col_list[var]\n",
    "        y_pred['Algorithm'] = name\n",
    "        metrics['Variable'] = col_list[var]\n",
    "        metrics['Algorithm'] = name\n",
    "        y_pred[col_list[var]] = vl.data_array().to_series().values\n",
    "        theta_preds.append(y_pred)\n",
    "        theta_metrics.append(metrics)\n",
    "theta_val_pred_df = pd.concat(theta_preds, axis=1)\n",
    "theta_val_metric_df = pd.DataFrame(theta_metrics)\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b28763-e097-43ea-867f-b5a802323453",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_val_metric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d702ed6-0580-47a3-84a2-a19d9bbf46a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions_679023median_total_price</th>\n",
       "      <th>Variable</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>679023median_total_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>192.801320</td>\n",
       "      <td>679023median_total_price</td>\n",
       "      <td>Theta</td>\n",
       "      <td>191.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>192.973122</td>\n",
       "      <td>679023median_total_price</td>\n",
       "      <td>Theta</td>\n",
       "      <td>213.0375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>192.973649</td>\n",
       "      <td>679023median_total_price</td>\n",
       "      <td>Theta</td>\n",
       "      <td>234.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>188.712878</td>\n",
       "      <td>679023median_total_price</td>\n",
       "      <td>Theta</td>\n",
       "      <td>177.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>188.542131</td>\n",
       "      <td>679023median_total_price</td>\n",
       "      <td>Theta</td>\n",
       "      <td>177.4125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predictions_679023median_total_price                  Variable  \\\n",
       "time                                                                   \n",
       "105                             192.801320  679023median_total_price   \n",
       "106                             192.973122  679023median_total_price   \n",
       "107                             192.973649  679023median_total_price   \n",
       "108                             188.712878  679023median_total_price   \n",
       "109                             188.542131  679023median_total_price   \n",
       "\n",
       "     Algorithm  679023median_total_price  \n",
       "time                                      \n",
       "105      Theta                  191.6625  \n",
       "106      Theta                  213.0375  \n",
       "107      Theta                  234.4125  \n",
       "108      Theta                  177.4125  \n",
       "109      Theta                  177.4125  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_val_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fecb290-dfe4-4669-8544-b3c39815e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle predictions and metrics:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_theta__val_predictions.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(theta_val_pred_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      theta_val_pred_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_theta__val_metrics.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(theta_val_metric_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      theta_val_metric_df = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dde9eb-598a-4a6a-b2a3-e6f5066b9fa8",
   "metadata": {},
   "source": [
    "Tabulate metrics per variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70c01a-94d3-423a-af41-25a6eebd34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabulate metrics per variable:\n",
    "with LogTime() as timer:\n",
    "    for var in range(len(col_list)):\n",
    "        actual_series = TimeSeries.from_values(theta_val_pred_df[col_list[var]].values)\n",
    "        pred_series = TimeSeries.from_values(theta_val_pred_df[(\"predictions\" + '_' + str(col_list[var]))].values)\n",
    "        pickle_var = globals()[(str(col_list[var]) + \"overall_metrics_val_theta\")] \n",
    "        pickle_var = {\n",
    "            \"Algorithm\": \"Theta\",\n",
    "            \"MAE\": mae(actual_series = actual_series, pred_series = pred_series),\n",
    "            \"MSE\": mse(actual_series = actual_series, pred_series = pred_series),\n",
    "            \"meanMASE\": theta_val_metric_df.MASE.mean(),\n",
    "            \"Forecast Bias\": ope(actual_series = actual_series, pred_series = pred_series)\n",
    "        }\n",
    "        file_2 = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/theta/val_overall_metrics_theta_'\n",
    "        file_edit_2 = file_2\n",
    "        file_to_use_2 = file_edit_2 + str(col_list[var])\n",
    "        with open(file, 'wb') as f:\n",
    "               pickle.dump(pickle_var, f) #write df to .pik file on disk\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2661a368-e48e-4a8e-ac93-60ec9650ddcb",
   "metadata": {},
   "source": [
    "Do FFT forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0944f97d-d2d8-4923-be6f-33b3f4029655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do FFT forecast:\n",
    "name = \"FFT\"\n",
    "fft_preds = []\n",
    "fft_metrics = []\n",
    "with LogTime() as timer:\n",
    "    for var in range(len(col_list)):\n",
    "        fft_model = FFT(nr_freqs_to_keep=35, trend=\"poly\", trend_poly_degree=2)\n",
    "        tr = TimeSeries.from_series(train_df[train_df.columns.values[var]])\n",
    "        vl = TimeSeries.from_series(val_df[val_df.columns.values[var]])\n",
    "        # ts = TimeSeries.from_series(test_df[test_df.columns.values[var]])\n",
    "        y_pred, metrics = eval_model(fft_model, tr, vl, name=name)\n",
    "        y_pred = format_y_pred(y_pred, (\"predictions\" + '_' + str(col_list[var]))).to_frame()\n",
    "        y_pred['Variable'] = col_list[var]\n",
    "        y_pred['Algorithm'] = name\n",
    "        metrics['Variable'] = col_list[var]\n",
    "        metrics['Algorithm'] = name\n",
    "        y_pred[col_list[var]] = vl.data_array().to_series().values\n",
    "        fft_preds.append(y_pred)\n",
    "        fft_metrics.append(metrics)\n",
    "fft_val_pred_df = pd.concat(fft_preds, axis=1)\n",
    "fft_val_metric_df = pd.DataFrame(fft_metrics)\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da04e89-c56e-4e4d-b539-2e30dd93e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_val_metric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f2ce36-9b3d-42bb-afa7-8eb9c40e9d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_val_pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d18e37f-36c2-44f0-88c5-227b79aa7842",
   "metadata": {},
   "source": [
    "Pickle predictions and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb87aeb-48e6-44c8-928e-d318056a6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle predictions and metrics:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_fft__val_predictions.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(fft_val_pred_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      fft_val_pred_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_fft__val_metrics.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(fft_val_metric_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      fft_val_metric_df = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5687fc-6393-41cb-909e-ca64d6195b8e",
   "metadata": {},
   "source": [
    "Tabulate metrics per variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f045b4b-6358-4a8c-9b12-16d7377b4f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabulate metrics per variable:\n",
    "with LogTime() as timer:\n",
    "    for var in range(len(col_list)):\n",
    "        actual_series = TimeSeries.from_values(fft_val_pred_df[col_list[var]].values)\n",
    "        pred_series = TimeSeries.from_values(fft_val_pred_df[(\"predictions\" + '_' + str(col_list[var]))].values)\n",
    "        pickle_var = globals()[(str(col_list[var]) + \"overall_metrics_val_fft\")] \n",
    "        pickle_var = {\n",
    "            \"Algorithm\": \"Theta\",\n",
    "            \"MAE\": mae(actual_series = actual_series, pred_series = pred_series),\n",
    "            \"MSE\": mse(actual_series = actual_series, pred_series = pred_series),\n",
    "            \"meanMASE\": fft_val_metric_df.MASE.mean(),\n",
    "            \"Forecast Bias\": ope(actual_series = actual_series, pred_series = pred_series)\n",
    "        }\n",
    "        file_2 = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/fft/val_overall_metrics_fft_'\n",
    "        file_edit_2 = file_2\n",
    "        file_to_use_2 = file_edit_2 + str(col_list[var])\n",
    "        with open(file, 'wb') as f:\n",
    "               pickle.dump(pickle_var, f) #write df to .pik file on disk\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba5ce0-0c73-4700-889c-7d8a2b6a436d",
   "metadata": {},
   "source": [
    "Evaluate baseline forecast for validation set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61fff94-75f9-499b-99ba-a49a7f67acff",
   "metadata": {},
   "source": [
    "Create table of overall metric comparison per variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e87fc6f-c0a7-4dd8-8be1-cd80595e1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create table of overall metric comparison per variable: \n",
    "with LogTime() as timer:\n",
    "    for var in range(len(col_list)):\n",
    "        file_2 = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/theta/val_overall_metrics_theta_'\n",
    "        file_edit_2 = file_2\n",
    "        file_to_use_2 = file_edit_2 + str(col_list[var]) + '.pik'\n",
    "        with open(file, 'rb') as f:\n",
    "               pickle_var = pickle.load(f) #load pickle file 'file' into variable\n",
    "        file_2 = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/fft/val_overall_metrics_fft_'\n",
    "        file_edit_2 = file_2\n",
    "        file_to_use_2 = file_edit_2 + str(col_list[var]) + '.pik'\n",
    "        with open(file, 'rb') as f:\n",
    "               pickle_var_2 = pickle.load(f) #load pickle file 'file' into variable\n",
    "        agg_val_metrics_df = pd.DataFrame([pickle_var_2, pickle_var])\n",
    "        \n",
    "        display(agg_val_metrics_df.style.format({\"MAE\": \"{:.3f}\", \n",
    "                                  \"MSE\": \"{:.3f}\", \n",
    "                                  \"meanMASE\": \"{:.3f}\", \n",
    "                                  \"Forecast Bias\": \"{:.2f}%\"}).highlight_min(color='lightgreen', subset=[\"MAE\",\"MSE\",\"meanMASE\"]))\n",
    "        file_2 = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/val_agg_overall_metrics_'\n",
    "        file_edit_2 = file_2\n",
    "        file_to_use_2 = file_edit_2 + str(col_list[var])\n",
    "        with open(file, 'wb') as f:\n",
    "               pickle.dump(agg_val_metrics_df, f) #write df to .pik file on disk\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492b90ec-e38b-4dc7-816e-2f13b11cea59",
   "metadata": {},
   "source": [
    "Concatenate forecasts and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2252300-eb5e-4922-86b3-9ee01f80b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate forecasts and metrics:\n",
    "baseline_val_pred_df = pd.concat([theta_val_pred_df, fft_val_pred_df])\n",
    "baseline_val_metrics_df = pd.concat([theta_val_metric_df, fft_val_metric_df])\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ed57a-7d58-45c5-b67f-e76474a26d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_val_metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2edc85-9cda-4234-b53e-c0293bc6274a",
   "metadata": {},
   "source": [
    "Pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7120f-5d04-4981-a09d-b44b4b539b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_baseline_val_preds.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(baseline_val_pred_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      baseline_val_pred_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_baseline_val_metrics.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(baseline_val_metrics_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      baseline_val_metrics_df = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2cb3fc-1b48-4bfe-a89b-ec0a9be7356e",
   "metadata": {},
   "source": [
    "Graphs to show baseline forecasts metrics for validation set (MASE, MAE, MSE, Forecast Bias):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d49a0d-cba8-4b8a-91b0-0a740fb8c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MASE:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/val_metrics_MASE'\n",
    "file_to_use = file + '.png'\n",
    "fig = px.histogram(baseline_val_metrics_df, \n",
    "                   x=\"MASE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=500, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MASE\", ylabel=\"Probability Density\", title=\"Distribution of MASE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,10])\n",
    "fig.write_image(file_to_use)\n",
    "fig.show()\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b670e-45e4-45de-9eb5-ba6a675a71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/val_metrics_MAE'\n",
    "file_to_use = file + '.png'\n",
    "fig = px.histogram(baseline_val_metrics_df, \n",
    "                   x=\"MAE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=100, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MAE\", ylabel=\"Probability Density\", title=\"Distribution of MAE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,1.1])\n",
    "fig.write_image(file_to_use)\n",
    "fig.show()\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b1ae4-1fdd-4357-b7ae-b0cfe900ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/val_metrics_MSE'\n",
    "file_to_use = file + '.png'\n",
    "fig = px.histogram(baseline_val_metrics_df, \n",
    "                   x=\"MSE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=500, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MSE\", ylabel=\"Probability Density\", title=\"Distribution of MSE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,1])\n",
    "fig.write_image(file_to_use)\n",
    "fig.show()\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eeb198-8184-4e96-9caf-8557680dda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forecast Bias:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/val_metrics_Forecast_Bias'\n",
    "file_to_use = file + '.png'\n",
    "fig = px.histogram(baseline_val_metrics_df, \n",
    "                   x=\"Forecast Bias\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=250,\n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"Forecast Bias\", ylabel=\"Probability Density\", title=\"Distribution of Forecast Bias in the dataset\")\n",
    "fig.update_layout(xaxis_range=[-200,200])\n",
    "fig.write_image(file_to_use)\n",
    "fig.show()\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d7df1-a6b3-4817-8760-485df29a6021",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f311b72-2864-4c13-9127-e8fe2454d1fa",
   "metadata": {},
   "source": [
    "### RUN FORECASTS FOR TEST SET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29915b9c-db45-486c-bd4f-d24b6241892e",
   "metadata": {},
   "source": [
    "Do Theta forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6201d9-a7cc-4d12-a100-65f6216d0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do Theta forecast:\n",
    "name = \"Theta\"\n",
    "theta_preds = []\n",
    "theta_metrics = []\n",
    "with LogTime() as timer:\n",
    "    for var in range(len(col_list)):\n",
    "        if seasonal_period_list[var] != 'not seasonal':\n",
    "            theta_model = Theta(theta=3, seasonality_period=seasonal_period_list[var], season_mode=SeasonalityMode.ADDITIVE)\n",
    "        if seasonal_period_list[var] == 'not seasonal':\n",
    "            theta_model = Theta(theta=3, seasonality_period=0, season_mode=SeasonalityMode.NONE)\n",
    "        tr = TimeSeries.from_series(train_df[train_df.columns.values[var]])\n",
    "        ts = TimeSeries.from_series(test_df[test_df.columns.values[var]])\n",
    "        y_pred, metrics = eval_model(theta_model, tr, ts, name=name)\n",
    "        y_pred = format_y_pred(y_pred, (\"predictions\" + '_' + str(col_list[var]))).to_frame()\n",
    "        y_pred['Variable'] = col_list[var]\n",
    "        y_pred['Algorithm'] = name\n",
    "        metrics['Variable'] = col_list[var]\n",
    "        metrics['Algorithm'] = name\n",
    "        y_pred[col_list[var]] = ts.data_array().to_series().values\n",
    "        theta_preds.append(y_pred)\n",
    "        theta_metrics.append(metrics)\n",
    "theta_test_pred_df = pd.concat(theta_preds, axis=1)\n",
    "theta_test_metric_df = pd.DataFrame(theta_metrics)\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a42e05-bfe6-4dce-9a2c-915d928b4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_test_metric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c1fec-3ebc-4e84-8c4e-1c1c873da6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_test_pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583ef9a-b642-4092-a62d-c01f80cb7180",
   "metadata": {},
   "source": [
    "Pickle predictions and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d28a16-450d-460f-b7e8-f438e49559a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle predictions and metrics:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_theta__test_predictions.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(theta_test_pred_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      theta_test_pred_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_theta__test_metrics.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(theta_test_metric_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      theta_test_metric_df = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e8f2b-7d2e-4332-8f70-4880580159bf",
   "metadata": {},
   "source": [
    "Tabulate metrics per variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f8138-e5c7-46ab-8a52-5411c6ddb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabulate metrics per variable:\n",
    "with LogTime() as timer:\n",
    "    for var in range(len(col_list)):\n",
    "        actual_series = TimeSeries.from_values(theta_val_test_df[col_list[var]].values)\n",
    "        pred_series = TimeSeries.from_values(theta_val_test_df[(\"predictions\" + '_' + str(col_list[var]))].values)\n",
    "        pickle_var = globals()[(str(col_list[var]) + \"overall_metrics_test_theta\")] \n",
    "        pickle_var = {\n",
    "            \"Algorithm\": \"Theta\",\n",
    "            \"MAE\": mae(actual_series = actual_series, pred_series = pred_series),\n",
    "            \"MSE\": mse(actual_series = actual_series, pred_series = pred_series),\n",
    "            \"meanMASE\": theta_test_metric_df.MASE.mean(),\n",
    "            \"Forecast Bias\": ope(actual_series = actual_series, pred_series = pred_series)\n",
    "        }\n",
    "        file_2 = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/theta/test_overall_metrics_theta_'\n",
    "        file_edit_2 = file_2\n",
    "        file_to_use_2 = file_edit_2 + str(col_list[var])\n",
    "        with open(file, 'wb') as f:\n",
    "               pickle.dump(pickle_var, f) #write df to .pik file on disk\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b83e18-a172-4cc3-a5a1-f4137a5cdee5",
   "metadata": {},
   "source": [
    "Do FFT forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b673d57-fcf6-4adb-961a-f9ca18e7efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do FFT forecast:\n",
    "name = \"FFT\"\n",
    "fft_preds = []\n",
    "fft_metrics = []\n",
    "with LogTime() as timer:\n",
    "    for var in range(len(col_list)):\n",
    "        fft_model = FFT(nr_freqs_to_keep=35, trend=\"poly\", trend_poly_degree=2)\n",
    "        tr = TimeSeries.from_series(train_df[train_df.columns.values[var]])\n",
    "        ts = TimeSeries.from_series(test_df[test_df.columns.values[var]])\n",
    "        y_pred, metrics = eval_model(fft_model, tr, ts, name=name)\n",
    "        y_pred = format_y_pred(y_pred, (\"predictions\" + '_' + str(col_list[var]))).to_frame()\n",
    "        y_pred['Variable'] = col_list[var]\n",
    "        y_pred['Algorithm'] = name\n",
    "        metrics['Variable'] = col_list[var]\n",
    "        metrics['Algorithm'] = name\n",
    "        y_pred[col_list[var]] = ts.data_array().to_series().values\n",
    "        fft_preds.append(y_pred)\n",
    "        fft_metrics.append(metrics)\n",
    "fft_test_pred_df = pd.concat(fft_preds, axis=1)\n",
    "fft_test_metric_df = pd.DataFrame(fft_metrics)\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac7505-d906-4ff7-9cf6-4e56aa79175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_test_metric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd81c2-265c-440d-bd27-550b96380f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_test_pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01b4865-86a4-44ce-8439-457cbdf0680d",
   "metadata": {},
   "source": [
    "Pickle predictions and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2477e7bf-c624-43a2-ad05-51cb3fb089eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle predictions and metrics:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_fft__test_predictions.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(fft_test_pred_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      fft_test_pred_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_fft__test_metrics.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(fft_test_metric_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      fft_test_metric_df = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1767f6-d532-497e-aa36-a1e6108ee7a9",
   "metadata": {},
   "source": [
    "Tabulate metrics per variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1533985-9414-4187-a4d1-54248c9bbada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabulate metrics per variable:\n",
    "with LogTime() as timer:\n",
    "    for var in range(len(col_list)):\n",
    "        actual_series = TimeSeries.from_values(fft_test_pred_df[col_list[var]].values)\n",
    "        pred_series = TimeSeries.from_values(fft_test_pred_df[(\"predictions\" + '_' + str(col_list[var]))].values)\n",
    "        pickle_var = globals()[(str(col_list[var]) + \"overall_metrics_test_fft\")] \n",
    "        pickle_var = {\n",
    "            \"Algorithm\": \"Theta\",\n",
    "            \"MAE\": mae(actual_series = actual_series, pred_series = pred_series),\n",
    "            \"MSE\": mse(actual_series = actual_series, pred_series = pred_series),\n",
    "            \"meanMASE\": fft_test_metric_df.MASE.mean(),\n",
    "            \"Forecast Bias\": ope(actual_series = actual_series, pred_series = pred_series)\n",
    "        }\n",
    "        file_2 = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/fft/test_overall_metrics_fft_'\n",
    "        file_edit_2 = file_2\n",
    "        file_to_use_2 = file_edit_2 + str(col_list[var])\n",
    "        with open(file, 'wb') as f:\n",
    "               pickle.dump(pickle_var, f) #write df to .pik file on disk\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6790df-2be5-4fda-bed9-a28e685a423d",
   "metadata": {},
   "source": [
    "Evaluate baseline forecast for validation set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a8add-13f4-4c91-ae1a-120be42ace28",
   "metadata": {},
   "source": [
    "Create table of overall metric comparison per variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9f959-0acd-4e00-9063-300b714f7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create table of overall metric comparison per variable: \n",
    "with LogTime() as timer:\n",
    "    for var in range(len(col_list)):\n",
    "        file_2 = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/theta/test_overall_metrics_theta_'\n",
    "        file_edit_2 = file_2\n",
    "        file_to_use_2 = file_edit_2 + str(col_list[var]) + '.pik'\n",
    "        with open(file, 'rb') as f:\n",
    "               pickle_var = pickle.load(f) #load pickle file 'file' into variable\n",
    "        file_2 = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/fft/test_overall_metrics_fft_'\n",
    "        file_edit_2 = file_2\n",
    "        file_to_use_2 = file_edit_2 + str(col_list[var]) + '.pik'\n",
    "        with open(file, 'rb') as f:\n",
    "               pickle_var_2 = pickle.load(f) #load pickle file 'file' into variable\n",
    "        agg_test_metrics_df = pd.DataFrame([pickle_var_2, pickle_var])\n",
    "        \n",
    "        display(agg_test_metrics_df.style.format({\"MAE\": \"{:.3f}\", \n",
    "                                  \"MSE\": \"{:.3f}\", \n",
    "                                  \"meanMASE\": \"{:.3f}\", \n",
    "                                  \"Forecast Bias\": \"{:.2f}%\"}).highlight_min(color='lightgreen', subset=[\"MAE\",\"MSE\",\"meanMASE\"]))\n",
    "        file_2 = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/test_agg_overall_metrics_'\n",
    "        file_edit_2 = file_2\n",
    "        file_to_use_2 = file_edit_2 + str(col_list[var])\n",
    "        with open(file, 'wb') as f:\n",
    "               pickle.dump(agg_test_metrics_df, f) #write df to .pik file on disk\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e0760-ec3e-45a5-8904-8c7931386b48",
   "metadata": {},
   "source": [
    "Concatenate forecasts and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f420393-a75b-46b2-9765-1d11a659f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate forecasts and metrics:\n",
    "baseline_test_pred_df = pd.concat([theta_test_pred_df, fft_test_pred_df])\n",
    "baseline_test_metrics_df = pd.concat([theta_test_metric_df, fft_test_metric_df])\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655da3e6-0c01-45d2-a199-5bf47a2d4833",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_test_metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b716d-9231-4aeb-aa6f-e276a1a0afcf",
   "metadata": {},
   "source": [
    "Pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62f7c4-eb40-41c2-a829-74e4736c754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_baseline_test_preds.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(baseline_test_pred_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      baseline_test_pred_df = pickle.load(f) #load pickle file 'file' into variable\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts_baseline_test_metrics.pik'\n",
    "with open(file, 'wb') as f:\n",
    "       pickle.dump(baseline_test_metrics_df, f) #write df to .pik file on disk\n",
    "# with open(file, 'rb') as f:\n",
    "#      baseline_test_metrics_df = pickle.load(f) #load pickle file 'file' into variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3458e5-50e1-40e7-ab52-7f9bde966646",
   "metadata": {},
   "source": [
    "Graphs to show baseline forecasts metrics for test data (MASE, MAE, MSE, Forecast Bias):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba702c-cac6-4496-9da4-5662cce43b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MASE:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/test_metrics_MASE'\n",
    "file_to_use = file + '.png'\n",
    "fig = px.histogram(baseline_test_metrics_df, \n",
    "                   x=\"MASE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=500, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MASE\", ylabel=\"Probability Density\", title=\"Distribution of MASE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,10])\n",
    "fig.write_image(file_to_use)\n",
    "fig.show()\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e9910-9747-461e-ba97-7f786458afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/test_metrics_MAE'\n",
    "file_to_use = file + '.png'\n",
    "fig = px.histogram(baseline_test_metrics_df, \n",
    "                   x=\"MAE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=100, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MAE\", ylabel=\"Probability Density\", title=\"Distribution of MAE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,1.1])\n",
    "fig.write_image(file_to_use)\n",
    "fig.show()\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f0bdaa-92ba-4816-a0bc-fda4de5fd2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/test_metrics_MSE'\n",
    "file_to_use = file + '.png'\n",
    "fig = px.histogram(baseline_test_metrics_df, \n",
    "                   x=\"MSE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=500, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MSE\", ylabel=\"Probability Density\", title=\"Distribution of MSE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,1])\n",
    "fig.write_image(file_to_use)\n",
    "fig.show()\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476e21a-60fa-4fa8-a3c2-17ff3fa452c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forecast Bias:\n",
    "file = '/Users/harrybakhshi/Desktop/Python_notes/data/PCDA_capstone/baseline_forecasts/test_metrics_Forecast_Bias'\n",
    "file_to_use = file + '.png'\n",
    "fig = px.histogram(baseline_test_metrics_df, \n",
    "                   x=\"Forecast Bias\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=250,\n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"Forecast Bias\", ylabel=\"Probability Density\", title=\"Distribution of Forecast Bias in the dataset\")\n",
    "fig.update_layout(xaxis_range=[-200,200])\n",
    "fig.write_image(file_to_use)\n",
    "fig.show()\n",
    "#^https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python/blob/main/notebooks/Chapter04/02-Baseline%20Forecasts%20using%20darts.ipynb\n",
    "#Accessed 17/06/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71889379-5562-435a-b310-77de68cb2c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
